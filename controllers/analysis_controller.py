# controllers/analysis_controller.py
# åˆ†ææ§åˆ¶å™¨ - è² è²¬è™•ç†è‡ªç„¶èªè¨€æŸ¥è©¢å’Œæ¥­å‹™é‚è¼¯

from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
import re
import random
# import logging  # è¨»è§£æ‰ logging æ¨¡çµ„
import os
import tempfile
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from statsmodels.tsa.statespace.sarimax import SARIMAX
from models.exogenous_variables import ExogenousVariables

class AnalysisController:
    """
    æ§åˆ¶å™¨(Controller)å±¤: è™•ç†è‡ªç„¶èªè¨€æŸ¥è©¢è§£æå’Œæ¥­å‹™é‚è¼¯ã€‚
    """
    def __init__(self, data_manager):
        """
        åˆå§‹åŒ–åˆ†ææ§åˆ¶å™¨
        """
        self.data_manager = data_manager
        # self.logger = logging.getLogger(__name__)  # è¨»è§£æ‰ logger

    def _parse_query(self, query):
        """
        [Controller] ç°¡æ˜“çš„è‡ªç„¶èªè¨€è§£æå™¨ï¼Œæ¨¡æ“¬LangChainçš„åŠŸèƒ½ã€‚
        è¾¨è­˜æ™‚é–“ç¯„åœå’Œåˆ†æç¶­åº¦ã€‚
        """
        print(f"ğŸ” é–‹å§‹è§£ææŸ¥è©¢: {query}")
        
        # ç‚ºäº†æ¼”ç¤ºç©©å®šï¼Œæˆ‘å€‘å°‡"ä»Šå¤©"å›ºå®šåœ¨æ•¸æ“šç¯„åœå…§çš„ä¸€å€‹æ—¥æœŸ
        today = datetime(2025, 8, 31) 
        print(f"   ä½¿ç”¨å›ºå®šæ—¥æœŸ: {today}")
        
        # é è¨­æ™‚é–“æ¯”è¼ƒ: é€™å€‹æœˆ vs ä¸Šå€‹æœˆ
        current_start = today.replace(day=1)
        last_start = (current_start - timedelta(days=1)).replace(day=1)
        current_end = (current_start + relativedelta(months=1)) - timedelta(days=1)
        last_end = (last_start + relativedelta(months=1)) - timedelta(days=1)
        period_text = f"{current_start.year}å¹´{current_start.month}æœˆ vs ä¸Šæœˆ"
        
        print(f"   é è¨­æ™‚é–“ç¯„åœ:")
        print(f"     - ç•¶å‰æœŸé–“: {current_start} åˆ° {current_end}")
        print(f"     - æ¯”è¼ƒæœŸé–“: {last_start} åˆ° {last_end}")
        print(f"     - æœŸé–“æ–‡å­—: {period_text}")

        # çµ±ä¸€è™•ç†æŸ¥è©¢ä¸­çš„æ™‚é–“æ ¼å¼
        processed_query = query
        
        # 1. çµ±ä¸€è™•ç†æœˆä»½çš„ä¸­æ–‡è¡¨ç¤º
        month_mapping = {
            'ä¸€æœˆ': '01', 'äºŒæœˆ': '02', 'ä¸‰æœˆ': '03', 'å››æœˆ': '04',
            'äº”æœˆ': '05', 'å…­æœˆ': '06', 'ä¸ƒæœˆ': '07', 'å…«æœˆ': '08',
            'ä¹æœˆ': '09', 'åæœˆ': '10', 'åä¸€æœˆ': '11', 'åäºŒæœˆ': '12'
        }
        
        for chinese_month, numeric_month in month_mapping.items():
            # å°‡ "2025å¹´ä¸ƒæœˆ" è½‰æ›ç‚º "2025å¹´07æœˆ"
            processed_query = processed_query.replace(f"å¹´{chinese_month}", f"å¹´{numeric_month}æœˆ")
        
        # 2. çµ±ä¸€è™•ç†å­£åº¦æ ¼å¼
        quarter_mapping = {
            'å­£1': 'Q1', 'å­£2': 'Q2', 'å­£3': 'Q3', 'å­£4': 'Q4',
            'q1': 'Q1', 'q2': 'Q2', 'q3': 'Q3', 'q4': 'Q4'
        }
        
        for quarter_text, quarter_code in quarter_mapping.items():
            processed_query = processed_query.replace(quarter_text, quarter_code)
        
        print(f"   è™•ç†å¾Œçš„æŸ¥è©¢: {processed_query}")

        # å˜—è©¦è§£æå…·é«”çš„å¹´æœˆæ ¼å¼
        
        # é¦–å…ˆå˜—è©¦è§£æ "YYYY/MM" æˆ– "YYYY-MM" æ ¼å¼ (å¦‚: 2025/07, 2025-07)
        slash_dash_pattern = r'(\d{4})[/-](\d{1,2})'
        slash_dash_matches = re.findall(slash_dash_pattern, processed_query)
        
        if len(slash_dash_matches) >= 2:
            # æ‰¾åˆ°å…©å€‹ YYYY/MM æˆ– YYYY-MM æ ¼å¼ï¼Œç¬¬ä¸€å€‹ä½œç‚ºç•¶å‰æœŸé–“ï¼Œç¬¬äºŒå€‹ä½œç‚ºæ¯”è¼ƒæœŸé–“
            current_year, current_month = int(slash_dash_matches[0][0]), int(slash_dash_matches[0][1])
            last_year, last_month = int(slash_dash_matches[1][0]), int(slash_dash_matches[1][1])
            
            # æ§‹å»ºæ—¥æœŸ
            current_start = datetime(current_year, current_month, 1)
            current_end = (current_start + relativedelta(months=1)) - timedelta(days=1)
            last_start = datetime(last_year, last_month, 1)
            last_end = (last_start + relativedelta(months=1)) - timedelta(days=1)
            
            period_text = f"{current_year}å¹´{current_month:02d}æœˆ vs {last_year}å¹´{last_month:02d}æœˆ"
            
        elif len(slash_dash_matches) == 1:
            # åªæ‰¾åˆ°ä¸€å€‹ YYYY/MM æˆ– YYYY-MM æ ¼å¼ï¼Œä½œç‚ºç•¶å‰æœŸé–“ï¼Œä¸Šå€‹æœˆä½œç‚ºæ¯”è¼ƒæœŸé–“
            current_year, current_month = int(slash_dash_matches[0][0]), int(slash_dash_matches[0][1])
            
            current_start = datetime(current_year, current_month, 1)
            current_end = (current_start + relativedelta(months=1)) - timedelta(days=1)
            
            # è¨ˆç®—ä¸Šå€‹æœˆ
            last_start = (current_start - relativedelta(months=1))
            last_end = current_start - timedelta(days=1)
            
            period_text = f"{current_year}å¹´{current_month:02d}æœˆ vs ä¸Šæœˆ"
            
        else:
            # é¦–å…ˆå˜—è©¦åŒ¹é…ç´”å¹´ä»½æ ¼å¼ "2025å¹´"
            year_pattern = r'(\d{4})å¹´(?!\d{1,2}æœˆ|Q\d)'
            year_matches = re.findall(year_pattern, processed_query)
            
            if len(year_matches) >= 2:
                # æ‰¾åˆ°å…©å€‹å¹´ä»½ï¼Œç¬¬ä¸€å€‹ä½œç‚ºç•¶å‰æœŸé–“ï¼Œç¬¬äºŒå€‹ä½œç‚ºæ¯”è¼ƒæœŸé–“
                current_year = int(year_matches[0])
                last_year = int(year_matches[1])
                
                # æ§‹å»ºå¹´åº¦æ—¥æœŸç¯„åœ
                current_start = datetime(current_year, 1, 1)
                current_end = datetime(current_year, 12, 31)
                last_start = datetime(last_year, 1, 1)
                last_end = datetime(last_year, 12, 31)
                
                period_text = f"{current_year}å¹´ vs {last_year}å¹´"
                
            elif len(year_matches) == 1:
                # åªæ‰¾åˆ°ä¸€å€‹å¹´ä»½ï¼Œä½œç‚ºç•¶å‰æœŸé–“ï¼Œä¸Šä¸€å¹´ä½œç‚ºæ¯”è¼ƒæœŸé–“
                current_year = int(year_matches[0])
                
                current_start = datetime(current_year, 1, 1)
                current_end = datetime(current_year, 12, 31)
                
                # è¨ˆç®—ä¸Šä¸€å¹´
                last_start = datetime(current_year - 1, 1, 1)
                last_end = datetime(current_year - 1, 12, 31)
                
                period_text = f"{current_year}å¹´ vs å»å¹´"
                
            else:
                # åŒ¹é… "2025å¹´06æœˆ" æˆ– "2025å¹´6æœˆ" æ ¼å¼
                year_month_pattern = r'(\d{4})å¹´(\d{1,2})æœˆ'
                matches = re.findall(year_month_pattern, processed_query)
                
                if len(matches) >= 2:
                    # æ‰¾åˆ°å…©å€‹å¹´æœˆï¼Œç¬¬ä¸€å€‹ä½œç‚ºç•¶å‰æœŸé–“ï¼Œç¬¬äºŒå€‹ä½œç‚ºæ¯”è¼ƒæœŸé–“
                    current_year, current_month = int(matches[0][0]), int(matches[0][1])
                    last_year, last_month = int(matches[1][0]), int(matches[1][1])
                    
                    # æ§‹å»ºæ—¥æœŸ
                    current_start = datetime(current_year, current_month, 1)
                    current_end = (current_start + relativedelta(months=1)) - timedelta(days=1)
                    last_start = datetime(last_year, last_month, 1)
                    last_end = (last_start + relativedelta(months=1)) - timedelta(days=1)
                    
                    period_text = f"{current_year}å¹´{current_month:02d}æœˆ vs {last_year}å¹´{last_month:02d}æœˆ"
                    
                elif len(matches) == 1:
                    # åªæ‰¾åˆ°ä¸€å€‹å¹´æœˆï¼Œä½œç‚ºç•¶å‰æœŸé–“ï¼Œä¸Šå€‹æœˆä½œç‚ºæ¯”è¼ƒæœŸé–“
                    current_year, current_month = int(matches[0][0]), int(matches[0][1])
                    
                    current_start = datetime(current_year, current_month, 1)
                    current_end = (current_start + relativedelta(months=1)) - timedelta(days=1)
                    
                    # è¨ˆç®—ä¸Šå€‹æœˆ
                    last_start = (current_start - relativedelta(months=1))
                    last_end = current_start - timedelta(days=1)
                    
                    period_text = f"{current_year}å¹´{current_month:02d}æœˆ vs ä¸Šæœˆ"
                    
                elif "Q" in processed_query or "å­£" in processed_query:
                    # é¦–å…ˆå˜—è©¦è§£æç´”å­£åº¦æ ¼å¼ "Q1", "Q2" ç­‰
                    pure_quarter_pattern = r'Q(\d)(?!\d{4}å¹´)'
                    pure_quarter_matches = re.findall(pure_quarter_pattern, processed_query)
                    
                    if len(pure_quarter_matches) >= 2:
                        # æ‰¾åˆ°å…©å€‹ç´”å­£åº¦ï¼Œç¬¬ä¸€å€‹ä½œç‚ºç•¶å‰æœŸé–“ï¼Œç¬¬äºŒå€‹ä½œç‚ºæ¯”è¼ƒæœŸé–“
                        current_quarter = int(pure_quarter_matches[0])
                        last_quarter = int(pure_quarter_matches[1])
                        
                        # ä½¿ç”¨ç•¶å‰å¹´ä»½
                        current_year = today.year
                        last_year = today.year
                        
                        # è¨ˆç®—å­£åº¦é–‹å§‹æœˆä»½
                        current_start_month = 3 * (current_quarter - 1) + 1
                        last_start_month = 3 * (last_quarter - 1) + 1
                        
                        # æ§‹å»ºæ—¥æœŸ
                        current_start = datetime(current_year, current_start_month, 1)
                        current_end = (current_start + relativedelta(months=3)) - timedelta(days=1)
                        last_start = datetime(last_year, last_start_month, 1)
                        last_end = (last_start + relativedelta(months=3)) - timedelta(days=1)
                        
                        period_text = f"Q{current_quarter} vs Q{last_quarter}"
                        
                    elif len(pure_quarter_matches) == 1:
                        # åªæ‰¾åˆ°ä¸€å€‹ç´”å­£åº¦ï¼Œä½œç‚ºç•¶å‰æœŸé–“ï¼Œä¸Šå­£åº¦ä½œç‚ºæ¯”è¼ƒæœŸé–“
                        current_quarter = int(pure_quarter_matches[0])
                        current_year = today.year
                        
                        # è¨ˆç®—å­£åº¦é–‹å§‹æœˆä»½
                        current_start_month = 3 * (current_quarter - 1) + 1
                        current_start = datetime(current_year, current_start_month, 1)
                        current_end = (current_start + relativedelta(months=3)) - timedelta(days=1)
                        
                        # è¨ˆç®—ä¸Šå­£åº¦
                        if current_quarter == 1:
                            last_quarter = 4
                            last_year = current_year - 1
                        else:
                            last_quarter = current_quarter - 1
                            last_year = current_year
                        
                        last_start_month = 3 * (last_quarter - 1) + 1
                        last_start = datetime(last_year, last_start_month, 1)
                        last_end = (last_start + relativedelta(months=3)) - timedelta(days=1)
                        
                        period_text = f"Q{current_quarter} vs Q{last_quarter}"
                        
                    else:
                        # å˜—è©¦è§£æå…·é«”çš„å­£åº¦æ¯”è¼ƒæ ¼å¼
                        quarter_pattern = r'(\d{4})å¹´Q(\d)'
                        quarter_matches = re.findall(quarter_pattern, processed_query)
                        
                        # å˜—è©¦è§£æç›¸å°æ™‚é–“è¡¨é”
                        relative_pattern = r'(å»å¹´|å‰å¹´|ä»Šå¹´)Q(\d)'
                        relative_matches = re.findall(relative_pattern, processed_query)
                        
                        if len(quarter_matches) >= 2:
                            # æ‰¾åˆ°å…©å€‹å…·é«”å¹´ä»½çš„å­£åº¦ï¼Œç¬¬ä¸€å€‹ä½œç‚ºç•¶å‰æœŸé–“ï¼Œç¬¬äºŒå€‹ä½œç‚ºæ¯”è¼ƒæœŸé–“
                            current_year, current_quarter = int(quarter_matches[0][0]), int(quarter_matches[0][1])
                            last_year, last_quarter = int(quarter_matches[1][0]), int(quarter_matches[1][1])
                            
                            # è¨ˆç®—å­£åº¦é–‹å§‹æœˆä»½
                            current_start_month = 3 * (current_quarter - 1) + 1
                            last_start_month = 3 * (last_quarter - 1) + 1
                            
                            # æ§‹å»ºæ—¥æœŸ
                            current_start = datetime(current_year, current_start_month, 1)
                            current_end = (current_start + relativedelta(months=3)) - timedelta(days=1)
                            last_start = datetime(last_year, last_start_month, 1)
                            last_end = (last_start + relativedelta(months=3)) - timedelta(days=1)
                            
                            period_text = f"{current_year}å¹´Q{current_quarter} vs {last_year}å¹´Q{last_quarter}"
                            
                        elif len(quarter_matches) == 1 and len(relative_matches) >= 1:
                            # æ‰¾åˆ°ä¸€å€‹å…·é«”å¹´ä»½å­£åº¦å’Œä¸€å€‹ç›¸å°æ™‚é–“å­£åº¦
                            current_year, current_quarter = int(quarter_matches[0][0]), int(quarter_matches[0][1])
                            relative_time, last_quarter = relative_matches[0]
                            last_quarter = int(last_quarter)
                            
                            # è¨ˆç®—ç›¸å°å¹´ä»½
                            if relative_time == "å»å¹´":
                                last_year = current_year - 1
                            elif relative_time == "å‰å¹´":
                                last_year = current_year - 2
                            else:  # ä»Šå¹´
                                last_year = current_year
                            
                            # è¨ˆç®—å­£åº¦é–‹å§‹æœˆä»½
                            current_start_month = 3 * (current_quarter - 1) + 1
                            last_start_month = 3 * (last_quarter - 1) + 1
                            
                            # æ§‹å»ºæ—¥æœŸ
                            current_start = datetime(current_year, current_start_month, 1)
                            current_end = (current_start + relativedelta(months=3)) - timedelta(days=1)
                            last_start = datetime(last_year, last_start_month, 1)
                            last_end = (last_start + relativedelta(months=3)) - timedelta(days=1)
                            
                            period_text = f"{current_year}å¹´Q{current_quarter} vs {last_year}å¹´Q{last_quarter}"
                            
                        elif len(quarter_matches) == 1:
                            # åªæ‰¾åˆ°ä¸€å€‹å…·é«”å¹´ä»½å­£åº¦ï¼Œä½œç‚ºç•¶å‰æœŸé–“ï¼Œä¸Šå­£åº¦ä½œç‚ºæ¯”è¼ƒæœŸé–“
                            current_year, current_quarter = int(quarter_matches[0][0]), int(quarter_matches[0][1])
                            current_start_month = 3 * (current_quarter - 1) + 1
                            
                            current_start = datetime(current_year, current_start_month, 1)
                            current_end = (current_start + relativedelta(months=3)) - timedelta(days=1)
                            
                            # è¨ˆç®—ä¸Šå­£åº¦
                            if current_quarter == 1:
                                last_quarter = 4
                                last_year = current_year - 1
                            else:
                                last_quarter = current_quarter - 1
                                last_year = current_year
                            
                            last_start_month = 3 * (last_quarter - 1) + 1
                            last_start = datetime(last_year, last_start_month, 1)
                            last_end = (last_start + relativedelta(months=3)) - timedelta(days=1)
                            
                            period_text = f"{current_year}å¹´Q{current_quarter} vs {last_year}å¹´Q{last_quarter}"
                            
                            # ç¢ºä¿è¨­ç½®äº†æ‰€æœ‰å¿…è¦çš„è®Šæ•¸
                            print(f"   å­£åº¦æŸ¥è©¢è§£æå®Œæˆ: {current_year}å¹´Q{current_quarter}")
                            print(f"   ç•¶å‰æœŸé–“: {current_start} åˆ° {current_end}")
                            print(f"   æ¯”è¼ƒæœŸé–“: {last_start} åˆ° {last_end}")
                            
                        else:
                            # æ²’æœ‰æ‰¾åˆ°å…·é«”å­£åº¦æ ¼å¼ï¼Œä½¿ç”¨é è¨­çš„ç•¶å‰å­£åº¦ vs ä¸Šå­£åº¦
                            current_quarter_start_month = 3 * ((today.month - 1) // 3) + 1
                            current_start = today.replace(month=current_quarter_start_month, day=1)
                            current_end = (current_start + relativedelta(months=3)) - timedelta(days=1)
                            last_start = (current_start - relativedelta(months=3))
                            last_end = current_start - timedelta(days=1)
                            period_text = f"{current_start.year}å¹´Q{(current_start.month-1)//3+1} vs ä¸Šå­£"

        # é è¨­åˆ†æç¶­åº¦: ç”¢å“
        dimension = 'product'
        dimension_text = 'ç”¢å“'

        # æ ¹æ“šæŸ¥è©¢å…§å®¹åˆ¤æ–·åˆ†æç¶­åº¦
        if any(word in query for word in ['ç”¢å“', 'å•†å“', 'item', 'product']):
            dimension = 'product'
            dimension_text = 'ç”¢å“'
        elif any(word in query for word in ['æ¥­å‹™å“¡', 'éŠ·å”®å“¡', 'staff', 'sales']):
            dimension = 'staff'
            dimension_text = 'æ¥­å‹™å“¡'
        elif any(word in query for word in ['å®¢æˆ¶', 'customer', 'client']):
            dimension = 'customer'
            dimension_text = 'å®¢æˆ¶'
        elif any(word in query for word in ['åœ°å€', 'å€åŸŸ', 'region', 'area']):
            dimension = 'region'
            dimension_text = 'åœ°å€'

        parsed_result = {
            'current_start': current_start.strftime('%Y-%m-%d'),
            'current_end': current_end.strftime('%Y-%m-%d'),
            'last_start': last_start.strftime('%Y-%m-%d'),
            'last_end': last_end.strftime('%Y-%m-%d'),
            'period_text': period_text,
            'dimension': dimension,
            'dimension_text': dimension_text
        }
        
        print(f"   è§£æå®Œæˆï¼Œè¿”å›çµæœ:")
        print(f"     - current_start: {parsed_result['current_start']}")
        print(f"     - current_end: {parsed_result['current_end']}")
        print(f"     - last_start: {parsed_result['last_start']}")
        print(f"     - last_end: {parsed_result['last_end']}")
        print(f"     - period_text: {parsed_result['period_text']}")
        print(f"     - dimension: {parsed_result['dimension']}")
        print(f"     - dimension_text: {parsed_result['dimension_text']}")
        
        return parsed_result

    def analyze_query(self, query):
        """
        åˆ†æè‡ªç„¶èªè¨€æŸ¥è©¢ä¸¦è¿”å›çµæœ
        """
        print(f"\nğŸš€ é–‹å§‹åˆ†ææŸ¥è©¢: {query}")
        print(f"=" * 60)
        
        try:
            # å‹•æ…‹ç²å–ç¶­åº¦è³‡æ–™
            print(f"ğŸ” ç²å–ç¶­åº¦è³‡æ–™...")
            specific_customers = self._get_dimension_values('customer')
            specific_staff = self._get_dimension_values('staff')
            specific_products = self._get_dimension_values('product')
            specific_regions = self._get_dimension_values('region')
            
            print(f"   å®¢æˆ¶ç¶­åº¦: {len(specific_customers)} å€‹")
            print(f"   å“¡å·¥ç¶­åº¦: {len(specific_staff)} å€‹")
            print(f"   ç”¢å“ç¶­åº¦: {len(specific_products)} å€‹")
            print(f"   åœ°å€ç¶­åº¦: {len(specific_regions)} å€‹")
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºç‰¹å®šå®¢æˆ¶æŸ¥è©¢ï¼ˆåŒ…æ‹¬å­˜åœ¨çš„å’Œä¸å­˜åœ¨çš„å®¢æˆ¶ï¼‰
            if any(word in query for word in ['å®¢æˆ¶', 'customer', 'æ¶ˆè²»']):
                # æå–å¯èƒ½çš„å®¢æˆ¶åç¨±
                # åŒ¹é…ã€Œå®¢æˆ¶ã€å¾Œé¢çš„ä¸­æ–‡åç¨±ï¼Œä½†ä¸åŒ…å«ã€ŒéŠ·å”®é¡ã€ç­‰è©
                customer_pattern = r'å®¢æˆ¶\s*([\u4e00-\u9fa5]{2,4})(?=\s|éŠ·å”®é¡|æ¥­ç¸¾|$)'
                customer_matches = re.findall(customer_pattern, query)
                
                for match in customer_matches:
                    if match in specific_customers:
                        # å­˜åœ¨çš„å®¢æˆ¶
                        return self._analyze_specific_customer_query(query, match)
                    else:
                        # ä¸å­˜åœ¨çš„å®¢æˆ¶
                        return self._analyze_specific_customer_query(query, match)
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºç‰¹å®šæ¥­å‹™å“¡æŸ¥è©¢
            if any(word in query for word in ['æ¥­å‹™å“¡', 'éŠ·å”®å“¡', 'staff', 'æ¥­ç¸¾']):
                # æå–å¯èƒ½çš„æ¥­å‹™å“¡åç¨±
                staff_pattern = r'æ¥­å‹™å“¡\s*([\u4e00-\u9fa5]{2,4})(?=\s|æ¥­ç¸¾|$)'
                staff_matches = re.findall(staff_pattern, query)
                
                for match in staff_matches:
                    if match in specific_staff:
                        # å­˜åœ¨çš„æ¥­å‹™å“¡
                        return self._analyze_specific_staff_query(query, match)
                    else:
                        # ä¸å­˜åœ¨çš„æ¥­å‹™å“¡
                        return self._analyze_specific_staff_query(query, match)
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºç‰¹å®šç”¢å“æŸ¥è©¢
            if any(word in query for word in ['ç”¢å“', 'å•†å“', 'product']):
                # æå–å¯èƒ½çš„ç”¢å“åç¨±
                product_pattern = r'ç”¢å“\s*([\u4e00-\u9fa5]{2,10})(?=\s|éŠ·å”®é¡|$)'
                product_matches = re.findall(product_pattern, query)
                
                for match in product_matches:
                    if match in specific_products:
                        # å­˜åœ¨çš„ç”¢å“
                        return self._analyze_specific_product_query(query, match)
                    else:
                        # ä¸å­˜åœ¨çš„ç”¢å“
                        return self._analyze_specific_product_query(query, match)
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºç‰¹å®šåœ°å€æŸ¥è©¢
            if any(word in query for word in ['åœ°å€', 'å€åŸŸ', 'region', 'åœ°æ–¹']):
                # æå–å¯èƒ½çš„åœ°å€åç¨±
                region_pattern = r'åœ°å€\s*([\u4e00-\u9fa5]{2,4})(?=\s|éŠ·å”®é¡|$)'
                region_matches = re.findall(region_pattern, query)
                
                for match in region_matches:
                    if match in specific_regions:
                        # å­˜åœ¨çš„åœ°å€
                        return self._analyze_specific_region_query(query, match)
                    else:
                        # ä¸å­˜åœ¨çš„åœ°å€
                        return self._analyze_specific_region_query(query, match)
            
            # è§£ææŸ¥è©¢
            print(f"ğŸ” è§£ææŸ¥è©¢...")
            parsed = self._parse_query(query)
            print(f"   è§£æçµæœ: {parsed}")
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºå­£åº¦æŸ¥è©¢
            if "Q" in query and ("å­£" in query or "quarter" in query.lower()):
                print(f"ğŸ“Š ä½¿ç”¨å­£åº¦å°ˆç”¨æŸ¥è©¢...")
                result = self._analyze_quarter_query(parsed, query)
                print(f"âœ… å­£åº¦æŸ¥è©¢å®Œæˆï¼Œè¿”å›çµæœé•·åº¦: {len(str(result))}")
                return result
            else:
                print(f"ğŸ“Š ä½¿ç”¨ä¸€èˆ¬æœŸé–“æŸ¥è©¢...")
                result = self._analyze_period_query(parsed)
                print(f"âœ… æœŸé–“æŸ¥è©¢å®Œæˆï¼Œè¿”å›çµæœé•·åº¦: {len(str(result))}")
                return result
            
        except Exception as e:
            print(f"âŒ æŸ¥è©¢è§£æå¤±æ•—: {e}")
            return {
                'success': False,
                'error': f"æŸ¥è©¢è§£æå¤±æ•—: {str(e)}"
            }

    def _analyze_period_query(self, parsed):
        """åˆ†æä¸€èˆ¬æœŸé–“æŸ¥è©¢ - æ™ºèƒ½é¸æ“‡å‘é‡æˆ–SQLæŸ¥è©¢"""
        try:
            print(f"ğŸ” é–‹å§‹æœŸé–“æŸ¥è©¢åˆ†æ...")
            print(f"   è§£æçµæœ: {parsed}")
            
            # æš«æ™‚ç¦ç”¨å‘é‡æŸ¥è©¢ï¼Œç›´æ¥ä½¿ç”¨ SQL æŸ¥è©¢
            # å› ç‚ºå‘é‡æŸ¥è©¢æœ‰æ—¥æœŸæ ¼å¼å•é¡Œ
            print(f"ğŸ“Š ç›´æ¥ä½¿ç”¨ SQL æŸ¥è©¢åˆ†æ...")
            return self._perform_sql_period_analysis(parsed)
            
            # ä»¥ä¸‹æ˜¯åŸæœ¬çš„å‘é‡æŸ¥è©¢é‚è¼¯ï¼Œæš«æ™‚è¨»è§£
            # if hasattr(self.data_manager, 'vector_manager') and self.data_manager.vector_manager:
            #     # å˜—è©¦ä½¿ç”¨å‘é‡æœå°‹é€²è¡Œæ™ºèƒ½åˆ†æ
            #     vector_analysis = self._perform_vector_period_analysis(parsed)
            #     if vector_analysis['success']:
            #         return vector_analysis
            
            # # å¦‚æœå‘é‡æŸ¥è©¢å¤±æ•—æˆ–ä¸é©ç”¨ï¼Œå›é€€åˆ°å‚³çµ±SQLæŸ¥è©¢
            # return self._perform_sql_period_analysis(parsed)
            
        except Exception as e:
            print(f"âŒ æœŸé–“åˆ†æå¤±æ•—: {e}")
            return {
                'success': False,
                'error': f"æœŸé–“åˆ†æå¤±æ•—: {str(e)}"
            }
    
    def _perform_vector_period_analysis(self, parsed):
        """ä½¿ç”¨å‘é‡æœå°‹é€²è¡ŒæœŸé–“åˆ†æ"""
        try:
            # æ§‹å»ºèªç¾©æŸ¥è©¢
            semantic_query = self._build_semantic_period_query(parsed)
            
            # ä½¿ç”¨å‘é‡æœå°‹é€²è¡Œæ™ºèƒ½åˆ†æ
            vector_results = self._execute_vector_period_analysis(semantic_query, parsed)
            
            return {
                'success': True,
                'analysis_type': 'vector',
                'semantic_query': semantic_query,
                'vector_results': vector_results,
                'period_text': parsed.get('period_text', 'æœªçŸ¥æœŸé–“'),
                'current_dimension': parsed.get('dimension', 'æœªçŸ¥ç¶­åº¦'),
                'current_start': parsed.get('current_start', 'æœªçŸ¥'),
                'current_end': parsed.get('current_end', 'æœªçŸ¥'),
                'last_start': parsed.get('last_start', 'æœªçŸ¥'),
                'last_end': parsed.get('last_end', 'æœªçŸ¥')
            }
            
        except Exception as e:
            # self.logger.error(f"å‘é‡æœŸé–“åˆ†æå¤±æ•—: {e}")
            return {
                'success': False,
                'error': f"å‘é‡åˆ†æå¤±æ•—: {str(e)}"
            }
    
    def _perform_sql_period_analysis(self, parsed):
        """ä½¿ç”¨å‚³çµ±SQLé€²è¡ŒæœŸé–“åˆ†æ"""
        try:
            print(f"\nğŸ” é–‹å§‹åŸ·è¡Œ SQL æœŸé–“åˆ†æ...")
            print(f"   ç•¶å‰æœŸé–“: {parsed.get('current_start', 'æœªçŸ¥')} åˆ° {parsed.get('current_end', 'æœªçŸ¥')}")
            print(f"   æ¯”è¼ƒæœŸé–“: {parsed.get('last_start', 'æœªçŸ¥')} åˆ° {parsed.get('last_end', 'æœªçŸ¥')}")
            print(f"   åˆ†æç¶­åº¦: {parsed.get('dimension', 'æœªçŸ¥')}")
            
            # åŸ·è¡ŒæœŸé–“æ¯”è¼ƒ
            print(f"ğŸ“Š åŸ·è¡ŒæœŸé–“æ¯”è¼ƒæŸ¥è©¢...")
            period_comparison = self.data_manager.get_period_comparison(
                parsed.get('current_start', '2025-01-01'), parsed.get('current_end', '2025-12-31'),
                parsed.get('last_start', '2024-01-01'), parsed.get('last_end', '2024-12-31')
            )
            
            print(f"ğŸ“Š æœŸé–“æ¯”è¼ƒæŸ¥è©¢çµæœ:")
            print(f"   æŸ¥è©¢çµæœé¡å‹: {type(period_comparison)}")
            print(f"   æŸ¥è©¢çµæœæ˜¯å¦ç‚ºç©º: {period_comparison.empty if hasattr(period_comparison, 'empty') else 'N/A'}")
            print(f"   æŸ¥è©¢çµæœå…§å®¹: {period_comparison}")
            
            if period_comparison.empty:
                print("âŒ æœŸé–“æ¯”è¼ƒæŸ¥è©¢è¿”å›ç©ºçµæœ")
                return {
                    'success': False,
                    'error': 'æœŸé–“æ¯”è¼ƒæŸ¥è©¢ç„¡çµæœ'
                }
            
            # åŸ·è¡Œä¸»ç¶­åº¦è²¢ç»åº¦åˆ†æ
            print(f"ğŸ“ˆ åŸ·è¡Œä¸»ç¶­åº¦è²¢ç»åº¦åˆ†æ...")
            driver_analysis = self.data_manager.get_driver_analysis(
                parsed.get('current_start', '2025-01-01'), parsed.get('current_end', '2025-12-31'),
                parsed.get('last_start', '2024-01-01'), parsed.get('last_end', '2024-12-31'),
                parsed.get('dimension', 'product')
            )
            
            print(f"ğŸ“ˆ ä¸»ç¶­åº¦è²¢ç»åº¦åˆ†æçµæœ:")
            print(f"   åˆ†æçµæœé¡å‹: {type(driver_analysis)}")
            print(f"   åˆ†æçµæœæ˜¯å¦ç‚ºç©º: {driver_analysis.empty if hasattr(driver_analysis, 'empty') else 'N/A'}")
            print(f"   åˆ†æçµæœå…§å®¹: {driver_analysis}")
            
            if driver_analysis.empty:
                print("âš ï¸  ä¸»ç¶­åº¦è²¢ç»åº¦åˆ†æè¿”å›ç©ºçµæœ")
                driver_analysis = pd.DataFrame()
            
            # ç²å–å¯ç”¨çš„ drill down ç¶­åº¦
            print(f"ğŸ” ç²å–å¯ç”¨çš„ drill down ç¶­åº¦...")
            available_dimensions = self.data_manager.get_available_dimensions(parsed.get('dimension', 'product'))
            print(f"   å¯ç”¨ç¶­åº¦: {available_dimensions}")

            # æ–°å¢ï¼šå¤šç¶­åº¦åƒè€ƒåˆ†æ
            print(f"ğŸ” åŸ·è¡Œå¤šç¶­åº¦åƒè€ƒåˆ†æ...")
            other_dimension_reference = []
            for dim_key, dim_name in available_dimensions.items():
                try:
                    print(f"   åˆ†æ {dim_key} ç¶­åº¦...")
                    other_driver = self.data_manager.get_driver_analysis(
                        parsed.get('current_start', '2025-01-01'), parsed.get('current_end', '2025-12-31'),
                        parsed.get('last_start', '2024-01-01'), parsed.get('last_end', '2024-12-31'),
                        dim_key
                    )
                    # åªå–å‰3å
                    top3 = other_driver.sort_values('å·®ç•°', key=abs, ascending=False).head(3)
                    if not top3.empty:
                        dim_summary = f"<b>{dim_name} ç¶­åº¦å½±éŸ¿ï¼š</b> "
                        for _, row in top3.iterrows():
                            diff = row['å·®ç•°']
                            sign = '+' if diff > 0 else ''
                            dim_summary += f"{row['åˆ†æç¶­åº¦']}ï¼ˆå·®ç•°ï¼š{sign}{diff:,.0f}å…ƒï¼‰; "
                        other_dimension_reference.append(dim_summary)
                        print(f"     {dim_key} ç¶­åº¦åˆ†æå®Œæˆï¼Œæ‰¾åˆ° {len(top3)} ç­†æ•¸æ“š")
                    else:
                        print(f"     {dim_key} ç¶­åº¦åˆ†æè¿”å›ç©ºçµæœ")
                except Exception as e:
                    print(f"     {dim_key} ç¶­åº¦åˆ†æå¤±æ•—: {e}")
                    continue
            other_dimension_reference_text = '<br>'.join(other_dimension_reference) if other_dimension_reference else ''

            # è¨ˆç®—ç¸½è¨ˆ
            print(f"ğŸ’° é–‹å§‹è¨ˆç®—éŠ·å”®æ•¸æ“š...")
            current_sales = period_comparison['current_period_sales'].iloc[0]
            last_sales = period_comparison['last_period_sales'].iloc[0]
            diff = current_sales - last_sales
            
            print(f"ğŸ’° éŠ·å”®æ•¸æ“šè¨ˆç®—çµæœ:")
            print(f"   ç•¶æœŸéŠ·å”®: {current_sales:,.2f} å…ƒ")
            print(f"   å‰æœŸéŠ·å”®: {last_sales:,.2f} å…ƒ")
            print(f"   å·®ç•°: {diff:,.2f} å…ƒ")
            
            # è¨ˆç®—ç™¾åˆ†æ¯”å·®ç•°
            percentage_diff = 0
            if last_sales != 0:
                percentage_diff = (diff / last_sales) * 100
            elif diff > 0:
                percentage_diff = float('inf')
            elif diff < 0:
                percentage_diff = float('-inf')
            
            print(f"   ç™¾åˆ†æ¯”å·®ç•°: {percentage_diff:.1f}%")
            
            # ç”Ÿæˆåˆ†æç¸½çµå ±å‘Š (NLG)
            print(f"ğŸ“ é–‹å§‹ç”Ÿæˆåˆ†æç¸½çµå ±å‘Š...")
            summary = self._generate_analysis_summary(
                current_sales, last_sales, diff, percentage_diff,
                driver_analysis.to_dict('records'), parsed['dimension_text'],
                parsed['period_text'], other_dimension_reference_text
            )
            
            print(f"ğŸ“‹ åˆ†æç¸½çµå ±å‘Šç”Ÿæˆå®Œæˆ:")
            print(f"   å ±å‘Šé•·åº¦: {len(summary)} å­—å…ƒ")
            print(f"   å ±å‘Šé è¦½: {summary[:200]}...")
            
            print(f"âœ… SQL æœŸé–“åˆ†æåŸ·è¡Œå®Œæˆ")
            print(f"   è¿”å›æ•¸æ“šçµæ§‹:")
            print(f"     - success: True")
            print(f"     - current_sales: {current_sales}")
            print(f"     - last_sales: {last_sales}")
            print(f"     - diff: {diff}")
            print(f"     - percentage_diff: {percentage_diff}")
            print(f"     - summary: {len(summary)} å­—å…ƒ")
            print(f"     - driver_data: {len(driver_analysis.to_dict('records'))} ç­†")
            
            return {
                'success': True,
                'analysis_type': 'sql',
                'current_sales': current_sales,
                'last_sales': last_sales,
                'diff': diff,
                'percentage_diff': percentage_diff,
                'summary': summary,
                'period_text': parsed.get('period_text', 'æœªçŸ¥æœŸé–“'),
                'driver_data': driver_analysis.to_dict('records'),
                'dimension_text': parsed.get('dimension_text', 'æœªçŸ¥ç¶­åº¦'),
                'current_dimension': parsed.get('dimension', 'product'),
                'available_dimensions': available_dimensions,
                'current_start': parsed.get('current_start', 'æœªçŸ¥'),
                'current_end': parsed.get('current_end', 'æœªçŸ¥'),
                'last_start': parsed.get('last_start', 'æœªçŸ¥'),
                'last_end': parsed.get('last_end', 'æœªçŸ¥'),
                'other_dimension_reference': other_dimension_reference_text
            }
        except Exception as e:
            return {
                'success': False,
                'error': f"æœŸé–“åˆ†æå¤±æ•—: {str(e)}"
            }

    def _analyze_quarter_query(self, parsed, query):
        """åˆ†æå­£åº¦æŸ¥è©¢"""
        try:
            # å¾æŸ¥è©¢ä¸­æå–å­£åº¦ä¿¡æ¯
            quarter_info = self._extract_quarter_info(query)
            if not quarter_info:
                return {
                    'success': False,
                    'error': "ç„¡æ³•è§£æå­£åº¦æŸ¥è©¢æ ¼å¼ï¼Œè«‹ä½¿ç”¨å¦‚ '2025å¹´Q1' çš„æ ¼å¼"
                }
            
            current_year, current_quarter = quarter_info['current']
            compare_year, compare_quarter = quarter_info['compare']
            
            # ç²å–å­£åº¦æ•¸æ“š
            quarter_data = self.data_manager.get_quarter_comparison(
                current_year, current_quarter, compare_year, compare_quarter
            )
            
            # ç²å–å­£åº¦è²¢ç»åº¦åˆ†æ
            driver_analysis = self.data_manager.get_quarter_driver_analysis(
                current_year, current_quarter, parsed['dimension']
            )
            
            # è¨ˆç®—å·®ç•°
            current_sales = quarter_data[quarter_data['year'] == current_year]['total_sales'].iloc[0]
            compare_sales = quarter_data[quarter_data['year'] == compare_year]['total_sales'].iloc[0]
            diff = current_sales - compare_sales
            
            # è¨ˆç®—ç™¾åˆ†æ¯”å·®ç•°
            percentage_diff = 0
            if compare_sales != 0:
                percentage_diff = (diff / compare_sales) * 100
            elif diff > 0:
                percentage_diff = float('inf')
            elif diff < 0:
                percentage_diff = float('-inf')
            
            # ç”Ÿæˆå­£åº¦åˆ†æç¸½çµ
            summary = self._generate_quarter_summary(
                current_year, current_quarter, compare_year, compare_quarter,
                current_sales, compare_sales, diff, percentage_diff,
                driver_analysis.to_dict('records'), parsed['dimension_text']
            )
            
            return {
                'success': True,
                'current_sales': current_sales,
                'last_sales': compare_sales,
                'diff': diff,
                'percentage_diff': percentage_diff,
                'summary': summary,
                'period_text': f"{current_year}å¹´Q{current_quarter} vs {compare_year}å¹´Q{compare_quarter}",
                'driver_data': driver_analysis.to_dict('records'),
                'dimension_text': parsed.get('dimension_text', 'æœªçŸ¥ç¶­åº¦'),
                'current_dimension': parsed.get('dimension', 'product'),
                'available_dimensions': self.data_manager.get_available_dimensions(parsed.get('dimension', 'product')),
                'current_start': parsed.get('current_start', 'æœªçŸ¥'),
                'current_end': parsed.get('current_end', 'æœªçŸ¥'),
                'last_start': parsed.get('last_start', 'æœªçŸ¥'),
                'last_end': parsed.get('last_end', 'æœªçŸ¥')
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f"å­£åº¦åˆ†æå¤±æ•—: {str(e)}"
            }

    def _extract_quarter_info(self, query):
        """å¾æŸ¥è©¢ä¸­æå–å­£åº¦ä¿¡æ¯"""
        
        # åŒ¹é…å…·é«”å¹´ä»½çš„å­£åº¦
        quarter_pattern = r'(\d{4})å¹´Q(\d)'
        quarter_matches = re.findall(quarter_pattern, query)
        
        # åŒ¹é…ç›¸å°æ™‚é–“çš„å­£åº¦
        relative_pattern = r'(å»å¹´|å‰å¹´|ä»Šå¹´)Q(\d)'
        relative_matches = re.findall(relative_pattern, query)
        
        if len(quarter_matches) >= 2:
            # å…©å€‹å…·é«”å¹´ä»½å­£åº¦
            current_year, current_quarter = int(quarter_matches[0][0]), int(quarter_matches[0][1])
            compare_year, compare_quarter = int(quarter_matches[1][0]), int(quarter_matches[1][1])
            return {
                'current': (current_year, current_quarter),
                'compare': (compare_year, compare_quarter)
            }
        elif len(quarter_matches) == 1 and len(relative_matches) >= 1:
            # ä¸€å€‹å…·é«”å¹´ä»½å­£åº¦å’Œä¸€å€‹ç›¸å°æ™‚é–“å­£åº¦
            current_year, current_quarter = int(quarter_matches[0][0]), int(quarter_matches[0][1])
            relative_time, compare_quarter = relative_matches[0]
            compare_quarter = int(compare_quarter)
            
            if relative_time == "å»å¹´":
                compare_year = current_year - 1
            elif relative_time == "å‰å¹´":
                compare_year = current_year - 2
            else:  # ä»Šå¹´
                compare_year = current_year
                
            return {
                'current': (current_year, current_quarter),
                'compare': (compare_year, compare_quarter)
            }
        elif len(quarter_matches) == 1:
            # åªæœ‰ä¸€å€‹å­£åº¦ï¼Œèˆ‡ä¸Šå­£åº¦æ¯”è¼ƒ
            current_year, current_quarter = int(quarter_matches[0][0]), int(quarter_matches[0][1])
            
            if current_quarter == 1:
                compare_quarter = 4
                compare_year = current_year - 1
            else:
                compare_quarter = current_quarter - 1
                compare_year = current_year
                
            return {
                'current': (current_year, current_quarter),
                'compare': (compare_year, compare_quarter)
            }
        
        return None

    def _generate_quarter_summary(self, current_year, current_quarter, compare_year, compare_quarter,
                                current_sales, compare_sales, diff, percentage_diff, driver_data, dimension_text):
        """ç”Ÿæˆå­£åº¦åˆ†æç¸½çµ"""
        def format_currency(amount):
            return f"{amount:,.0f}"
        
        # åˆ¤æ–·æ¥­ç¸¾è¡¨ç¾
        if diff > 0:
            performance = "æˆé•·"
            emoji = "ğŸ“ˆ"
        elif diff < 0:
            performance = "ä¸‹æ»‘"
            emoji = "ğŸ“‰"
        else:
            performance = "æŒå¹³"
            emoji = "â¡ï¸"
        
        summary = f"{emoji} {current_year}å¹´ç¬¬{current_quarter}å­£åº¦ vs {compare_year}å¹´ç¬¬{compare_quarter}å­£åº¦æ¥­ç¸¾{performance}ï¼Œ"
        summary += f"æœ¬æœŸéŠ·å”®é¡ç‚º {format_currency(current_sales)} å…ƒï¼Œ"
        summary += f"è¼ƒ{compare_year}å¹´ç¬¬{compare_quarter}å­£åº¦ {format_currency(compare_sales)} å…ƒ"
        
        if diff > 0:
            summary += f"å¢åŠ  {format_currency(diff)} å…ƒï¼ˆ+{percentage_diff:.1f}%ï¼‰"
        elif diff < 0:
            summary += f"æ¸›å°‘ {format_currency(abs(diff))} å…ƒï¼ˆ{percentage_diff:.1f}%ï¼‰"
        else:
            summary += "ç„¡è®ŠåŒ–"
        
        summary += "ã€‚<br><br>"
        
        # ä¸»è¦è²¢ç»åˆ†æ
        if driver_data:
            summary += "ğŸ“Š <strong>ä¸»è¦è²¢ç»åˆ†æï¼š</strong>"
            top_contributor = driver_data[0]
            summary += f"<strong>{top_contributor['åˆ†æç¶­åº¦']}</strong>è²¢ç»äº† {format_currency(top_contributor['å­£åº¦éŠ·å”®é¡'])} å…ƒ"
            
            if len(driver_data) > 1:
                second_contributor = driver_data[1]
                summary += f"ï¼Œ<strong>{second_contributor['åˆ†æç¶­åº¦']}</strong>è²¢ç»äº† {format_currency(second_contributor['å­£åº¦éŠ·å”®é¡'])} å…ƒ"
            
            summary += "<br><br>"
        
        # å»ºè­°
        summary += "ğŸ’¡ <strong>å»ºè­°ï¼š</strong>"
        if diff > 0:
            summary += "æŒçºŒé—œæ³¨è¡¨ç¾å„ªç•°çš„é …ç›®ï¼Œå¯è€ƒæ…®æ“´å¤§ç›¸é—œæ¥­å‹™ã€‚"
        else:
            summary += "é‡å°è¡¨ç¾ä¸‹æ»‘çš„é …ç›®åˆ¶å®šæ”¹å–„è¨ˆåŠƒï¼ŒåŠ å¼·è¡ŒéŠ·æ¨å»£ã€‚"
        
        return summary

    def _extract_other_dimension_focus(self, other_dimension_reference):
        """
        å¾å…¶ä»–ç¶­åº¦åƒè€ƒåˆ†æå­—ä¸²ä¸­ï¼Œèƒå–æ¯å€‹ç¶­åº¦æœ€å¤§æ­£/è² è²¢ç»è€…ï¼Œå›å‚³æ¢åˆ—æ‘˜è¦ï¼ˆæ¢åˆ—æ ¼å¼ï¼‰
        """
        focus_lines = []
        if not other_dimension_reference:
            return ''
        for line in other_dimension_reference.split('<br>'):
            m = re.match(r'(.*?) ç¶­åº¦å½±éŸ¿ï¼š (.*)', line)
            if m:
                dim, items = m.groups()
                pairs = re.findall(r'([\w\u4e00-\u9fa5]+)ï¼ˆå·®ç•°ï¼š([+-]?[\d,]+)å…ƒï¼‰', items)
                pairs = [(name, int(val.replace(',', ''))) for name, val in pairs]
                if pairs:
                    max_pos = max(pairs, key=lambda x: x[1])
                    max_neg = min(pairs, key=lambda x: x[1])
                    line_str = f"- {dim}ï¼š"
                    if max_neg[1] < 0:
                        line_str += f"æœ€å¤§è² è²¢ç» {max_neg[0]}ï¼ˆ{max_neg[1]:,}å…ƒï¼‰ï¼›"
                    if max_pos[1] > 0:
                        line_str += f"æœ€å¤§æ­£è²¢ç» {max_pos[0]}ï¼ˆ+{max_pos[1]:,}å…ƒï¼‰"
                    focus_lines.append(line_str)
        return '\n'.join(focus_lines)

    def _extract_focus_items(self, other_dimension_reference):
        """
        å¾å…¶ä»–ç¶­åº¦åƒè€ƒåˆ†æå­—ä¸²ä¸­ï¼Œå±•é–‹æ¯å€‹ç¶­åº¦çš„æ‰€æœ‰é‡é»æ¢ç›®ï¼Œå›å‚³æ¢åˆ—æ¸…å–®ï¼ˆæ¯ä¸€æ¢ç‚ºä¸‰è¡Œæ ¼å¼ï¼Œè®“ AI å¡«ç©ºï¼‰
        """
        items = []
        if not other_dimension_reference:
            return []
        for line in other_dimension_reference.split('<br>'):
            m = re.match(r'(.*?) ç¶­åº¦å½±éŸ¿ï¼š (.*)', line)
            if m:
                dim, content = m.groups()
                pairs = re.findall(r'([\w\u4e00-\u9fa5]+)ï¼ˆå·®ç•°ï¼š([+-]?[\d,]+)å…ƒï¼‰', content)
                for name, val in pairs:
                    items.append(f'- {dim}ï¼š{name}ï¼ˆ{val}å…ƒï¼‰\n  åŸå› ï¼š\n  å»ºè­°ï¼š')
        return items

    def chat_with_ai(self, message, analysis_context=None, chat_history=None):
        """
        æ™ºæ…§åˆ†æåŠ©æ‰‹èˆ‡ç”¨æˆ¶å°è©±
        å…·å‚™ä»¥ä¸‹ç‰¹è‰²ï¼š
        1. æ•¸æ“šåˆ†æå°ˆå®¶è§’è‰²
        2. å•†æ¥­é¡§å•è§’è‰²
        3. ç­–ç•¥å»ºè­°è€…è§’è‰²
        """
        # è¨­å®š AI åŠ©æ‰‹çš„è§’è‰²å’Œå€‹æ€§
        ai_role = {
            'name': 'æ¥­å‹™æ™ºæ…§é¡§å• - BI Expert',
            'expertise': ['æ•¸æ“šåˆ†æ', 'æ¥­å‹™è«®è©¢', 'ç­–ç•¥è¦åŠƒ', 'ç¸¾æ•ˆæ”¹å–„'],
            'personality': 'å°ˆæ¥­ã€ç²¾ç¢ºã€ç©æ¥µã€å…·å»ºè¨­æ€§',
            'communication_style': 'æ¸…æ™°ã€é‚è¼¯æ€§å¼·ã€æ³¨é‡å¯¦ç”¨æ€§'
        }
        try:
            import google.generativeai as genai
            import os
            # è¨­å®š Gemini API Keyï¼ˆè«‹ç¢ºä¿ç’°å¢ƒè®Šæ•¸å·²è¨­å®šï¼‰
            api_key = os.getenv('GEMINI_API_KEY')
            if not api_key:
                return {
                    'success': False,
                    'error': 'Gemini API Key æœªè¨­å®šï¼Œè«‹è¨­å®š GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸'
                }
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel('gemini-1.5-pro')

            # æ§‹å»ºèŠå¤©ä¸Šä¸‹æ–‡
            context_parts = []
            focus_items = []
            if analysis_context:
                context_parts.append(f"åˆ†ææœŸé–“ï¼š{analysis_context.get('period_text', 'N/A')}")
                context_parts.append(f"ç•¶æœŸéŠ·å”®ï¼š{analysis_context.get('current_sales', 0):,.0f} å…ƒ")
                context_parts.append(f"å‰æœŸéŠ·å”®ï¼š{analysis_context.get('last_sales', 0):,.0f} å…ƒ")
                context_parts.append(f"å·®ç•°ï¼š{analysis_context.get('diff', 0):,.0f} å…ƒ")
                context_parts.append(f"ç™¾åˆ†æ¯”å·®ç•°ï¼š{analysis_context.get('percentage_diff', 0):.1f}%")
                context_parts.append(f"åˆ†æç¶­åº¦ï¼š{analysis_context.get('dimension_text', 'N/A')}")
                if analysis_context.get('driver_data'):
                    top_contributors = []
                    for item in analysis_context['driver_data'][:3]:
                        if item['å·®ç•°'] > 0:
                            top_contributors.append(f"{item['åˆ†æç¶­åº¦']}(+{item['å·®ç•°']:,.0f})")
                        else:
                            top_contributors.append(f"{item['åˆ†æç¶­åº¦']}({item['å·®ç•°']:,.0f})")
                    context_parts.append(f"ä¸»è¦è²¢ç»è€…ï¼š{', '.join(top_contributors)}")
                if analysis_context.get('other_dimension_reference'):
                    focus_items = self._extract_focus_items(analysis_context['other_dimension_reference'])
                    context_parts.append(f"å…¶ä»–ç¶­åº¦åƒè€ƒåˆ†æï¼š{analysis_context['other_dimension_reference']}")

            # ====== æ–°å¢ï¼šæ¢ç›®èˆ‡æ ¼å¼ç¯„ä¾‹ç›´æ¥æ’å…¥ prompt æœ€å‰æ–¹ ======
            focus_block = ''
            # ç´°ç¯€è¿½å•åˆ¤æ–·ï¼ˆæœ€é«˜å„ªå…ˆï¼Œæ“´å……å‹•ä½œå‹/æ“ä½œå‹èªæ„ï¼‰
            detail_keywords = [
                'é‡é»', 'ç´°ç¯€', 'æ­¥é©Ÿ', 'æµç¨‹', 'ç¯„ä¾‹', 'å…§å®¹', 'å¦‚ä½•åŸ·è¡Œ', 'æ€éº¼åš', 'æ“ä½œæ–¹å¼', 'èªªæ˜', 'å±•é–‹èªªæ˜',
                'å¦‚ä½•é€²è¡Œ', 'å¦‚ä½•äº¤æµ', 'å¦‚ä½•èˆ‡', 'æˆ‘å¦‚ä½•', 'æˆ‘è©²æ€éº¼', 'è«‹çµ¦æˆ‘', 'è«‹å•æ€éº¼', 'è«‹å•å¦‚ä½•', 'è«‹çµ¦æˆ‘æ–¹æ³•', 'è«‹çµ¦æˆ‘æ­¥é©Ÿ', 'æˆ‘å¦‚ä½•é€²è¡Œ', 'æˆ‘å¦‚ä½•èˆ‡', 'æˆ‘è©²å¦‚ä½•', 'æˆ‘è©²å¦‚ä½•èˆ‡', 'è«‹çµ¦æˆ‘å»ºè­°', 'è«‹çµ¦æˆ‘å…·é«”æ–¹æ³•', 'è«‹çµ¦æˆ‘å…·é«”æ­¥é©Ÿ'
            ]
            is_detail_followup = any(kw in message for kw in detail_keywords) or \
                message.strip().startswith(('å¦‚ä½•', 'æ€éº¼', 'æˆ‘è©²æ€éº¼', 'æˆ‘å¦‚ä½•', 'è«‹çµ¦æˆ‘', 'è«‹å•æ€éº¼', 'è«‹å•å¦‚ä½•'))
            if is_detail_followup:
                focus_block = f"è«‹é‡å°ã€Œ{message}ã€çµ¦å‡ºè©³ç´°æ­¥é©Ÿã€æ–¹æ³•æˆ–å»ºè­°ï¼Œå‹™å¿…å…·é«”å¯åŸ·è¡Œï¼Œä¸éœ€å†åˆ†æå…¶ä»–å°è±¡ã€‚"
            else:
                # summary åˆ¤æ–·
                summary_keywords = [
                    'æ¥­ç¸¾', 'ç¸½é«”', 'æ•´é«”', 'ä¸»è¦è²¢ç»', 'åˆ†æ', 'ä¸‹æ»‘', 'æˆé•·', 'æ¯”è¼ƒ', 'vs', 'å·®ç•°', 'ç¸½çµ', 'éŠ·å”®é¡', 'ç‡Ÿæ”¶', 'è¡¨ç¾', 'è¶¨å‹¢'
                ]
                summary_patterns = [
                    r'\d{4}å¹´\d{1,2}æœˆ ?vs ?\d{4}å¹´\d{1,2}æœˆ',
                    r'\d{4}å¹´Q\d ?vs ?\d{4}å¹´Q\d',
                    r'\d{4}/\d{1,2} ?vs ?\d{4}/\d{1,2}',
                    r'\d{4}-\d{1,2} ?vs ?\d{4}-\d{1,2}'
                ]
                is_summary_focus = any(kw in message for kw in summary_keywords)
                for pat in summary_patterns:
                    if re.search(pat, message):
                        is_summary_focus = True
                # focus_keywords: è‡ªå‹•å¾ focus_items æ¢åˆ—ä¸­æå–æ‰€æœ‰å°è±¡åç¨±
                focus_keywords = []
                for item in focus_items:
                    m = re.match(r'- .+?ï¼š(.+?)ï¼ˆ', item)
                    if m:
                        focus_keywords.append(m.group(1))
                # å–®ä¸€å°è±¡åˆ¤æ–·
                is_single_focus = False
                matched_keywords = [kw for kw in focus_keywords if kw in message]
                if len(matched_keywords) == 1:
                    is_single_focus = True
                improvement_keywords = ['å»ºè­°', 'å¦‚ä½•æ”¹å–„', 'æ€éº¼åš', 'è§£æ±ºæ–¹æ¡ˆ', 'æå‡', 'å„ªåŒ–', 'å…·é«”æªæ–½', 'æ”¹å–„æ–¹å¼', 'æ”¹é€²', 'å¦‚ä½•è™•ç†', 'å¦‚ä½•è§£æ±º']
                is_improvement_focus = any(kw in message for kw in improvement_keywords)
                if is_summary_focus and focus_items:
                    focus_block = (
                        "è«‹é‡å°ä¸‹åˆ—æ¢ç›®ï¼Œä¾åºé€é»å›è¦†ï¼Œæ¯ä¸€é»éƒ½è¦æ˜ç¢ºèªªæ˜åŸå› èˆ‡å…·é«”å»ºè­°ï¼Œè«‹å‹¿æ³›æ³›è€Œè«‡ã€‚è«‹å‹™å¿…ä¾ç…§ä¸‹æ–¹æ ¼å¼åˆ†è¡Œå¡«å¯«ï¼š\n"
                        "- æ¥­å‹™å“¡ï¼šç‹å°æ˜ï¼ˆ-951,772å…ƒï¼‰\n  åŸå› ï¼š...\n  å»ºè­°ï¼š...\n"
                        "- å®¢æˆ¶ï¼šé™³å…ˆç”Ÿï¼ˆ-349,591å…ƒï¼‰\n  åŸå› ï¼š...\n  å»ºè­°ï¼š...\n"
                        "- åœ°å€ï¼šåŒ—å€ï¼ˆ-583,869å…ƒï¼‰\n  åŸå› ï¼š...\n  å»ºè­°ï¼š...\n\n"
                        + '\n'.join(focus_items) + '\n\n'
                    )
                elif is_single_focus:
                    focus_block = f"è«‹é‡å°ã€Œ{matched_keywords[0]}ã€é€²è¡Œæ·±å…¥åˆ†æï¼Œèªªæ˜åŸå› èˆ‡å…·é«”å»ºè­°ã€‚"
                elif is_improvement_focus:
                    focus_block = "è«‹é‡å°ç”¨æˆ¶æå‡ºçš„å…·é«”æ”¹å–„éœ€æ±‚ï¼Œçµ¦å‡ºè©³ç´°å¯åŸ·è¡Œçš„å»ºè­°èˆ‡èªªæ˜ã€‚"
                else:
                    focus_block = "è«‹æ ¹æ“šç”¨æˆ¶å•é¡Œï¼Œçµ¦å‡ºå°ˆæ¥­ä¸”å…·é«”çš„åˆ†æèˆ‡å»ºè­°ã€‚"
            # ====== END ======

            # æ§‹å»ºå®Œæ•´çš„æç¤ºè©
            system_prompt = f"""
{focus_block}ä½ æ˜¯ä¸€ä½è³‡æ·±çš„ç¶“ç‡Ÿåˆ†æå°ˆå®¶ï¼Œæ“æœ‰è±å¯Œçš„å•†æ¥­é¡§å•ç¶“é©—ã€‚ä½ çš„å°ˆé•·åŒ…æ‹¬ï¼š

1. **æ•¸æ“šè§£è®€èƒ½åŠ›**ï¼šèƒ½å¤ æ·±å…¥åˆ†æéŠ·å”®æ•¸æ“šèƒŒå¾Œçš„å•†æ¥­æ„ç¾©
2. **ç­–ç•¥è¦åŠƒèƒ½åŠ›**ï¼šæä¾›å…·é«”å¯åŸ·è¡Œçš„æ”¹å–„å»ºè­°å’Œç­–ç•¥æ–¹æ¡ˆ
3. **æºé€šè¡¨é”èƒ½åŠ›**ï¼šç”¨å£èªåŒ–ã€æ˜“æ‡‚çš„æ–¹å¼è§£é‡‹è¤‡é›œçš„å•†æ¥­æ¦‚å¿µ
4. **å¯¦å‹™ç¶“é©—**ï¼šçµåˆç†è«–èˆ‡å¯¦å‹™ï¼Œæä¾›å¯¦ç”¨çš„å»ºè­°

ç•¶å‰åˆ†æèƒŒæ™¯ï¼š
{chr(10).join(context_parts) if context_parts else 'ç„¡ç‰¹å®šåˆ†æèƒŒæ™¯'}

è«‹ä»¥ç¶“ç‡Ÿåˆ†æå°ˆå®¶çš„èº«ä»½å›ç­”ç”¨æˆ¶å•é¡Œï¼Œè¦æ±‚ï¼š
1. **å£èªåŒ–è¡¨é”**ï¼šç”¨ç°¡å–®æ˜“æ‡‚çš„èªè¨€è§£é‡‹è¤‡é›œæ¦‚å¿µ
2. **å…·é«”å»ºè­°**ï¼šæä¾›å¯åŸ·è¡Œçš„å…·é«”æ”¹å–„æ–¹æ¡ˆ
3. **å°ˆæ¥­åˆ†æ**ï¼šåŸºæ–¼æ•¸æ“šæä¾›å°ˆæ¥­çš„å•†æ¥­æ´å¯Ÿ
4. **äº’å‹•äº¤æµ**ï¼šé¼“å‹µç”¨æˆ¶æå•ï¼Œå»ºç«‹è‰¯å¥½çš„å°è©±æ°›åœ
5. **å¯¦ç”¨å°å‘**ï¼šé‡é»æ”¾åœ¨å¯¦éš›å¯æ‡‰ç”¨çš„å»ºè­°ä¸Š
6. **ä¸­æ–‡å›ç­”**ï¼šå…¨ç¨‹ä½¿ç”¨ç¹é«”ä¸­æ–‡
7. **é©ä¸­é•·åº¦**ï¼šå›ç­”æ§åˆ¶åœ¨300å­—ä»¥å…§ï¼Œä¿æŒé‡é»çªå‡º
8. **ç‰¹åˆ¥è¦æ±‚**ï¼šè«‹å‹™å¿…é‡å°æ¢åˆ—çš„æ¯ä¸€å€‹å°è±¡ï¼Œä¾åºé€é»å›è¦†ï¼Œæ¯ä¸€é»éƒ½è¦æ˜ç¢ºèªªæ˜åŸå› èˆ‡å…·é«”å»ºè­°ï¼Œè«‹å‹¿æ³›æ³›è€Œè«‡ã€‚
9. **æ ¼å¼ç¯„ä¾‹**ï¼š\n- æ¥­å‹™å“¡ï¼šç‹å°æ˜ï¼ˆ-951,772å…ƒï¼‰\n  åŸå› ï¼š...\n  å»ºè­°ï¼š...\n- å®¢æˆ¶ï¼šé™³å…ˆç”Ÿï¼ˆ-349,591å…ƒï¼‰\n  åŸå› ï¼š...\n  å»ºè­°ï¼š...\n- åœ°å€ï¼šåŒ—å€ï¼ˆ-583,869å…ƒï¼‰\n  åŸå› ï¼š...\n  å»ºè­°ï¼š...\n
è¨˜ä½ï¼šä½ æ˜¯ä¸€ä½ç¶“é©—è±å¯Œçš„ç¶“ç‡Ÿåˆ†æå°ˆå®¶ï¼Œè¦è®“ç”¨æˆ¶æ„Ÿå—åˆ°å°ˆæ¥­ä¸”è¦ªåˆ‡çš„è«®è©¢é«”é©—ã€‚
"""

            # æ§‹å»ºèŠå¤©æ­·å²
            chat_messages = []
            if chat_history:
                for msg in chat_history:
                    if msg.get('role') == 'user':
                        chat_messages.append(f"ç”¨æˆ¶ï¼š{msg.get('content', '')}")
                    elif msg.get('role') == 'assistant':
                        chat_messages.append(f"å°ˆå®¶ï¼š{msg.get('content', '')}")

            # æ§‹å»ºå®Œæ•´å°è©±ï¼Œä¿ç•™å®Œæ•´ system prompt èˆ‡èšç„¦æ¢åˆ—æŒ‡ä»¤
            full_conversation = f"""{system_prompt}

å°è©±æ­·å²ï¼š
{chr(10).join(chat_messages) if chat_messages else 'ç„¡å°è©±æ­·å²'}

ç”¨æˆ¶å•é¡Œï¼š
{message}
"""

            response = model.generate_content(full_conversation)
            print("é€çµ¦ Gemini çš„ messageï¼š", full_conversation)
            # æ–°å¢ï¼šè‹¥ AI å›æ‡‰ç‚ºç©ºï¼Œå°å‡ºè­¦å‘Š
            if not response.text or not response.text.strip():
                print("[è­¦å‘Š] Gemini å›å‚³ç©ºç™½å›æ‡‰ï¼è«‹æª¢æŸ¥ promptã€API Key æˆ–æœå‹™ç‹€æ…‹ã€‚")
            return {
                'success': True,
                'response': response.text,
                'model': 'gemini-pro'
            }
        except ImportError:
            # å¦‚æœæ²’æœ‰å®‰è£ google-generativeaiï¼Œä½¿ç”¨å‚™ç”¨æ–¹æ¡ˆ
            return self._fallback_chat_response(message, analysis_context, chat_history)
        except Exception as e:
            return {
                'success': False,
                'error': f'Gemini API èª¿ç”¨å¤±æ•—ï¼š{str(e)}'
            }

    def _fallback_chat_response(self, message, analysis_context=None, chat_history=None):
        """
        å‚™ç”¨èŠå¤©å›æ‡‰ï¼ˆç•¶ Gemini API ä¸å¯ç”¨æ™‚ï¼‰
        """
        try:
            # æ§‹å»ºèŠå¤©ä¸Šä¸‹æ–‡
            context_parts = []
            if analysis_context:
                context_parts.append(f"åˆ†ææœŸé–“ï¼š{analysis_context.get('period_text', 'N/A')}")
                context_parts.append(f"ç•¶æœŸéŠ·å”®ï¼š{analysis_context.get('current_sales', 0):,.0f} å…ƒ")
                context_parts.append(f"å‰æœŸéŠ·å”®ï¼š{analysis_context.get('last_sales', 0):,.0f} å…ƒ")
                context_parts.append(f"å·®ç•°ï¼š{analysis_context.get('diff', 0):,.0f} å…ƒ")
                context_parts.append(f"ç™¾åˆ†æ¯”å·®ç•°ï¼š{analysis_context.get('percentage_diff', 0):.1f}%")
                context_parts.append(f"åˆ†æç¶­åº¦ï¼š{analysis_context.get('dimension_text', 'N/A')}")
                if analysis_context.get('driver_data'):
                    top_contributors = []
                    for item in analysis_context['driver_data'][:3]:
                        if item['å·®ç•°'] > 0:
                            top_contributors.append(f"{item['åˆ†æç¶­åº¦']}(+{item['å·®ç•°']:,.0f})")
                        else:
                            top_contributors.append(f"{item['åˆ†æç¶­åº¦']}({item['å·®ç•°']:,.0f})")
                    context_parts.append(f"ä¸»è¦è²¢ç»è€…ï¼š{', '.join(top_contributors)}")
                # å¼·åŒ–ï¼šæ˜ç¢ºè¦æ±‚ AI èšç„¦å…¶ä»–ç¶­åº¦
                if analysis_context.get('other_dimension_reference'):
                    # è‡ªå‹•å±•é–‹æ¢ç›®èšç„¦
                    focus_items = self._extract_focus_items(analysis_context['other_dimension_reference'])
                    if focus_items:
                        context_parts.append(
                            "è«‹é‡å°ä¸‹åˆ—å°è±¡åˆ†åˆ¥èªªæ˜åŸå› èˆ‡å…·é«”å»ºè­°ï¼Œè«‹ä¾åºé€é»å›è¦†ï¼Œæ¯ä¸€é»éƒ½è¦æ˜ç¢ºèªªæ˜åŸå› èˆ‡å»ºè­°ï¼Œè«‹å‹¿æ³›æ³›è€Œè«‡ï¼š\n" + '\n'.join(focus_items)
                        )
                    context_parts.append(f"å…¶ä»–ç¶­åº¦åƒè€ƒåˆ†æï¼š{analysis_context['other_dimension_reference']}")
            
            # ä½¿ç”¨åŸæœ‰çš„å›æ‡‰ç”Ÿæˆé‚è¼¯
            system_prompt = f"""
ä½ æ˜¯ä¸€ä½è³‡æ·±çš„ç¶“ç‡Ÿåˆ†æå°ˆå®¶ï¼Œæ“æœ‰è±å¯Œçš„å•†æ¥­é¡§å•ç¶“é©—ã€‚

ç•¶å‰åˆ†æèƒŒæ™¯ï¼š
{chr(10).join(context_parts) if context_parts else 'ç„¡ç‰¹å®šåˆ†æèƒŒæ™¯'}

è«‹ä»¥ç¶“ç‡Ÿåˆ†æå°ˆå®¶çš„èº«ä»½å›ç­”ç”¨æˆ¶å•é¡Œï¼Œè¦æ±‚ï¼š
1. ç”¨å£èªåŒ–ã€æ˜“æ‡‚çš„æ–¹å¼è§£é‡‹è¤‡é›œæ¦‚å¿µ
2. æä¾›å…·é«”å¯åŸ·è¡Œçš„æ”¹å–„æ–¹æ¡ˆ
3. åŸºæ–¼æ•¸æ“šæä¾›å°ˆæ¥­çš„å•†æ¥­æ´å¯Ÿ
4. é¼“å‹µç”¨æˆ¶æå•ï¼Œå»ºç«‹è‰¯å¥½çš„å°è©±æ°›åœ
5. å…¨ç¨‹ä½¿ç”¨ç¹é«”ä¸­æ–‡
6. å›ç­”æ§åˆ¶åœ¨300å­—ä»¥å…§
7. ç‰¹åˆ¥è¦æ±‚ï¼šå‹™å¿…é‡å°ã€Œå…¶ä»–ç¶­åº¦åƒè€ƒåˆ†æã€ä¸­å½±éŸ¿æœ€å¤§çš„æ¥­å‹™å“¡ã€å®¢æˆ¶ã€åœ°å€ï¼Œåˆ†åˆ¥èªªæ˜åŸå› èˆ‡å…·é«”å»ºè­°ï¼Œè®“ç”¨æˆ¶èƒ½ç›´æ¥æŒæ¡å¤šç¶­åº¦é‡é»ã€‚
"""

            response = self._generate_ai_response(message, system_prompt, chat_history)
            
            return {
                'success': True,
                'response': response,
                'model': 'fallback'
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'å‚™ç”¨å›æ‡‰ç”Ÿæˆå¤±æ•—ï¼š{str(e)}'
            }

    def _generate_ai_response(self, user_message, system_prompt, chat_history=None):
        """
        ç”Ÿæˆ AI å›æ‡‰ï¼ˆæ¨¡æ“¬ç‰ˆæœ¬ï¼‰
        """
        # é€™è£¡å¯ä»¥æ¥å…¥çœŸå¯¦çš„ AI APIï¼Œå¦‚ OpenAI GPT æˆ– Google Gemini
        # ç›®å‰ä½¿ç”¨è¦å‰‡åŸºç¤çš„å›æ‡‰ç”Ÿæˆ
        
        user_message_lower = user_message.lower()
        
        # æ ¹æ“šç”¨æˆ¶å•é¡Œé¡å‹ç”Ÿæˆå›æ‡‰
        if any(word in user_message_lower for word in ['æ”¹å–„', 'æå‡', 'æ”¹é€²', 'å„ªåŒ–']):
            return self._generate_improvement_suggestions(user_message)
        elif any(word in user_message_lower for word in ['åŸå› ', 'ç‚ºä»€éº¼', 'ç‚ºä½•']):
            return self._generate_cause_analysis(user_message)
        elif any(word in user_message_lower for word in ['å»ºè­°', 'ç­–ç•¥', 'æ–¹æ¡ˆ']):
            return self._generate_strategy_suggestions(user_message)
        elif any(word in user_message_lower for word in ['è¶¨å‹¢', 'é æ¸¬', 'æœªä¾†']):
            return self._generate_trend_analysis(user_message)
        elif any(word in user_message_lower for word in ['é¢¨éšª', 'å•é¡Œ', 'æŒ‘æˆ°']):
            return self._generate_risk_analysis(user_message)
        else:
            return self._generate_general_response(user_message)

    def _generate_improvement_suggestions(self, user_message):
        """ç”Ÿæˆæ”¹å–„å»ºè­°ï¼ŒåŒ…å«å…·é«”è¡Œå‹•æ­¥é©Ÿ"""
        suggestions = [
            "ğŸ“ˆ ä½œç‚ºæ‚¨çš„æ¥­å‹™åˆ†æå°ˆå®¶ï¼Œæˆ‘å»ºè­°æ¡å–ä»¥ä¸‹æ”¹å–„æªæ–½ï¼š\n\n" +
            "1ï¸âƒ£ ç”¢å“ç­–ç•¥å„ªåŒ–\n" +
            "   â€¢ åŠ å¼·è¡¨ç¾å„ªç•°ç”¢å“çš„è¡ŒéŠ·æ¨å»£\n" +
            "   â€¢ é‡å°ä¸‹æ»‘ç”¢å“é€²è¡Œå®šä½èª¿æ•´\n" +
            "   â€¢ å»ºç«‹ç”¢å“ç”Ÿå‘½é€±æœŸç›£æ§æ©Ÿåˆ¶\n\n" +
            "2ï¸âƒ£ éŠ·å”®æµç¨‹æ”¹å–„\n" +
            "   â€¢ å„ªåŒ–éŠ·å”®æ¼æ–—è½‰åŒ–ç‡\n" +
            "   â€¢ å¯¦æ–½ç²¾æº–çš„å®¢æˆ¶åˆ†ç¾¤ç­–ç•¥\n" +
            "   â€¢ å»ºç«‹éŠ·å”®ç¸¾æ•ˆè¿½è¹¤ç³»çµ±\n\n" +
            "3ï¸âƒ£ å®¢æˆ¶é«”é©—æå‡\n" +
            "   â€¢ å¼·åŒ–å”®å¾Œæœå‹™å“è³ª\n" +
            "   â€¢ å»ºç«‹å®¢æˆ¶åé¥‹æ©Ÿåˆ¶\n" +
            "   â€¢ é–‹ç™¼å€‹æ€§åŒ–æœå‹™æ–¹æ¡ˆ\n\n" +
            "ğŸ’¡ å»ºè­°å„ªå…ˆå¯¦æ–½ç¬¬ä¸€é …æªæ–½ï¼Œå¯ä»¥å¸¶ä¾†æœ€å¿«çš„æ”¹å–„æ•ˆæœã€‚",

            "ğŸ¯ åŸºæ–¼æ•¸æ“šåˆ†æï¼Œæˆ‘ç‚ºæ‚¨åˆ¶å®šäº†ä»¥ä¸‹æ”¹å–„æ–¹æ¡ˆï¼š\n\n" +
            "1ï¸âƒ£ çŸ­æœŸå„ªåŒ–ï¼ˆ1-3å€‹æœˆï¼‰\n" +
            "   â€¢ å„ªåŒ–ç”¢å“å®šåƒ¹ç­–ç•¥\n" +
            "   â€¢ åŠ å¼·éŠ·å”®åœ˜éšŠåŸ¹è¨“\n" +
            "   â€¢ å•Ÿå‹•ä¿ƒéŠ·æ´»å‹•å„ªåŒ–\n\n" +
            "2ï¸âƒ£ ä¸­æœŸæ”¹å–„ï¼ˆ3-6å€‹æœˆï¼‰\n" +
            "   â€¢ å»ºç«‹å®¢æˆ¶å¿ èª åº¦è¨ˆåŠƒ\n" +
            "   â€¢ å„ªåŒ–ä¾›æ‡‰éˆç®¡ç†\n" +
            "   â€¢ ç™¼å±•æ•¸ä½è¡ŒéŠ·æ¸ é“\n\n" +
            "3ï¸âƒ£ é•·æœŸç™¼å±•ï¼ˆ6-12å€‹æœˆï¼‰\n" +
            "   â€¢ å»ºç«‹æ•¸æ“šåˆ†æå¹³å°\n" +
            "   â€¢ é–‹ç™¼æ–°å¸‚å ´æ©Ÿæœƒ\n" +
            "   â€¢ å¼·åŒ–å“ç‰Œå»ºè¨­\n\n" +
            "ğŸ“Š æ ¹æ“šROIåˆ†æï¼Œå»ºè­°å„ªå…ˆåŸ·è¡ŒçŸ­æœŸå„ªåŒ–æ–¹æ¡ˆã€‚",

            "ğŸ’¼ èº«ç‚ºæ‚¨çš„æ¥­å‹™é¡§å•ï¼Œæˆ‘æä¾›ä»¥ä¸‹å…·é«”æ”¹å–„å»ºè­°ï¼š\n\n" +
            "1ï¸âƒ£ éŠ·å”®æ•ˆç‡æå‡\n" +
            "   â€¢ å¯¦æ–½éŠ·å”®è‡ªå‹•åŒ–å·¥å…·\n" +
            "   â€¢ å„ªåŒ–å®¢æˆ¶é–‹ç™¼æµç¨‹\n" +
            "   â€¢ å»ºç«‹ç¸¾æ•ˆçå‹µæ©Ÿåˆ¶\n\n" +
            "2ï¸âƒ£ å®¢æˆ¶é—œä¿‚å¼·åŒ–\n" +
            "   â€¢ å»ºç«‹å®¢æˆ¶åˆ†å±¤æœå‹™\n" +
            "   â€¢ é–‹ç™¼æœƒå“¡å¢å€¼æœå‹™\n" +
            "   â€¢ å„ªåŒ–å®¢è¨´è™•ç†æµç¨‹\n\n" +
            "3ï¸âƒ£ ç‡Ÿé‹æ•ˆç‡å„ªåŒ–\n" +
            "   â€¢ streamline ä½œæ¥­æµç¨‹\n" +
            "   â€¢ å»ºç«‹KPIç›£æ§å„€è¡¨æ¿\n" +
            "   â€¢ å„ªåŒ–è³‡æºé…ç½®\n\n" +
            "ğŸŒŸ é€™äº›å»ºè­°åŸºæ–¼æ‚¨çš„æ¥­å‹™ç¾æ³ï¼Œçµåˆäº†å¸‚å ´æœ€ä½³å¯¦è¸ã€‚"
        ]
        return random.choice(suggestions)

    def _generate_cause_analysis(self, user_message):
        """ç”Ÿæˆæ·±å…¥çš„åŸå› åˆ†æï¼ŒåŒ…å«æ•¸æ“šæ”¯æŒ"""
        analyses = [
            "ğŸ“Š æ ¹æ“šå¤šç¶­åº¦åˆ†æï¼Œæˆ‘ç™¼ç¾ä»¥ä¸‹é—œéµå½±éŸ¿å› ç´ ï¼š\n\n" +
            "1ï¸âƒ£ å…§éƒ¨å› ç´ ï¼ˆå¯æ§ï¼‰\n" +
            "   â€¢ ç”¢å“ç”Ÿå‘½é€±æœŸèª¿æ•´éœ€æ±‚ï¼ˆä½”æ¯”ç´„35%ï¼‰\n" +
            "   â€¢ éŠ·å”®åœ˜éšŠç¸¾æ•ˆæ³¢å‹•ï¼ˆä½”æ¯”ç´„25%ï¼‰\n" +
            "   â€¢ ä¿ƒéŠ·ç­–ç•¥åŸ·è¡Œæ•ˆæœï¼ˆä½”æ¯”ç´„20%ï¼‰\n\n" +
            "2ï¸âƒ£ å¤–éƒ¨å› ç´ ï¼ˆéœ€æ‡‰å°ï¼‰\n" +
            "   â€¢ å¸‚å ´ç«¶çˆ­åŠ åŠ‡ï¼ˆå½±éŸ¿ç¨‹åº¦ï¼šé«˜ï¼‰\n" +
            "   â€¢ æ¶ˆè²»è€…åå¥½æ”¹è®Šï¼ˆå½±éŸ¿ç¨‹åº¦ï¼šä¸­ï¼‰\n" +
            "   â€¢ ç¶“æ¿Ÿç’°å¢ƒè®ŠåŒ–ï¼ˆå½±éŸ¿ç¨‹åº¦ï¼šä¸­ï¼‰\n\n" +
            "ğŸ’¡ å»ºè­°å„ªå…ˆè™•ç†å…§éƒ¨å› ç´ ï¼Œå¯å¸¶ä¾†ç«‹å³æ”¹å–„ã€‚",

            "ğŸ” é€šéæ•¸æ“šæŒ–æ˜ï¼Œè­˜åˆ¥å‡ºä»¥ä¸‹æ ¸å¿ƒåŸå› ï¼š\n\n" +
            "1ï¸âƒ£ çŸ­æœŸå½±éŸ¿å› ç´ \n" +
            "   â€¢ å­£ç¯€æ€§éœ€æ±‚æ³¢å‹•ï¼ˆæœˆç’°æ¯”å½±éŸ¿Â±15%ï¼‰\n" +
            "   â€¢ ç«¶çˆ­å°æ‰‹ä¿ƒéŠ·æ´»å‹•ï¼ˆå½±éŸ¿æœŸï¼š2-4é€±ï¼‰\n" +
            "   â€¢ åº«å­˜æ°´å¹³èª¿æ•´ï¼ˆå½±éŸ¿è¨‚å–®å±¥è¡Œç‡ï¼‰\n\n" +
            "2ï¸âƒ£ é•·æœŸè¶¨å‹¢å› ç´ \n" +
            "   â€¢ ç”¢å“å‰µæ–°é€±æœŸï¼ˆå½±éŸ¿å“ç‰Œç«¶çˆ­åŠ›ï¼‰\n" +
            "   â€¢ å®¢æˆ¶æ¶ˆè²»ç¿’æ…£æ”¹è®Šï¼ˆå¹´åº¦è¶¨å‹¢ï¼‰\n" +
            "   â€¢ å¸‚å ´é£½å’Œåº¦æå‡ï¼ˆç”¢æ¥­é€±æœŸï¼‰\n\n" +
            "ğŸ“ˆ å„å› ç´ å½±éŸ¿ç¨‹åº¦å·²é‡åŒ–åˆ†æï¼Œä¾¿æ–¼åˆ¶å®šå°ç­–ã€‚",

            "ğŸ¯ ä¾æ“šæ·±å…¥åˆ†æï¼Œç¾æœ‰æŒ‘æˆ°æºè‡ªä»¥ä¸‹å› ç´ ï¼š\n\n" +
            "1ï¸âƒ£ ç‡Ÿé‹å±¤é¢\n" +
            "   â€¢ éŠ·å”®æµç¨‹æ•ˆç‡ï¼ˆ-12% YoYï¼‰\n" +
            "   â€¢ å®¢æˆ¶æœå‹™æ»¿æ„åº¦ï¼ˆè¼ƒç›®æ¨™å·®5%ï¼‰\n" +
            "   â€¢ åº«å­˜å‘¨è½‰ç‡ï¼ˆä½æ–¼è¡Œæ¥­æ¨™æº–ï¼‰\n\n" +
            "2ï¸âƒ£ å¸‚å ´å±¤é¢\n" +
            "   â€¢ å“ç‰ŒèªçŸ¥åº¦ï¼ˆå¸‚å ´æ’åç¬¬3ï¼‰\n" +
            "   â€¢ åƒ¹æ ¼ç«¶çˆ­åŠ›ï¼ˆè¼ƒç«¶å“é«˜8%ï¼‰\n" +
            "   â€¢ é€šè·¯è¦†è“‹ç‡ï¼ˆå¾…æå‡å€åŸŸï¼š20%ï¼‰\n\n" +
            "3ï¸âƒ£ ç”¢å“å±¤é¢\n" +
            "   â€¢ ç”¢å“çµ„åˆæœ€ä½³åŒ–ï¼ˆå¾…èª¿æ•´SKUï¼š30%ï¼‰\n" +
            "   â€¢ æ–°å“ä¸Šå¸‚ç¯€å¥ï¼ˆè¼ƒè¨ˆç•«å»¶é²1å€‹æœˆï¼‰\n" +
            "   â€¢ ç”¢å“å·®ç•°åŒ–ï¼ˆå‰µæ–°æŒ‡æ•¸ï¼š75/100ï¼‰\n\n" +
            "ğŸ“Š ä»¥ä¸Šåˆ†æå·²ç´å…¥æœ€æ–°çš„å¸‚å ´æ•¸æ“šã€‚"
        ]
        return random.choice(analyses)

    def _generate_strategy_suggestions(self, user_message):
        """ç”Ÿæˆç­–ç•¥å»ºè­°"""
        strategies = [
            "å»ºè­°ç­–ç•¥ï¼š1) çŸ­æœŸï¼šåŠ å¼·ä¿ƒéŠ·æ´»å‹•ï¼›2) ä¸­æœŸï¼šç”¢å“å‰µæ–°å‡ç´šï¼›3) é•·æœŸï¼šå»ºç«‹å“ç‰Œç«¶çˆ­å„ªå‹¢ã€‚",
            "ç­–ç•¥æ–¹å‘ï¼š1) å®¢æˆ¶ç´°åˆ†èˆ‡ç²¾æº–è¡ŒéŠ·ï¼›2) ç”¢å“å·®ç•°åŒ–ç­–ç•¥ï¼›3) æ•¸ä½åŒ–è½‰å‹ï¼›4) ä¾›æ‡‰éˆå„ªåŒ–ã€‚",
            "ç™¼å±•ç­–ç•¥ï¼š1) å¸‚å ´æ“´å¼µï¼›2) ç”¢å“å¤šå…ƒåŒ–ï¼›3) å®¢æˆ¶åƒ¹å€¼æå‡ï¼›4) ç‡Ÿé‹æ•ˆç‡æ”¹å–„ã€‚"
        ]
        return random.choice(strategies)

    def _generate_trend_analysis(self, user_message):
        """ç”Ÿæˆè¶¨å‹¢åˆ†æ"""
        trends = [
            "æœªä¾†è¶¨å‹¢é æ¸¬ï¼š1) æ•¸ä½åŒ–è½‰å‹åŠ é€Ÿï¼›2) å®¢æˆ¶é«”é©—é‡è¦æ€§æå‡ï¼›3) æ•¸æ“šé©…å‹•æ±ºç­–æ™®åŠï¼›4) å€‹æ€§åŒ–æœå‹™éœ€æ±‚å¢åŠ ã€‚",
            "ç™¼å±•è¶¨å‹¢ï¼š1) ç·šä¸Šç·šä¸‹èåˆï¼›2) æ™ºèƒ½åŒ–ç‡Ÿé‹ï¼›3) å¯æŒçºŒç™¼å±•ï¼›4) å…¨çƒåŒ–ç«¶çˆ­åŠ åŠ‡ã€‚",
            "å¸‚å ´è¶¨å‹¢ï¼š1) æ¶ˆè²»å‡ç´šï¼›2) æŠ€è¡“å‰µæ–°ï¼›3) æœå‹™åŒ–è½‰å‹ï¼›4) ç”Ÿæ…‹ç³»çµ±å»ºè¨­ã€‚"
        ]
        return random.choice(trends)

    def _generate_risk_analysis(self, user_message):
        """ç”Ÿæˆé¢¨éšªåˆ†æ"""
        risks = [
            "ä¸»è¦é¢¨éšªï¼š1) å¸‚å ´ç«¶çˆ­åŠ åŠ‡ï¼›2) å®¢æˆ¶æµå¤±é¢¨éšªï¼›3) æŠ€è¡“è®Šé©è¡æ“Šï¼›4) ä¾›æ‡‰éˆä¸ç©©å®šï¼›5) æ³•è¦æ”¿ç­–è®ŠåŒ–ã€‚",
            "é¢¨éšªå› ç´ ï¼š1) ç¶“æ¿Ÿé€±æœŸæ³¢å‹•ï¼›2) å®¢æˆ¶éœ€æ±‚è®ŠåŒ–ï¼›3) æŠ€è¡“æ›´æ–°æ›ä»£ï¼›4) äººæ‰æµå¤±ï¼›5) è³‡é‡‘éˆé¢¨éšªã€‚",
            "æ½›åœ¨é¢¨éšªï¼š1) å¸‚å ´é£½å’Œï¼›2) æ›¿ä»£å“å¨è„…ï¼›3) æˆæœ¬ä¸Šå‡ï¼›4) å“è³ªå•é¡Œï¼›5) å“ç‰Œå½¢è±¡å—æã€‚"
        ]
        return random.choice(risks)

    def _generate_general_response(self, user_message):
        """ç”Ÿæˆä¸€èˆ¬å›æ‡‰ï¼ŒåŒ…å«è§’è‰²æ‰®æ¼”å’Œå°ˆæ¥­å»ºè­°"""
        responses = [
            "æ‚¨å¥½ï¼Œæˆ‘æ˜¯æ‚¨çš„æ¥­å‹™æ™ºæ…§é¡§å•ã€‚ğŸ“Š ä½œç‚ºä¸€åå°ˆæ¥­çš„æ•¸æ“šåˆ†æå°ˆå®¶ï¼Œæˆ‘å¯ä»¥å”åŠ©æ‚¨ï¼š\n\n" +
            "1ï¸âƒ£ æ·±å…¥è§£è®€éŠ·å”®æ•¸æ“šèƒŒå¾Œçš„æ„ç¾©\n" +
            "2ï¸âƒ£ æä¾›åŸºæ–¼æ•¸æ“šçš„æ”¹å–„å»ºè­°\n" +
            "3ï¸âƒ£ åˆ†æå¸‚å ´è¶¨å‹¢å’Œç«¶çˆ­æ…‹å‹¢\n" +
            "4ï¸âƒ£ åˆ¶å®šå…·é«”å¯è¡Œçš„ç­–ç•¥æ–¹æ¡ˆ\n\n" +
            "ğŸ’¡ è«‹å‘Šè¨´æˆ‘æ‚¨æœ€é—œæ³¨çš„æ¥­å‹™å•é¡Œï¼Œæˆ‘æœƒé‹ç”¨å°ˆæ¥­çŸ¥è­˜ç‚ºæ‚¨æä¾›é‡èº«å®šåˆ¶çš„è§£æ±ºæ–¹æ¡ˆã€‚",

            "ä½œç‚ºæ‚¨çš„BI Expertï¼Œæˆ‘ç†è§£æ¯å€‹æ¥­å‹™æ±ºç­–éƒ½éœ€è¦å …å¯¦çš„æ•¸æ“šæ”¯æŒã€‚ğŸ“ˆ æˆ‘å¯ä»¥å¹«æ‚¨ï¼š\n\n" +
            "1ï¸âƒ£ è­˜åˆ¥é—œéµç¸¾æ•ˆæŒ‡æ¨™(KPI)çš„è®ŠåŒ–\n" +
            "2ï¸âƒ£ ç™¼æ˜æ¥­ç¸¾æ³¢å‹•çš„æ ¹æœ¬åŸå› \n" +
            "3ï¸âƒ£ é æ¸¬æœªä¾†çš„æ¥­å‹™è¶¨å‹¢\n" +
            "4ï¸âƒ£ æä¾›å…·é«”çš„å„ªåŒ–å»ºè­°\n\n" +
            "ğŸ¯ è®“æˆ‘å€‘ä¸€èµ·é€šéæ•¸æ“šé©…å‹•çš„æ–¹å¼ï¼Œæ¨å‹•æ¥­å‹™æŒçºŒå¢é•·ï¼",

            "æ‚¨å¥½ï¼æˆ‘æ˜¯å°ˆæ³¨æ–¼æ¥­å‹™åˆ†æèˆ‡ç­–ç•¥è¦åŠƒçš„AIé¡§å•ã€‚ğŸ¤ åŸºæ–¼æ‚¨çš„æ¥­å‹™æ•¸æ“šï¼Œæˆ‘èƒ½å¤ ï¼š\n\n" +
            "1ï¸âƒ£ é€²è¡Œå¤šç¶­åº¦çš„éŠ·å”®åˆ†æ\n" +
            "2ï¸âƒ£ è­˜åˆ¥æ¥­å‹™å¢é•·æ©Ÿæœƒ\n" +
            "3ï¸âƒ£ æä¾›å¯¦ç”¨çš„æ”¹å–„æ–¹æ¡ˆ\n" +
            "4ï¸âƒ£ å”åŠ©åˆ¶å®šè¡Œå‹•è¨ˆåŠƒ\n\n" +
            "ğŸ“Š è«‹åˆ†äº«æ‚¨çš„å…·é«”éœ€æ±‚ï¼Œè®“æˆ‘ç”¨æ•¸æ“šçš„èªè¨€ï¼Œå¹«æ‚¨æ‰¾åˆ°æœ€å„ªè§£æ±ºæ–¹æ¡ˆã€‚"
        ]
        return random.choice(responses)

    def drill_down_analysis(self, current_start, current_end, last_start, last_end, 
                           primary_dimension, primary_value, drill_dimension):
        """
        åŸ·è¡Œ drill down åˆ†æ
        """
        try:
            # ç²å– drill down æ•¸æ“š
            drill_down_data = self.data_manager.get_drill_down_analysis(
                current_start, current_end, last_start, last_end,
                primary_dimension, primary_value, drill_dimension
            )
            
            # ç²å–ç¶­åº¦æ–‡å­—
            dimension_map = {
                'product': 'ç”¢å“',
                'staff': 'æ¥­å‹™å“¡',
                'customer': 'å®¢æˆ¶',
                'region': 'åœ°å€'
            }
            
            return {
                'success': True,
                'drill_down_data': drill_down_data.to_dict('records'),
                'primary_dimension_text': dimension_map.get(primary_dimension, primary_dimension),
                'drill_dimension_text': dimension_map.get(drill_dimension, drill_dimension)
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }

    def sql_to_natural_language(self, sql_query):
        """
        å°‡ SQL æŸ¥è©¢è½‰æ›ç‚ºè‡ªç„¶èªè¨€æè¿°
        """
        sql_upper = sql_query.upper()
        # ç²¾ç¢ºåˆ¤æ–· staff_name, SUM(f.amount), SUM(f.quantity)
        if (
            'SELECT' in sql_upper and 'STAFF_NAME' in sql_upper and 
            'SUM(F.AMOUNT)' in sql_upper and 'SUM(F.QUANTITY)' in sql_upper
        ):
            return "çµ±è¨ˆå„æ¥­å‹™å“¡éŠ·å”®æ¥­ç¸¾å’Œæ•¸é‡"
        # å…¶ä»–æƒ…å¢ƒç¶­æŒåŸæœ‰åˆ¤æ–·
        if 'STAFF_NAME' in sql_upper and 'SUM' in sql_upper and 'AMOUNT' in sql_upper:
            if 'QUANTITY' in sql_upper:
                return "çµ±è¨ˆå„æ¥­å‹™å“¡éŠ·å”®æ¥­ç¸¾å’Œæ•¸é‡"
            else:
                return "çµ±è¨ˆå„æ¥­å‹™å“¡éŠ·å”®æ¥­ç¸¾"
        elif 'PRODUCT_NAME' in sql_upper and 'SUM' in sql_upper and 'AMOUNT' in sql_upper:
            if 'QUANTITY' in sql_upper:
                return "çµ±è¨ˆå„ç”¢å“éŠ·å”®é¡å’Œæ•¸é‡"
            else:
                return "çµ±è¨ˆå„ç”¢å“éŠ·å”®é¡"
        elif 'CUSTOMER_NAME' in sql_upper and 'SUM' in sql_upper and 'AMOUNT' in sql_upper:
            if 'QUANTITY' in sql_upper:
                return "çµ±è¨ˆå„å®¢æˆ¶æ¶ˆè²»é‡‘é¡å’Œæ•¸é‡"
            else:
                return "çµ±è¨ˆå„å®¢æˆ¶æ¶ˆè²»é‡‘é¡"
        elif 'REGION_NAME' in sql_upper and 'SUM' in sql_upper and 'AMOUNT' in sql_upper:
            if 'QUANTITY' in sql_upper:
                return "çµ±è¨ˆå„åœ°å€éŠ·å”®é¡å’Œæ•¸é‡"
            else:
                return "çµ±è¨ˆå„åœ°å€éŠ·å”®é¡"
        elif 'STAFF' in sql_upper and 'SUM' in sql_upper and 'AMOUNT' in sql_upper:
            if 'QUANTITY' in sql_upper:
                return "çµ±è¨ˆå„æ¥­å‹™å“¡éŠ·å”®æ¥­ç¸¾å’Œæ•¸é‡"
            else:
                return "çµ±è¨ˆå„æ¥­å‹™å“¡éŠ·å”®æ¥­ç¸¾"
        elif 'PRODUCT' in sql_upper and 'SUM' in sql_upper and 'AMOUNT' in sql_upper:
            if 'QUANTITY' in sql_upper:
                return "çµ±è¨ˆå„ç”¢å“éŠ·å”®é¡å’Œæ•¸é‡"
            else:
                return "çµ±è¨ˆå„ç”¢å“éŠ·å”®é¡"
        elif 'CUSTOMER' in sql_upper and 'SUM' in sql_upper and 'AMOUNT' in sql_upper:
            if 'QUANTITY' in sql_upper:
                return "çµ±è¨ˆå„å®¢æˆ¶æ¶ˆè²»é‡‘é¡å’Œæ•¸é‡"
            else:
                return "çµ±è¨ˆå„å®¢æˆ¶æ¶ˆè²»é‡‘é¡"
        elif 'REGION' in sql_upper and 'SUM' in sql_upper and 'AMOUNT' in sql_upper:
            if 'QUANTITY' in sql_upper:
                return "çµ±è¨ˆå„åœ°å€éŠ·å”®é¡å’Œæ•¸é‡"
            else:
                return "çµ±è¨ˆå„åœ°å€éŠ·å”®é¡"
        elif 'STAFF' in sql_upper and 'DATE' in sql_upper:
            return "æŸ¥è©¢æ¥­å‹™å“¡æ¯æ—¥éŠ·å”®æ¥­ç¸¾"
        elif 'PRODUCT' in sql_upper and 'DATE' in sql_upper:
            return "æŸ¥è©¢ç”¢å“æ¯æ—¥éŠ·å”®æƒ…æ³"
        elif 'CUSTOMER' in sql_upper and 'DATE' in sql_upper:
            return "æŸ¥è©¢å®¢æˆ¶æ¯æ—¥æ¶ˆè²»æƒ…æ³"
        elif 'REGION' in sql_upper and 'DATE' in sql_upper:
            return "æŸ¥è©¢åœ°å€æ¯æ—¥éŠ·å”®æƒ…æ³"
        else:
            # é€šç”¨æè¿°
            return "åŸ·è¡Œè³‡æ–™åº«æŸ¥è©¢"

    def natural_language_to_sql(self, natural_query, original_query=None):
        """
        å°‡è‡ªç„¶èªè¨€æŸ¥è©¢è½‰æ›ç‚º SQL
        """
        # æª¢æŸ¥æŸ¥è©¢ä¸­æ˜¯å¦åŒ…å«æ˜ç¢ºçš„æ™‚é–“æ ¼å¼
        import re
        
        # çµ±ä¸€è™•ç†æŸ¥è©¢ä¸­çš„æ™‚é–“æ ¼å¼
        processed_query = natural_query
        
        # 1. çµ±ä¸€è™•ç†æœˆä»½çš„ä¸­æ–‡è¡¨ç¤º
        month_mapping = {
            'ä¸€æœˆ': '01', 'äºŒæœˆ': '02', 'ä¸‰æœˆ': '03', 'å››æœˆ': '04',
            'äº”æœˆ': '05', 'å…­æœˆ': '06', 'ä¸ƒæœˆ': '07', 'å…«æœˆ': '08',
            'ä¹æœˆ': '09', 'åæœˆ': '10', 'åä¸€æœˆ': '11', 'åäºŒæœˆ': '12'
        }
        
        for chinese_month, numeric_month in month_mapping.items():
            # å°‡ "2025å¹´ä¸ƒæœˆ" è½‰æ›ç‚º "2025å¹´07æœˆ"
            processed_query = processed_query.replace(f"å¹´{chinese_month}", f"å¹´{numeric_month}æœˆ")
        
        # 2. çµ±ä¸€è™•ç†å­£åº¦æ ¼å¼
        quarter_mapping = {
            'å­£1': 'Q1', 'å­£2': 'Q2', 'å­£3': 'Q3', 'å­£4': 'Q4',
            'q1': 'Q1', 'q2': 'Q2', 'q3': 'Q3', 'q4': 'Q4'
        }
        
        for quarter_text, quarter_code in quarter_mapping.items():
            processed_query = processed_query.replace(quarter_text, quarter_code)
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«æ™‚é–“æ ¼å¼ï¼ˆä½¿ç”¨è™•ç†å¾Œçš„æŸ¥è©¢ï¼‰
        time_patterns = [
            r'\d{4}[/-]\d{1,2}',  # YYYY/MM æˆ– YYYY-MM
            r'\d{4}å¹´\d{1,2}æœˆ',   # YYYYå¹´MMæœˆ
            r'Q\d',                # Q1, Q2, etc.
            r'\d{4}å¹´Q\d'          # YYYYå¹´Q1
        ]
        
        has_time_format = any(re.search(pattern, processed_query) for pattern in time_patterns)
        
        # åªæœ‰åœ¨æŸ¥è©¢ä¸­åŒ…å«æ˜ç¢ºæ™‚é–“æ ¼å¼æ™‚æ‰è§£ææ™‚é–“
        year = None
        month = None
        quarter = None
        if has_time_format:
            query_to_parse = original_query if original_query else natural_query
            parsed = self._parse_query(query_to_parse)
            
            # å˜—è©¦å¾è§£æçµæœä¸­ç²å–æ™‚é–“è³‡è¨Š
            if parsed:
                try:
                    # æª¢æŸ¥æ˜¯å¦æœ‰ current_start
                    if 'current_start' in parsed:
                        dt = parsed['current_start']
                        year = int(dt[:4])
                        
                        # æª¢æŸ¥æ˜¯å¦æœ‰æœˆä»½è³‡è¨Šï¼ˆæœˆä»½æŸ¥è©¢ï¼‰
                        if len(dt) > 7 and dt[5:7].isdigit():
                            month = int(dt[5:7])
                            quarter = (month - 1) // 3 + 1
                        # æª¢æŸ¥æ˜¯å¦ç‚ºå­£åº¦æŸ¥è©¢
                        elif 'Q' in processed_query:
                            quarter_match = re.search(r'Q(\d)', processed_query)
                            if quarter_match:
                                quarter = int(quarter_match.group(1))
                                # å­£åº¦æŸ¥è©¢ä¸éœ€è¦æœˆä»½
                                month = None
                except Exception as e:
                    print(f"æ™‚é–“è§£æéŒ¯èª¤: {e}")
                    pass
        
        # å‹•æ…‹ç²å–ç¶­åº¦è³‡æ–™
        specific_customers = self._get_dimension_values('customer')
        specific_staff = self._get_dimension_values('staff')
        specific_products = self._get_dimension_values('product')
        specific_regions = self._get_dimension_values('region')
        
        query_lower = natural_query.lower()
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«ç‰¹å®šå®¢æˆ¶åç¨±
        for customer in specific_customers:
            if customer in natural_query:
                # æª¢æŸ¥è©²å®¢æˆ¶æ˜¯å¦å­˜åœ¨æ–¼è³‡æ–™åº«ä¸­
                customer_exists = self._check_customer_exists(customer)
                if customer_exists:
                    # å®¢æˆ¶å­˜åœ¨ï¼Œç”Ÿæˆé‡å°è©²å®¢æˆ¶çš„æŸ¥è©¢
                    if year and month:
                        # æ”¯æ´æœˆä»½æŸ¥è©¢
                        return f'''
                            SELECT c.customer_name, c.customer_level, SUM(f.amount) as total_sales, SUM(f.quantity) as total_quantity
                            FROM sales_fact f
                            JOIN dim_customer c ON f.customer_id = c.customer_id
                            JOIN dim_time t ON f.time_id = t.time_id
                            WHERE c.customer_name = '{customer}' AND t.year = {year} AND t.month = {month}
                            GROUP BY c.customer_name, c.customer_level
                        '''
                    elif year and quarter:
                        # æ”¯æ´å­£åº¦æŸ¥è©¢
                        quarter_start_month = 3 * (quarter - 1) + 1
                        quarter_end_month = 3 * quarter
                        return f'''
                            SELECT c.customer_name, c.customer_level, SUM(f.amount) as total_sales, SUM(f.quantity) as total_quantity
                            FROM sales_fact f
                            JOIN dim_customer c ON f.customer_id = c.customer_id
                            JOIN dim_time t ON f.time_id = t.time_id
                            WHERE c.customer_name = '{customer}' AND t.year = {year} AND t.month BETWEEN {quarter_start_month} AND {quarter_end_month}
                            GROUP BY c.customer_name, c.customer_level
                        '''
                    else:
                        # ç„¡æ™‚é–“é™åˆ¶ï¼ŒæŸ¥è©¢æ‰€æœ‰è³‡æ–™
                        return f'''
                            SELECT c.customer_name, c.customer_level, SUM(f.amount) as total_sales, SUM(f.quantity) as total_quantity
                            FROM sales_fact f
                            JOIN dim_customer c ON f.customer_id = c.customer_id
                            GROUP BY c.customer_name, c.customer_level
                        '''
                else:
                    # å®¢æˆ¶ä¸å­˜åœ¨ï¼Œè¿”å›ç©ºçµæœæŸ¥è©¢
                    return f'''
                        SELECT c.customer_name, c.customer_level, SUM(f.amount) as total_sales, SUM(f.quantity) as total_quantity
                        FROM sales_fact f
                        JOIN dim_customer c ON f.customer_id = c.customer_id
                        WHERE c.customer_name = '{customer}'
                        GROUP BY c.customer_name, c.customer_level
                    '''
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«ç‰¹å®šæ¥­å‹™å“¡åç¨±
        for staff in specific_staff:
            if staff in natural_query:
                # ç”Ÿæˆé‡å°è©²æ¥­å‹™å“¡çš„æŸ¥è©¢
                if year and month:
                    # æ”¯æ´æœˆä»½æŸ¥è©¢
                    return f'''
                        SELECT s.staff_name, s.department, SUM(f.amount) as total_sales, SUM(f.quantity) as total_quantity
                        FROM sales_fact f
                        JOIN dim_staff s ON f.staff_id = s.staff_id
                        JOIN dim_time t ON f.time_id = t.time_id
                        WHERE s.staff_name = '{staff}' AND t.year = {year} AND t.month = {month}
                        GROUP BY s.staff_name, s.department
                    '''
                elif year and quarter:
                    # æ”¯æ´å­£åº¦æŸ¥è©¢
                    quarter_start_month = 3 * (quarter - 1) + 1
                    quarter_end_month = 3 * quarter
                    return f'''
                        SELECT s.staff_name, s.department, SUM(f.amount) as total_sales, SUM(f.quantity) as total_quantity
                        FROM sales_fact f
                        JOIN dim_staff s ON f.staff_id = s.staff_id
                        JOIN dim_time t ON f.time_id = t.time_id
                        WHERE s.staff_name = '{staff}' AND t.year = {year} AND t.month BETWEEN {quarter_start_month} AND {quarter_end_month}
                        GROUP BY s.staff_name, s.department
                    '''
                else:
                    # ç„¡æ™‚é–“é™åˆ¶ï¼ŒæŸ¥è©¢æ‰€æœ‰è³‡æ–™
                    return f'''
                        SELECT s.staff_name, s.department, SUM(f.amount) as total_sales, SUM(f.quantity) as total_quantity
                        FROM sales_fact f
                        JOIN dim_staff s ON f.staff_id = s.staff_id
                        GROUP BY s.staff_name, s.department
                    '''
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«ç‰¹å®šç”¢å“åç¨±
        for product in specific_products:
            if product in natural_query:
                # ç”Ÿæˆé‡å°è©²ç”¢å“çš„æŸ¥è©¢
                if year and month:
                    # æ”¯æ´æœˆä»½æŸ¥è©¢
                    return f'''
                        SELECT p.product_name, p.category, SUM(f.amount) as total_sales, SUM(f.quantity) as total_quantity
                        FROM sales_fact f
                        JOIN dim_product p ON f.product_id = p.product_id
                        JOIN dim_time t ON f.time_id = t.time_id
                        WHERE p.product_name = '{product}' AND t.year = {year} AND t.month = {month}
                        GROUP BY p.product_name, p.category
                    '''
                elif year and quarter:
                    # æ”¯æ´å­£åº¦æŸ¥è©¢
                    quarter_start_month = 3 * (quarter - 1) + 1
                    quarter_end_month = 3 * quarter
                    return f'''
                        SELECT p.product_name, p.category, SUM(f.amount) as total_sales, SUM(f.quantity) as total_quantity
                        FROM sales_fact f
                        JOIN dim_product p ON f.product_id = p.product_id
                        JOIN dim_time t ON f.time_id = t.time_id
                        WHERE p.product_name = '{product}' AND t.year = {year} AND t.month BETWEEN {quarter_start_month} AND {quarter_end_month}
                        GROUP BY p.product_name, p.category
                    '''
                else:
                    # ç„¡æ™‚é–“é™åˆ¶ï¼ŒæŸ¥è©¢æ‰€æœ‰è³‡æ–™
                    return f'''
                        SELECT p.product_name, p.category, SUM(f.amount) as total_sales, SUM(f.quantity) as total_quantity
                        FROM sales_fact f
                        JOIN dim_product p ON f.product_id = p.product_id
                        GROUP BY p.product_name, p.category
                    '''
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«ç‰¹å®šåœ°å€åç¨±
        for region in specific_regions:
            if region in natural_query:
                # ç”Ÿæˆé‡å°è©²åœ°å€çš„æŸ¥è©¢
                if year and month:
                    # æ”¯æ´æœˆä»½æŸ¥è©¢
                    return f'''
                        SELECT r.region_name, r.region_type, SUM(f.amount) as total_sales, SUM(f.quantity) as total_quantity
                        FROM sales_fact f
                        JOIN dim_region r ON f.region_id = r.region_id
                        JOIN dim_time t ON f.time_id = t.time_id
                        WHERE r.region_name = '{region}' AND t.year = {year} AND t.month = {month}
                        GROUP BY r.region_name, r.region_type
                    '''
                elif year and quarter:
                    # æ”¯æ´å­£åº¦æŸ¥è©¢
                    quarter_start_month = 3 * (quarter - 1) + 1
                    quarter_end_month = 3 * quarter
                    return f'''
                        SELECT r.region_name, r.region_type, SUM(f.amount) as total_sales, SUM(f.quantity) as total_quantity
                        FROM sales_fact f
                        JOIN dim_region r ON f.region_id = r.region_id
                        JOIN dim_time t ON f.time_id = t.time_id
                        WHERE r.region_name = '{region}' AND t.year = {year} AND t.month BETWEEN {quarter_start_month} AND {quarter_end_month}
                        GROUP BY r.region_name, r.region_type
                    '''
                else:
                    # ç„¡æ™‚é–“é™åˆ¶ï¼ŒæŸ¥è©¢æ‰€æœ‰è³‡æ–™
                    return f'''
                        SELECT r.region_name, r.region_type, SUM(f.amount) as total_sales, SUM(f.quantity) as total_quantity
                        FROM sales_fact f
                        JOIN dim_region r ON f.region_id = r.region_id
                        GROUP BY r.region_name, r.region_type
                    '''
        
        # æ–°å¢å°ã€Œçµ±è¨ˆå„æ¥­å‹™å“¡éŠ·å”®æ¥­ç¸¾å’Œæ•¸é‡ã€çš„æŸ¥è©¢æ¨¡å¼
        if natural_query.strip() == "çµ±è¨ˆå„æ¥­å‹™å“¡éŠ·å”®æ¥­ç¸¾å’Œæ•¸é‡":
            if year and month:
                # æ”¯æ´æœˆä»½æŸ¥è©¢
                return f'''
                    SELECT s.staff_name, s.department, SUM(f.amount) as total_sales, SUM(f.quantity) as total_quantity
                    FROM sales_fact f
                    JOIN dim_staff s ON f.staff_id = s.staff_id
                    JOIN dim_time t ON f.time_id = t.time_id
                    WHERE t.year = {year} AND t.month = {month}
                    GROUP BY s.staff_name, s.department
                    ORDER BY total_sales DESC
                '''
            elif year and quarter:
                # æ”¯æ´å­£åº¦æŸ¥è©¢
                quarter_start_month = 3 * (quarter - 1) + 1
                quarter_end_month = 3 * quarter
                return f'''
                    SELECT s.staff_name, s.department, SUM(f.amount) as total_sales, SUM(f.quantity) as total_quantity
                    FROM sales_fact f
                    JOIN dim_staff s ON f.staff_id = s.staff_id
                    JOIN dim_time t ON f.time_id = t.time_id
                    WHERE t.year = {year} AND t.month BETWEEN {quarter_start_month} AND {quarter_end_month}
                    GROUP BY s.staff_name, s.department
                    ORDER BY total_sales DESC
                '''
            else:
                # ç„¡æ™‚é–“é™åˆ¶ï¼ŒæŸ¥è©¢æ‰€æœ‰è³‡æ–™
                return '''
                    SELECT s.staff_name, s.department, SUM(f.amount) as total_sales, SUM(f.quantity) as total_quantity
                    FROM sales_fact f
                    JOIN dim_staff s ON f.staff_id = s.staff_id
                    GROUP BY s.staff_name, s.department
                    ORDER BY total_sales DESC
                '''
        # å…¶é¤˜ç¶­æŒåŸæœ‰é‚è¼¯
        # ... existing code ...
        
        # ç°¡å–®çš„æŸ¥è©¢æ¨¡å¼åŒ¹é…
        query_patterns = {
            r'é¡¯ç¤ºæ‰€æœ‰ç”¢å“': 'SELECT * FROM dim_product',
            r'æŸ¥è©¢å®¢æˆ¶éŠ·å”®é¡': '''
                SELECT c.customer_name, SUM(f.amount) as total_sales
                FROM sales_fact f
                JOIN dim_customer c ON f.customer_id = c.customer_id
                GROUP BY c.customer_name
                ORDER BY total_sales DESC
            ''',
            r'é¡¯ç¤ºå‰(\d+)ç­†éŠ·å”®è¨˜éŒ„': lambda match: f'SELECT * FROM sales_fact LIMIT {match.group(1)}',
            r'çµ±è¨ˆå„ç”¢å“éŠ·å”®é¡': '''
                SELECT p.product_name, SUM(f.amount) as total_sales
                FROM sales_fact f
                JOIN dim_product p ON f.product_id = p.product_id
                GROUP BY p.product_name
                ORDER BY total_sales DESC
            ''',
            r'é¡¯ç¤ºæ‰€æœ‰å®¢æˆ¶': 'SELECT * FROM dim_customer',
            r'é¡¯ç¤ºæ‰€æœ‰æ¥­å‹™å“¡': 'SELECT * FROM dim_staff',
            r'é¡¯ç¤ºæ‰€æœ‰åœ°å€': 'SELECT * FROM dim_region',
            r'é¡¯ç¤ºæ‰€æœ‰æ™‚é–“': 'SELECT * FROM dim_time',
            r'é¡¯ç¤ºéŠ·å”®äº‹å¯¦': 'SELECT * FROM sales_fact LIMIT 20',
            r'æŸ¥è©¢(\d{4})å¹´(\d{1,2})æœˆéŠ·å”®': lambda match: f'''
                SELECT t.date, SUM(f.amount) as daily_sales, SUM(f.quantity) as daily_quantity
                FROM sales_fact f
                JOIN dim_time t ON f.time_id = t.time_id
                WHERE t.year = {match.group(1)} AND t.month = {match.group(2)}
                GROUP BY t.date
                ORDER BY t.date
            ''',
            r'æŸ¥è©¢(\d{4})å¹´Q(\d)éŠ·å”®': lambda match: f'''
                SELECT t.date, SUM(f.amount) as daily_sales, SUM(f.quantity) as daily_quantity
                FROM sales_fact f
                JOIN dim_time t ON f.time_id = t.time_id
                WHERE t.year = {match.group(1)} AND t.quarter = {match.group(2)}
                GROUP BY t.date
                ORDER BY t.date
            ''',
            r'çµ±è¨ˆå„å®¢æˆ¶æ¶ˆè²»': '''
                SELECT c.customer_name, SUM(f.amount) as total_consumption
                FROM sales_fact f
                JOIN dim_customer c ON f.customer_id = c.customer_id
                GROUP BY c.customer_name
                ORDER BY total_consumption DESC
            ''',
            r'çµ±è¨ˆå„æ¥­å‹™å“¡æ¥­ç¸¾': '''
                SELECT s.staff_name, SUM(f.amount) as total_sales
                FROM sales_fact f
                JOIN dim_staff s ON f.staff_id = s.staff_id
                GROUP BY s.staff_name
                ORDER BY total_sales DESC
            ''',
            r'çµ±è¨ˆå„åœ°å€éŠ·å”®': '''
                SELECT r.region_name, SUM(f.amount) as total_sales
                FROM sales_fact f
                JOIN dim_region r ON f.region_id = r.region_id
                GROUP BY r.region_name
                ORDER BY total_sales DESC
            ''',
            # æ–°å¢å¤šç¶­åº¦æŸ¥è©¢æ¨¡å¼
            r'æ¥­å‹™å“¡.*(\d{4})å¹´(\d{1,2})æœˆ.*æ¥­ç¸¾': lambda match: f'''
                SELECT s.staff_name, t.date, SUM(f.amount) as daily_sales
                FROM sales_fact f
                JOIN dim_staff s ON f.staff_id = s.staff_id
                JOIN dim_time t ON f.time_id = t.time_id
                WHERE t.year = {match.group(1)} AND t.month = {match.group(2)}
                GROUP BY s.staff_name, t.date
                ORDER BY s.staff_name, t.date
            ''',
            r'(\d{4})å¹´(\d{1,2})æœˆ.*æ¥­å‹™å“¡.*æ¥­ç¸¾': lambda match: f'''
                SELECT s.staff_name, t.date, SUM(f.amount) as daily_sales
                FROM sales_fact f
                JOIN dim_staff s ON f.staff_id = s.staff_id
                JOIN dim_time t ON f.time_id = t.time_id
                WHERE t.year = {match.group(1)} AND t.month = {match.group(2)}
                GROUP BY s.staff_name, t.date
                ORDER BY s.staff_name, t.date
            ''',
            r'ç”¢å“.*(\d{4})å¹´(\d{1,2})æœˆ.*éŠ·å”®': lambda match: f'''
                SELECT p.product_name, t.date, SUM(f.amount) as daily_sales
                FROM sales_fact f
                JOIN dim_product p ON f.product_id = p.product_id
                JOIN dim_time t ON f.time_id = t.time_id
                WHERE t.year = {match.group(1)} AND t.month = {match.group(2)}
                GROUP BY p.product_name, t.date
                ORDER BY p.product_name, t.date
            ''',
            r'å®¢æˆ¶.*(\d{4})å¹´(\d{1,2})æœˆ.*æ¶ˆè²»': lambda match: f'''
                SELECT c.customer_name, t.date, SUM(f.amount) as daily_consumption
                FROM sales_fact f
                JOIN dim_customer c ON f.customer_id = c.customer_id
                JOIN dim_time t ON f.time_id = t.time_id
                WHERE t.year = {match.group(1)} AND t.month = {match.group(2)}
                GROUP BY c.customer_name, t.date
                ORDER BY c.customer_name, t.date
            ''',
            # æ–°å¢æ”¯æ´ç¶­åº¦è¡¨å…§è³‡æ–™æŸ¥è©¢çš„æ¨¡å¼
            r'(\d{4})å¹´(\d{1,2})æœˆ.*å®¢æˆ¶.*ç­‰ç´š': lambda match: f'''
                SELECT c.customer_name, c.customer_level, SUM(f.amount) as total_sales
                FROM sales_fact f
                JOIN dim_customer c ON f.customer_id = c.customer_id
                JOIN dim_time t ON f.time_id = t.time_id
                WHERE t.year = {match.group(1)} AND t.month = {match.group(2)}
                GROUP BY c.customer_name, c.customer_level
                ORDER BY total_sales DESC
            ''',
            r'(\d{4})å¹´(\d{1,2})æœˆ.*æ¥­å‹™å“¡.*éƒ¨é–€': lambda match: f'''
                SELECT s.staff_name, s.department, SUM(f.amount) as total_sales
                FROM sales_fact f
                JOIN dim_staff s ON f.staff_id = s.staff_id
                JOIN dim_time t ON f.time_id = t.time_id
                WHERE t.year = {match.group(1)} AND t.month = {match.group(2)}
                GROUP BY s.staff_name, s.department
                ORDER BY total_sales DESC
            ''',
            r'(\d{4})å¹´(\d{1,2})æœˆ.*ç”¢å“.*é¡åˆ¥': lambda match: f'''
                SELECT p.product_name, p.category, SUM(f.amount) as total_sales
                FROM sales_fact f
                JOIN dim_product p ON f.product_id = p.product_id
                JOIN dim_time t ON f.time_id = t.time_id
                WHERE t.year = {match.group(1)} AND t.month = {match.group(2)}
                GROUP BY p.product_name, p.category
                ORDER BY total_sales DESC
            ''',
            r'(\d{4})å¹´(\d{1,2})æœˆ.*åœ°å€.*é¡å‹': lambda match: f'''
                SELECT r.region_name, r.region_type, SUM(f.amount) as total_sales
                FROM sales_fact f
                JOIN dim_region r ON f.region_id = r.region_id
                JOIN dim_time t ON f.time_id = t.time_id
                WHERE t.year = {match.group(1)} AND t.month = {match.group(2)}
                GROUP BY r.region_name, r.region_type
                ORDER BY total_sales DESC
            ''',
            # æ”¯æ´å­£åº¦æŸ¥è©¢çš„æ¨¡å¼
            r'(\d{4})å¹´Q(\d).*å®¢æˆ¶.*ç­‰ç´š': lambda match: f'''
                SELECT c.customer_name, c.customer_level, SUM(f.amount) as total_sales
                FROM sales_fact f
                JOIN dim_customer c ON f.customer_id = c.customer_id
                JOIN dim_time t ON f.time_id = t.time_id
                WHERE t.year = {match.group(1)} AND t.quarter = {match.group(2)}
                GROUP BY c.customer_name, c.customer_level
                ORDER BY total_sales DESC
            ''',
            r'(\d{4})å¹´Q(\d).*æ¥­å‹™å“¡.*éƒ¨é–€': lambda match: f'''
                SELECT s.staff_name, s.department, SUM(f.amount) as total_sales
                FROM sales_fact f
                JOIN dim_staff s ON f.staff_id = s.staff_id
                JOIN dim_time t ON f.time_id = t.time_id
                WHERE t.year = {match.group(1)} AND t.quarter = {match.group(2)}
                GROUP BY s.staff_name, s.department
                ORDER BY total_sales DESC
            ''',
            r'(\d{4})å¹´Q(\d).*ç”¢å“.*é¡åˆ¥': lambda match: f'''
                SELECT p.product_name, p.category, SUM(f.amount) as total_sales
                FROM sales_fact f
                JOIN dim_product p ON f.product_id = p.product_id
                JOIN dim_time t ON f.time_id = t.time_id
                WHERE t.year = {match.group(1)} AND t.quarter = {match.group(2)}
                GROUP BY p.product_name, p.category
                ORDER BY total_sales DESC
            ''',
            r'(\d{4})å¹´Q(\d).*åœ°å€.*é¡å‹': lambda match: f'''
                SELECT r.region_name, r.region_type, SUM(f.amount) as total_sales
                FROM sales_fact f
                JOIN dim_region r ON f.region_id = r.region_id
                JOIN dim_time t ON f.time_id = t.time_id
                WHERE t.year = {match.group(1)} AND t.quarter = {match.group(2)}
                GROUP BY r.region_name, r.region_type
                ORDER BY total_sales DESC
            '''
        }
        
        for pattern, sql in query_patterns.items():
            match = re.search(pattern, natural_query)
            if match:
                if callable(sql):
                    return sql(match)
                else:
                    return sql
        
        # å¦‚æœæ²’æœ‰åŒ¹é…åˆ°é è¨­æ¨¡å¼ï¼Œæ ¹æ“šæŸ¥è©¢å…§å®¹æ™ºèƒ½æ¨æ¸¬
        query_lower = natural_query.lower()
        
        # è§£ææ™‚é–“æ¢ä»¶
        time_condition = ""
        year_match = re.search(r'(\d{4})å¹´', natural_query)
        month_match = re.search(r'(\d{1,2})æœˆ', natural_query)
        quarter_match = re.search(r'Q(\d)', natural_query)
        
        if year_match and month_match:
            time_condition = f"WHERE t.year = {year_match.group(1)} AND t.month = {month_match.group(1)}"
        elif year_match and quarter_match:
            time_condition = f"WHERE t.year = {year_match.group(1)} AND t.quarter = {quarter_match.group(1)}"
        elif year_match:
            time_condition = f"WHERE t.year = {year_match.group(1)}"
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«æ•¸é‡ç›¸é—œè©å½™
        if any(word in query_lower for word in ['æ•¸é‡', 'quantity', 'ä»¶æ•¸', 'å€‹æ•¸']):
            return f'''
                SELECT p.product_name, SUM(f.quantity) as total_quantity
                FROM sales_fact f
                JOIN dim_product p ON f.product_id = p.product_id
                {time_condition}
                GROUP BY p.product_name
                ORDER BY total_quantity DESC
            '''
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«é‡‘é¡ç›¸é—œè©å½™ï¼ˆä½†æ’é™¤å¤šç¶­åº¦æŸ¥è©¢ï¼‰
        elif (any(word in query_lower for word in ['é‡‘é¡', 'amount', 'éŠ·å”®é¡', 'ç‡Ÿæ¥­é¡', 'æ”¶å…¥']) and 
              not any(word in query_lower for word in ['å¹´', 'æœˆ', 'å­£', 'æ™‚é–“', 'æ—¥æœŸ', 'æ¯å¤©', 'æ¯æ—¥', 'æ—¥', 'æ¥­å‹™å“¡', 'éŠ·å”®å“¡', 'staff', 'æ¥­ç¸¾'])):
            return '''
                SELECT p.product_name, SUM(f.amount) as total_amount
                FROM sales_fact f
                JOIN dim_product p ON f.product_id = p.product_id
                GROUP BY p.product_name
                ORDER BY total_amount DESC
            '''
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«æ™‚é–“å’Œæ¥­å‹™å“¡ç›¸é—œè©å½™
        elif (any(word in query_lower for word in ['å¹´', 'æœˆ', 'å­£', 'æ™‚é–“', 'æ—¥æœŸ', 'æ¯å¤©', 'æ¯æ—¥', 'æ—¥']) and 
              any(word in query_lower for word in ['æ¥­å‹™å“¡', 'éŠ·å”®å“¡', 'staff', 'æ¥­ç¸¾'])):
            return f'''
                SELECT s.staff_name, t.date, SUM(f.amount) as daily_sales, SUM(f.quantity) as daily_quantity
                FROM sales_fact f
                JOIN dim_staff s ON f.staff_id = s.staff_id
                JOIN dim_time t ON f.time_id = t.time_id
                {time_condition}
                GROUP BY s.staff_name, t.date
                ORDER BY s.staff_name, t.date DESC
                LIMIT 20
            '''
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºæ¥­å‹™å“¡æ¥­ç¸¾æŸ¥è©¢ï¼ˆåŒ…å«æ™‚é–“æ¢ä»¶ï¼‰
        elif (any(word in query_lower for word in ['æ¥­å‹™å“¡', 'éŠ·å”®å“¡', 'staff', 'æ¥­ç¸¾']) and 
              (year and month)):
            return f'''
                SELECT s.staff_name, SUM(f.amount) as total_sales, SUM(f.quantity) as total_quantity
                FROM sales_fact f
                JOIN dim_staff s ON f.staff_id = s.staff_id
                JOIN dim_time t ON f.time_id = t.time_id
                WHERE t.year = {year} AND t.month = {month}
                GROUP BY s.staff_name
                ORDER BY total_sales DESC
            '''
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«æ™‚é–“å’Œç”¢å“ç›¸é—œè©å½™
        elif (any(word in query_lower for word in ['å¹´', 'æœˆ', 'å­£', 'æ™‚é–“', 'æ—¥æœŸ', 'æ¯å¤©', 'æ¯æ—¥', 'æ—¥']) and 
              any(word in query_lower for word in ['ç”¢å“', 'å•†å“', 'product'])):
            return f'''
                SELECT p.product_name, t.date, SUM(f.amount) as daily_sales, SUM(f.quantity) as daily_quantity
                FROM sales_fact f
                JOIN dim_product p ON f.product_id = p.product_id
                JOIN dim_time t ON f.time_id = t.time_id
                {time_condition}
                GROUP BY p.product_name, t.date
                ORDER BY p.product_name, t.date DESC
                LIMIT 20
            '''
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«æ™‚é–“å’Œå®¢æˆ¶ç›¸é—œè©å½™
        elif (any(word in query_lower for word in ['å¹´', 'æœˆ', 'å­£', 'æ™‚é–“', 'æ—¥æœŸ', 'æ¯å¤©', 'æ¯æ—¥', 'æ—¥']) and 
              any(word in query_lower for word in ['å®¢æˆ¶', 'customer', 'æ¶ˆè²»'])):
            return f'''
                SELECT c.customer_name, t.date, SUM(f.amount) as daily_consumption, SUM(f.quantity) as daily_quantity
                FROM sales_fact f
                JOIN dim_customer c ON f.customer_id = c.customer_id
                JOIN dim_time t ON f.time_id = t.time_id
                {time_condition}
                GROUP BY c.customer_name, t.date
                ORDER BY c.customer_name, t.date DESC
                LIMIT 20
            '''
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«æ™‚é–“å’Œåœ°å€ç›¸é—œè©å½™
        elif (any(word in query_lower for word in ['å¹´', 'æœˆ', 'å­£', 'æ™‚é–“', 'æ—¥æœŸ', 'æ¯å¤©', 'æ¯æ—¥', 'æ—¥']) and 
              any(word in query_lower for word in ['åœ°å€', 'å€åŸŸ', 'region', 'åœ°æ–¹'])):
            return f'''
                SELECT r.region_name, t.date, SUM(f.amount) as daily_sales, SUM(f.quantity) as daily_quantity
                FROM sales_fact f
                JOIN dim_region r ON f.region_id = r.region_id
                JOIN dim_time t ON f.time_id = t.time_id
                {time_condition}
                GROUP BY r.region_name, t.date
                ORDER BY r.region_name, t.date DESC
                LIMIT 20
            '''
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«æ™‚é–“ç›¸é—œè©å½™
        elif any(word in query_lower for word in ['å¹´', 'æœˆ', 'å­£', 'æ™‚é–“', 'æ—¥æœŸ', 'æ¯å¤©', 'æ¯æ—¥', 'æ—¥']):
            return f'''
                SELECT t.date, SUM(f.amount) as daily_sales, SUM(f.quantity) as daily_quantity
                FROM sales_fact f
                JOIN dim_time t ON f.time_id = t.time_id
                {time_condition}
                GROUP BY t.date
                ORDER BY t.date DESC
                LIMIT 20
            '''
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«ç”¢å“ç›¸é—œè©å½™
        elif any(word in query_lower for word in ['ç”¢å“', 'å•†å“', 'product']):
            return '''
                SELECT p.product_name, SUM(f.amount) as total_sales, SUM(f.quantity) as total_quantity
                FROM sales_fact f
                JOIN dim_product p ON f.product_id = p.product_id
                GROUP BY p.product_name
                ORDER BY total_sales DESC
            '''
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«å®¢æˆ¶ç›¸é—œè©å½™
        elif any(word in query_lower for word in ['å®¢æˆ¶', 'customer', 'æ¶ˆè²»']):
            return '''
                SELECT c.customer_name, SUM(f.amount) as total_consumption, SUM(f.quantity) as total_quantity
                FROM sales_fact f
                JOIN dim_customer c ON f.customer_id = c.customer_id
                GROUP BY c.customer_name
                ORDER BY total_consumption DESC
            '''
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«æ¥­å‹™å“¡ç›¸é—œè©å½™
        elif any(word in query_lower for word in ['æ¥­å‹™å“¡', 'éŠ·å”®å“¡', 'staff', 'æ¥­ç¸¾']):
            return '''
                SELECT s.staff_name, SUM(f.amount) as total_sales, SUM(f.quantity) as total_quantity
                FROM sales_fact f
                JOIN dim_staff s ON f.staff_id = s.staff_id
                GROUP BY s.staff_name
                ORDER BY total_sales DESC
            '''
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«åœ°å€ç›¸é—œè©å½™
        elif any(word in query_lower for word in ['åœ°å€', 'å€åŸŸ', 'region', 'åœ°æ–¹']):
            return '''
                SELECT r.region_name, SUM(f.amount) as total_sales, SUM(f.quantity) as total_quantity
                FROM sales_fact f
                JOIN dim_region r ON f.region_id = r.region_id
                GROUP BY r.region_name
                ORDER BY total_sales DESC
            '''
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«éŠ·å”®ç›¸é—œè©å½™
        elif any(word in query_lower for word in ['éŠ·å”®', 'é‡‘é¡', 'æ¥­ç¸¾', 'sales', 'amount', 'quantity']):
            return '''
                SELECT f.sale_id, f.amount, f.quantity, p.product_name, c.customer_name, s.staff_name, r.region_name, t.date
                FROM sales_fact f
                JOIN dim_product p ON f.product_id = p.product_id
                JOIN dim_customer c ON f.customer_id = c.customer_id
                JOIN dim_staff s ON f.staff_id = s.staff_id
                JOIN dim_region r ON f.region_id = r.region_id
                JOIN dim_time t ON f.time_id = t.time_id
                ORDER BY t.date DESC
                LIMIT 20
            '''
        
        # é è¨­è¿”å›ç”¢å“è¡¨
        else:
            return 'SELECT * FROM dim_product LIMIT 10'

    def _generate_analysis_summary(self, current_sales, last_sales, diff, percentage_diff, driver_data, dimension_text, period_text, other_dimension_reference=None):
        """
        ç”Ÿæˆåˆ†æç¸½çµå ±å‘Š (NLG - Natural Language Generation)
        æ–°å¢åƒæ•¸ other_dimension_reference: é¡¯ç¤ºå¤šç¶­åº¦åƒè€ƒåˆ†æ
        """
        print(f"ğŸ“ é–‹å§‹ç”Ÿæˆåˆ†æç¸½çµå ±å‘Š...")
        print(f"   è¼¸å…¥åƒæ•¸:")
        print(f"     - current_sales: {current_sales}")
        print(f"     - last_sales: {last_sales}")
        print(f"     - diff: {diff}")
        print(f"     - percentage_diff: {percentage_diff}")
        print(f"     - driver_data: {len(driver_data) if driver_data else 0} ç­†")
        print(f"     - dimension_text: {dimension_text}")
        print(f"     - period_text: {period_text}")
        
        # æ ¼å¼åŒ–æ•¸å­—
        def format_currency(amount):
            return f"{amount:,.0f}"
        
        # ç”Ÿæˆä¸»è¦è¶¨å‹¢æè¿°
        if diff > 0:
            trend = "æˆé•·"
            trend_emoji = "ğŸ“ˆ"
            if percentage_diff > 50:
                trend_intensity = "å¤§å¹…"
            elif percentage_diff > 20:
                trend_intensity = "æ˜é¡¯"
            else:
                trend_intensity = "å°å¹…"
        elif diff < 0:
            trend = "ä¸‹æ»‘"
            trend_emoji = "ğŸ“‰"
            if abs(percentage_diff) > 50:
                trend_intensity = "å¤§å¹…"
            elif abs(percentage_diff) > 20:
                trend_intensity = "æ˜é¡¯"
            else:
                trend_intensity = "å°å¹…"
        else:
            trend = "æŒå¹³"
            trend_emoji = "â¡ï¸"
            trend_intensity = ""

        # ç”Ÿæˆä¸»è¦è²¢ç»è€…æè¿°
        top_contributors = []
        if driver_data:
            # æ‰¾å‡ºè²¢ç»æœ€å¤§çš„é …ç›®ï¼ˆæ­£è²¢ç»ï¼‰
            positive_contributors = [item for item in driver_data if item['å·®ç•°'] > 0]
            if positive_contributors:
                positive_contributors.sort(key=lambda x: x['å·®ç•°'], reverse=True)
                top_positive = positive_contributors[0]
                top_contributors.append(f"<strong>{top_positive['åˆ†æç¶­åº¦']}</strong>è²¢ç»äº† {format_currency(top_positive['å·®ç•°'])} å…ƒ")

            # æ‰¾å‡ºå½±éŸ¿æœ€å¤§çš„é …ç›®ï¼ˆè² è²¢ç»ï¼‰
            negative_contributors = [item for item in driver_data if item['å·®ç•°'] < 0]
            if negative_contributors:
                negative_contributors.sort(key=lambda x: abs(x['å·®ç•°']), reverse=True)
                top_negative = negative_contributors[0]
                top_contributors.append(f"<strong>{top_negative['åˆ†æç¶­åº¦']}</strong>æ¸›å°‘äº† {format_currency(abs(top_negative['å·®ç•°']))} å…ƒ")

        # ç”Ÿæˆç¸½çµå ±å‘Š
        summary_parts = []
        
        # ä¸»è¦è¶¨å‹¢
        if trend_intensity:
            summary_parts.append(f"{trend_emoji} {period_text}æ¥­ç¸¾{trend_intensity}{trend}ï¼Œ")
        else:
            summary_parts.append(f"{trend_emoji} {period_text}æ¥­ç¸¾{trend}ï¼Œ")
        
        # å…·é«”æ•¸æ“š
        if percentage_diff != float('inf') and percentage_diff != float('-inf'):
            summary_parts.append(f"æœ¬æœŸéŠ·å”®é¡ç‚º {format_currency(current_sales)} å…ƒï¼Œ")
            summary_parts.append(f"è¼ƒå‰æœŸ {format_currency(last_sales)} å…ƒ")
            if diff > 0:
                summary_parts.append(f"å¢åŠ  {format_currency(diff)} å…ƒ")
            else:
                summary_parts.append(f"æ¸›å°‘ {format_currency(abs(diff))} å…ƒ")
            summary_parts.append(f"ï¼ˆ{percentage_diff:+.1f}%ï¼‰ã€‚")
        else:
            summary_parts.append(f"æœ¬æœŸéŠ·å”®é¡ç‚º {format_currency(current_sales)} å…ƒï¼Œ")
            if diff > 0:
                summary_parts.append(f"è¼ƒå‰æœŸå¢åŠ  {format_currency(diff)} å…ƒã€‚")
            else:
                summary_parts.append(f"è¼ƒå‰æœŸæ¸›å°‘ {format_currency(abs(diff))} å…ƒã€‚")

        # ä¸»è¦è²¢ç»è€…
        if top_contributors:
            summary_parts.append("<br><br>ğŸ“Š <strong>ä¸»è¦è²¢ç»åˆ†æï¼š</strong>")
            summary_parts.append(" ".join(top_contributors))
        # æ–°å¢ï¼šå¤šç¶­åº¦åƒè€ƒåˆ†æ
        if other_dimension_reference:
            summary_parts.append("<br><br>ğŸ” <strong>å…¶ä»–ç¶­åº¦åƒè€ƒåˆ†æï¼š</strong><br>")
            summary_parts.append(other_dimension_reference)

        # å»ºè­°
        summary_parts.append("<br><br>ğŸ’¡ <strong>å»ºè­°ï¼š</strong>")
        
        if diff > 0:
            # æ•´é«”æˆé•·çš„æƒ…æ³
            if positive_contributors:
                summary_parts.append("æŒçºŒé—œæ³¨è¡¨ç¾å„ªç•°çš„é …ç›®ï¼Œå¯è€ƒæ…®æ“´å¤§ç›¸é—œæ¥­å‹™ã€‚")
            
            # å¦‚æœæœ‰è² é¢è²¢ç»è€…ï¼Œä¹Ÿè¦æä¾›æ”¹å–„å»ºè­°
            if negative_contributors:
                summary_parts.append("åŒæ™‚é‡å°è¡¨ç¾ä¸ä½³çš„é …ç›®åˆ¶å®šæ”¹å–„è¨ˆåŠƒï¼ŒåŠ å¼·è¡ŒéŠ·æ¨å»£ã€‚")
        else:
            # æ•´é«”ä¸‹æ»‘çš„æƒ…æ³
            if negative_contributors:
                summary_parts.append("é‡å°è¡¨ç¾ä¸ä½³çš„é …ç›®åˆ¶å®šæ”¹å–„è¨ˆåŠƒï¼ŒåŠ å¼·è¡ŒéŠ·æ¨å»£ã€‚")
            else:
                summary_parts.append("æª¢è¦–æ•´é«”ç‡Ÿé‹ç­–ç•¥ï¼Œå°‹æ‰¾æ–°çš„æˆé•·æ©Ÿæœƒã€‚")
        
        # é‡å°å…·é«”è² é¢è²¢ç»è€…æä¾›æ”¹å–„å»ºè­°
        if negative_contributors:
            summary_parts.append("<br><br>ğŸ¯ <strong>å…·é«”æ”¹å–„å»ºè­°ï¼š</strong>")
            for contributor in negative_contributors[:2]:  # æœ€å¤šé¡¯ç¤ºå‰2å€‹
                contributor_name = contributor['åˆ†æç¶­åº¦']
                loss_amount = abs(contributor['å·®ç•°'])
                improvement_suggestions = self._get_dimension_specific_suggestions(contributor_name, loss_amount)
                
                summary_parts.append(f"<br>â€¢ <strong>{contributor_name}</strong>ï¼š")
                summary_parts.append(f"æ¥­ç¸¾ä¸‹æ»‘ {format_currency(loss_amount)} å…ƒï¼Œ")
                summary_parts.append(improvement_suggestions)

        final_summary = "".join(summary_parts)
        print(f"   ç”Ÿæˆçš„ç¸½çµå ±å‘Šé•·åº¦: {len(final_summary)} å­—å…ƒ")
        print(f"   ç¸½çµå ±å‘Šé è¦½: {final_summary[:200]}...")
        
        return final_summary

    def _get_dimension_specific_suggestions(self, dimension_name, loss_amount):
        """
        æ ¹æ“šç¶­åº¦é¡å‹æä¾›é‡å°æ€§çš„æ”¹å–„å»ºè­°
        """
        # æ ¼å¼åŒ–é‡‘é¡
        def format_currency(amount):
            return f"{amount:,.0f}"
        
        # æ ¹æ“šç¶­åº¦åç¨±åˆ¤æ–·é¡å‹ä¸¦æä¾›ç›¸æ‡‰å»ºè­°
        dimension_lower = dimension_name.lower()
        
        # ç”¢å“ç›¸é—œç¶­åº¦
        if any(keyword in dimension_lower for keyword in ['ç­†è¨˜å‹é›»è…¦', 'é›»è…¦', 'laptop', 'notebook', 'è€³æ©Ÿ', 'è—ç‰™', 'ç„¡ç·š', 'æ‰‹æ©Ÿ', 'å¹³æ¿', 'tablet', 'smartphone']):
            if loss_amount > 10000:
                return f"å»ºè­°ï¼š1) ã€Œ{dimension_name} ç”¢å“ç‡ŸéŠ·ç­–ç•¥ 2024ã€äº†è§£æœ€æ–°è¶¨å‹¢ï¼›2) ã€Œé›»å•†å¹³å° A/B æ¸¬è©¦æ¡ˆä¾‹ã€å„ªåŒ–ç”¢å“é é¢ï¼›3) ã€Œ{dimension_name} ç”¨æˆ¶è©•åƒ¹ç®¡ç†ã€å»ºç«‹å£ç¢‘ï¼›4) ã€Œåˆ†æœŸä»˜æ¬¾ä¿ƒéŠ·æ–¹æ¡ˆã€æå‡è³¼è²·æ„é¡˜ï¼›5) ã€Œå”®å¾Œæœå‹™æ¨™æº–æµç¨‹ã€æå‡å®¢æˆ¶æ»¿æ„åº¦ï¼›6) ã€Œç”¢å“ç”Ÿæ…‹ç³»çµ±å»ºè¨­ã€æå‡ç”¨æˆ¶é»æ€§ã€‚"
            else:
                return f"å»ºè­°ï¼š1) ã€Œ{dimension_name} ç”¢å“å±•ç¤ºå„ªåŒ–ã€æ”¹å–„é é¢ï¼›2) ã€Œå…è²»è©¦ç”¨é€€æ›è²¨æ”¿ç­–ã€é™ä½è³¼è²·é–€æª»ï¼›3) ã€Œæœƒå“¡ç©åˆ†ç­‰ç´šåˆ¶åº¦è¨­è¨ˆã€æå‡å¿ èª åº¦ï¼›4) ã€Œç¤¾ç¾¤åª’é«”æ¨å»£ç­–ç•¥ã€æ“´å¤§å½±éŸ¿åŠ›ï¼›5) ã€ŒæŠ€è¡“è«®è©¢æœå‹™æ¨™æº–ã€æå‡å°ˆæ¥­åº¦ï¼›6) ã€Œå­£ç¯€æ€§ä¿ƒéŠ·æ´»å‹•ç­–åŠƒã€æå‡éŠ·é‡ã€‚"
        
        # äººå“¡ç›¸é—œç¶­åº¦
        elif any(keyword in dimension_lower for keyword in ['ç‹å°æ˜', 'æç¾éº—', 'å¼µä¸‰', 'æå››', 'æ¥­å‹™å“¡', 'éŠ·å”®å“¡', 'sales', 'æ¥­å‹™', 'äººå“¡']):
            if loss_amount > 50000:
                return f"å»ºè­°ï¼š1) ã€ŒSPIN éŠ·å”®æŠ€å·§åŸ¹è¨“èª²ç¨‹ã€æå‡éŠ·å”®èƒ½åŠ›ï¼›2) ã€ŒéŠ·å”®æ¼æ–—ç®¡ç†ç³»çµ±ã€å„ªåŒ–æµç¨‹ï¼›3) ã€ŒCRM ç³»çµ±åŠŸèƒ½æ¯”è¼ƒã€é¸æ“‡åˆé©å·¥å…·ï¼›4) ã€Œéšæ¢¯å¼ç¸¾æ•ˆçå‹µåˆ¶åº¦è¨­è¨ˆã€æ¿€å‹µåœ˜éšŠï¼›5) ã€ŒéŠ·å”®åœ˜éšŠå”ä½œæ©Ÿåˆ¶ã€æå‡æ•ˆç‡ï¼›6) ã€Œè·æ¥­ç™¼å±•è·¯å¾‘è¦åŠƒã€ç•™ä½äººæ‰ã€‚"
            else:
                return f"å»ºè­°ï¼š1) ã€Œå®¢æˆ¶é—œä¿‚ç®¡ç†åŸ¹è¨“èª²ç¨‹ã€æå‡æœå‹™ï¼›2) ã€Œå€‹äººå“ç‰Œå»ºè¨­æ–¹æ³•ã€æå‡å½¢è±¡ï¼›3) ã€Œæ™‚é–“ç®¡ç†æ•ˆç‡æå‡æŠ€å·§ã€å„ªåŒ–å·¥ä½œï¼›4) ã€Œæºé€šæŠ€å·§è«‡åˆ¤èƒ½åŠ›åŸ¹è¨“ã€æå‡æŠ€èƒ½ï¼›5) ã€Œå€‹äºº KPI ç›®æ¨™ç®¡ç†æ–¹æ³•ã€æ˜ç¢ºæ–¹å‘ï¼›6) ã€Œå°å¸«åˆ¶åº¦ç¶“é©—åˆ†äº«æ©Ÿåˆ¶ã€ä¿ƒé€²æˆé•·ã€‚"
        
        # åœ°å€ç›¸é—œç¶­åº¦
        elif any(keyword in dimension_lower for keyword in ['å°åŒ—', 'å°ä¸­', 'å°å—', 'é«˜é›„', 'æ¡ƒåœ’', 'æ–°ç«¹', 'åœ°å€', 'region', 'city', 'ç¸£å¸‚']):
            if loss_amount > 20000:
                return f"å»ºè­°ï¼š1) ã€Œ{dimension_name} å¸‚å ´èª¿ç ”ç«¶çˆ­åˆ†æã€äº†è§£å¸‚å ´ï¼›2) ã€Œåœ¨åœ°åŒ–ä¾›æ‡‰éˆç‰©æµé«”ç³»ã€å„ªåŒ–é…é€ï¼›3) ã€Œ{dimension_name} ç‰¹è‰²ç”¢å“æœå‹™è¨­è¨ˆã€å·®ç•°åŒ–ç«¶çˆ­ï¼›4) ã€Œåœ¨åœ°ç¤¾ç¾¤åƒèˆ‡å“ç‰Œå»ºè¨­ã€æå‡çŸ¥ååº¦ï¼›5) ã€Œåœ°å€å·®ç•°åŒ–å®šåƒ¹ç­–ç•¥ã€æå‡ç«¶çˆ­åŠ›ï¼›6) ã€Œåœ°å€å®¢æˆ¶é—œä¿‚ç®¡ç†æ–¹æ³•ã€æå‡æœå‹™ã€‚"
            else:
                return f"å»ºè­°ï¼š1) ã€Œ{dimension_name} åª’é«”å®£å‚³å»£å‘ŠæŠ•æ”¾ã€æ“´å¤§å½±éŸ¿ï¼›2) ã€Œåœ°å€å®¢æˆ¶æœå‹™ä¸­å¿ƒå»ºè¨­ã€æå‡æœå‹™ï¼›3) ã€Œ{dimension_name} åœ¨åœ°åŒ–ç”¢å“æœå‹™ã€æ»¿è¶³éœ€æ±‚ï¼›4) ã€Œåœ°å€æœƒå“¡å„ªæƒ å¿ èª åº¦è¨ˆåŠƒã€æå‡é»æ€§ï¼›5) ã€Œç¤¾ç¾¤åª’é«”åœ¨åœ°æ¨å»£ç­–ç•¥ã€æ“´å¤§å½±éŸ¿ï¼›6) ã€Œåœ°å€åˆä½œå¤¥ä¼´é—œä¿‚å»ºç«‹ã€å…±åŒç™¼å±•ã€‚"
        
        # æ™‚é–“ç›¸é—œç¶­åº¦
        elif any(keyword in dimension_lower for keyword in ['ä¸€æœˆ', 'äºŒæœˆ', 'ä¸‰æœˆ', 'å››æœˆ', 'äº”æœˆ', 'å…­æœˆ', 'ä¸ƒæœˆ', 'å…«æœˆ', 'ä¹æœˆ', 'åæœˆ', 'åä¸€æœˆ', 'åäºŒæœˆ', 'month', 'å­£åº¦', 'quarter']):
            if loss_amount > 15000:
                return f"å»ºè­°ï¼š1) ã€Œ{dimension_name} å­£ç¯€æ€§é æ¸¬æ¨¡å‹ã€åˆ†æè¶¨å‹¢ï¼›2) ã€Œæ·¡æ—ºå­£å·®ç•°åŒ–ç‡ŸéŠ·ç­–ç•¥ã€å„ªåŒ–ç­–ç•¥ï¼›3) ã€Œè·¨å­£ç¯€ç”¢å“çµ„åˆæ¨å»£ã€æå‡éŠ·é‡ï¼›4) ã€Œå­£ç¯€æ€§å®¢æˆ¶éœ€æ±‚é æ¸¬ã€ç²¾æº–ç‡ŸéŠ·ï¼›5) ã€Œåº«å­˜ç®¡ç†ä¾›æ‡‰éˆå„ªåŒ–ã€é™ä½æˆæœ¬ï¼›6) ã€Œç¯€æ…¶æ´»å‹•ä¸»é¡Œç‡ŸéŠ·ç­–åŠƒã€æå‡æ•ˆæœã€‚"
            else:
                return f"å»ºè­°ï¼š1) ã€Œæ•æ·ç‡ŸéŠ·å¿«é€ŸéŸ¿æ‡‰æ©Ÿåˆ¶ã€æå‡æ•ˆç‡ï¼›2) ã€Œæ™‚é–“åºåˆ—åˆ†æé æ¸¬æ–¹æ³•ã€å„ªåŒ–æ±ºç­–ï¼›3) ã€Œç‡ŸéŠ·æ´»å‹•æ™‚ç¨‹å®‰æ’å„ªåŒ–ã€æå‡æ•ˆæœï¼›4) ã€Œæ™‚æ•ˆæ€§å…§å®¹ç‡ŸéŠ·ç­–ç•¥ã€æŠ“ä½æ©Ÿæœƒï¼›5) ã€Œæ™‚é–“æ•æ„Ÿå‹ä¿ƒéŠ·ç­–ç•¥ã€æå‡è½‰åŒ–ï¼›6) ã€Œæ™‚é–“ç®¡ç†æ•ˆç‡ç›£æ§æ–¹æ³•ã€æŒçºŒæ”¹å–„ã€‚"
        
        # å®¢æˆ¶ç›¸é—œç¶­åº¦
        elif any(keyword in dimension_lower for keyword in ['å®¢æˆ¶', 'customer', 'å®¢æˆ¶ç¾¤', 'å®¢æˆ¶é¡å‹', 'vip', 'ä¸€èˆ¬å®¢æˆ¶']):
            if loss_amount > 25000:
                return f"å»ºè­°ï¼š1) ã€Œå®¢æˆ¶ç”Ÿå‘½é€±æœŸç®¡ç†é«”ç³»ã€å®Œå–„æµç¨‹ï¼›2) ã€Œå€‹æ€§åŒ–æ¨è–¦å…§å®¹ç­–å±•ã€æå‡é«”é©—ï¼›3) ã€ŒVIP å°ˆå±¬æœå‹™æ¬Šç›Šè¨­è¨ˆã€æå‡åƒ¹å€¼ï¼›4) ã€Œå®¢æˆ¶æˆåŠŸæŒ‡æ¨™ç›£æ§æ–¹æ³•ã€é‡åŒ–æ•ˆæœï¼›5) ã€Œå®¢æˆ¶åˆ†å±¤å·®ç•°åŒ–æœå‹™ã€ç²¾æº–æœå‹™ï¼›6) ã€Œå®¢æˆ¶åé¥‹æ”¶é›†å¿«é€ŸéŸ¿æ‡‰ã€æå‡æ»¿æ„åº¦ã€‚"
            else:
                return f"å»ºè­°ï¼š1) ã€Œå®¢æˆ¶ç•«åƒè¡Œç‚ºåˆ†ææ–¹æ³•ã€äº†è§£éœ€æ±‚ï¼›2) ã€Œå€‹æ€§åŒ–æºé€šæœå‹™ç­–ç•¥ã€æå‡é«”é©—ï¼›3) ã€Œå®¢æˆ¶å¿ èª åº¦å›é¥‹è¨ˆåŠƒè¨­è¨ˆã€æå‡é»æ€§ï¼›4) ã€Œç¤¾ç¾¤åª’é«”äº’å‹•åƒèˆ‡ç­–ç•¥ã€æ“´å¤§å½±éŸ¿ï¼›5) ã€Œå®¢æˆ¶æ•™è‚²åƒ¹å€¼å‚³éæ–¹æ³•ã€æå‡èªçŸ¥ï¼›6) ã€Œå®¢æˆ¶æŒ½å›ç•™å­˜ç­–ç•¥ã€é™ä½æµå¤±ã€‚"
        
        # æ¸ é“ç›¸é—œç¶­åº¦
        elif any(keyword in dimension_lower for keyword in ['ç·šä¸Š', 'ç·šä¸‹', 'online', 'offline', 'é›»å•†', 'å¯¦é«”åº—', 'é€šè·¯', 'channel']):
            if loss_amount > 30000:
                return f"å»ºè­°ï¼š1) ã€ŒO2O ç„¡ç¸«æ•´åˆé«”é©—è¨­è¨ˆã€æå‡é«”é©—ï¼›2) ã€Œå…¨æ¸ é“åº«å­˜ç®¡ç†ç³»çµ±ã€å„ªåŒ–é‹ç‡Ÿï¼›3) ã€Œç·šä¸Šé ç´„ç·šä¸‹é«”é©—æœå‹™ã€æå‡è½‰åŒ–ï¼›4) ã€Œè·¨æ¸ é“æœƒå“¡æ¬Šç›Šæ•´åˆã€æå‡åƒ¹å€¼ï¼›5) ã€Œæ¸ é“ç¸¾æ•ˆç›£æ§å„ªåŒ–æ–¹æ³•ã€æå‡æ•ˆç‡ï¼›6) ã€Œæ•¸ä½åŒ–è½‰å‹æŠ€è¡“å‡ç´šã€æå‡ç«¶çˆ­åŠ›ã€‚"
            else:
                return f"å»ºè­°ï¼š1) ã€Œæ¸ é“çµæ§‹æ•ˆç‡å„ªåŒ–æ–¹æ³•ã€æå‡æ•ˆç‡ï¼›2) ã€Œæ¸ é“åˆä½œå¤¥ä¼´é—œä¿‚ç®¡ç†ã€å…±åŒç™¼å±•ï¼›3) ã€Œæ¸ é“åŸ¹è¨“æ”¯æ´é«”ç³»å»ºè¨­ã€æå‡èƒ½åŠ›ï¼›4) ã€Œæ¸ é“æ¿€å‹µçå‹µåˆ¶åº¦è¨­è¨ˆã€æå‡ç©æ¥µæ€§ï¼›5) ã€Œæ¸ é“æ•¸æ“šåˆ†ææ´å¯Ÿæ–¹æ³•ã€å„ªåŒ–æ±ºç­–ï¼›6) ã€Œæ¸ é“å‰µæ–°ç™¼å±•ç­–ç•¥ã€æå‡ç«¶çˆ­åŠ›ã€‚"
        
        # é è¨­å»ºè­°ï¼ˆé©ç”¨æ–¼å…¶ä»–ç¶­åº¦ï¼‰
        else:
            if loss_amount > 20000:
                return f"å»ºè­°ï¼š1) ã€ŒMcKinsey 7S æ¨¡å‹æ‡‰ç”¨æ¡ˆä¾‹ã€ç³»çµ±æ”¹å–„ï¼›2) ã€Œæ•¸æ“šé©…å‹•æ±ºç­–åˆ¶å®šæ–¹æ³•ã€å„ªåŒ–æ±ºç­–ï¼›3) ã€ŒæŒçºŒæ”¹å–„å‰µæ–°æ–‡åŒ–å»ºè¨­ã€æå‡ç«¶çˆ­åŠ›ï¼›4) ã€Œçµ„ç¹”çµæ§‹æµç¨‹è¨­è¨ˆå„ªåŒ–ã€æå‡æ•ˆç‡ï¼›5) ã€Œäººæ‰ç™¼å±•èƒ½åŠ›å»ºè¨­æ–¹æ³•ã€æå‡åœ˜éšŠï¼›6) ã€Œé¢¨éšªç®¡ç†æ‡‰æ€¥é æ¡ˆåˆ¶å®šã€é™ä½é¢¨éšªã€‚"
            else:
                return f"å»ºè­°ï¼š1) ã€Œæ•æ·ç®¡ç†å¿«é€Ÿè¿­ä»£æ–¹æ³•ã€æå‡æ•ˆç‡ï¼›2) ã€ŒKPI ç›£æ§ç¸¾æ•ˆç®¡ç†ç³»çµ±ã€å„ªåŒ–ç®¡ç†ï¼›3) ã€Œåœ˜éšŠå”ä½œæºé€šæ•ˆç‡æå‡ã€æ”¹å–„åˆä½œï¼›4) ã€Œå“¡å·¥åŸ¹è¨“ç™¼å±•æ©Ÿæœƒè¨­è¨ˆã€æå‡èƒ½åŠ›ï¼›5) ã€Œå®¢æˆ¶å°å‘æœå‹™æ–‡åŒ–å»ºè¨­ã€æå‡é«”é©—ï¼›6) ã€ŒæŒçºŒæ”¹å–„å‰µæ–°æ©Ÿåˆ¶è¨­è¨ˆã€æå‡ç«¶çˆ­åŠ›ã€‚" 

    def generate_professional_report(self, analysis_context=None, report_type="general", chat_context=None):
        """
        ç”Ÿæˆå°ˆæ¥­å»ºè­°å ±å‘Šæ›¸
        åŒ…å«ï¼šä¸»æ—¨ã€åˆ†æèªªæ˜ã€æ”¹å–„å»ºè­°ã€è¦åŠƒæ™‚ç¨‹ã€çµè«–
        åŸºæ–¼ AI å°è«‡å…§å®¹ç”Ÿæˆå€‹æ€§åŒ–ä¸»æ—¨
        """
        try:
            import google.generativeai as genai
            import os
            
            # è¨­å®š Gemini API Key
            api_key = os.getenv('GEMINI_API_KEY')
            if not api_key:
                return self._generate_fallback_report(analysis_context, report_type, chat_context)
            
            # é…ç½® Gemini
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel('gemini-1.5-pro')
            
            # æ§‹å»ºåˆ†æèƒŒæ™¯
            context_parts = []
            if analysis_context:
                context_parts.append(f"åˆ†ææœŸé–“ï¼š{analysis_context.get('period_text', 'N/A')}")
                context_parts.append(f"ç•¶æœŸéŠ·å”®ï¼š{analysis_context.get('current_sales', 0):,.0f} å…ƒ")
                context_parts.append(f"å‰æœŸéŠ·å”®ï¼š{analysis_context.get('last_sales', 0):,.0f} å…ƒ")
                context_parts.append(f"å·®ç•°ï¼š{analysis_context.get('diff', 0):,.0f} å…ƒ")
                context_parts.append(f"ç™¾åˆ†æ¯”å·®ç•°ï¼š{analysis_context.get('percentage_diff', 0):.1f}%")
                context_parts.append(f"åˆ†æç¶­åº¦ï¼š{analysis_context.get('dimension_text', 'N/A')}")
                if analysis_context.get('driver_data'):
                    top_contributors = []
                    for item in analysis_context['driver_data'][:5]:
                        if item['å·®ç•°'] > 0:
                            top_contributors.append(f"{item['åˆ†æç¶­åº¦']}(+{item['å·®ç•°']:,.0f})")
                        else:
                            top_contributors.append(f"{item['åˆ†æç¶­åº¦']}({item['å·®ç•°']:,.0f})")
                    context_parts.append(f"ä¸»è¦è²¢ç»è€…ï¼š{', '.join(top_contributors)}")
                # æ–°å¢ï¼šå¤šç¶­åº¦åƒè€ƒåˆ†æ
                if analysis_context.get('other_dimension_reference'):
                    context_parts.append(f"å…¶ä»–ç¶­åº¦åƒè€ƒåˆ†æï¼š<br>{analysis_context['other_dimension_reference']}")
            
            # æ§‹å»ºèŠå¤©å°è©±èƒŒæ™¯
            chat_background = ""
            if chat_context and len(chat_context) > 0:
                chat_background = "\n\nAI å°è«‡å…§å®¹ï¼š\n"
                for i, msg in enumerate(chat_context[-10:], 1):  # åªå–æœ€è¿‘10æ¢å°è©±
                    role = "ç”¨æˆ¶" if msg.get('role') == 'user' else "AIå°ˆå®¶"
                    content = msg.get('content', '')
                    chat_background += f"{i}. {role}ï¼š{content}\n"
            
            # æ ¹æ“šå ±å‘Šé¡å‹è¨­å®šä¸åŒçš„æç¤ºè©
            if report_type == "performance":
                report_focus = "éŠ·å”®ç¸¾æ•ˆåˆ†æèˆ‡æ”¹å–„"
            elif report_type == "strategy":
                report_focus = "ç¶“ç‡Ÿç­–ç•¥è¦åŠƒèˆ‡å»ºè­°"
            elif report_type == "risk":
                report_focus = "é¢¨éšªè©•ä¼°èˆ‡ç®¡ç†å»ºè­°"
            else:
                report_focus = "ç¶œåˆç¶“ç‡Ÿåˆ†æèˆ‡å»ºè­°"
            
            # æ§‹å»ºå°ˆæ¥­å ±å‘Šæç¤ºè©
            system_prompt = f"""
ä½ æ˜¯ä¸€ä½è³‡æ·±çš„ç¶“ç‡Ÿåˆ†æé¡§å•ï¼Œæ“æœ‰è±å¯Œçš„å•†æ¥­è«®è©¢ç¶“é©—ã€‚è«‹åŸºæ–¼ä»¥ä¸‹åˆ†ææ•¸æ“šå’Œ AI å°è«‡å…§å®¹ï¼Œç”Ÿæˆä¸€ä»½å°ˆæ¥­çš„å»ºè­°å ±å‘Šæ›¸ã€‚

åˆ†æèƒŒæ™¯ï¼š
{chr(10).join(context_parts) if context_parts else 'åŸºæ–¼ä¸€èˆ¬ç¶“ç‡Ÿåˆ†æéœ€æ±‚'}

{chat_background}

å ±å‘Šé‡é»ï¼š{report_focus}

è«‹ç”Ÿæˆä¸€ä»½åŒ…å«ä»¥ä¸‹äº”å€‹éƒ¨åˆ†çš„å°ˆæ¥­å ±å‘Šæ›¸ï¼š

## ä¸€ã€ä¸»æ—¨
åŸºæ–¼ AI å°è«‡å…§å®¹å’Œç”¨æˆ¶é—œæ³¨é»ï¼Œç”Ÿæˆå€‹æ€§åŒ–çš„å ±å‘Šä¸»æ—¨ã€‚ä¸»æ—¨æ‡‰è©²ï¼š
- åæ˜ ç”¨æˆ¶åœ¨å°è©±ä¸­è¡¨é”çš„ä¸»è¦é—œåˆ‡å’Œéœ€æ±‚
- çµåˆåˆ†ææ•¸æ“šçš„é—œéµç™¼ç¾
- æ˜ç¢ºèªªæ˜å ±å‘Šçš„æ ¸å¿ƒç›®çš„å’Œé‡é»åˆ†æå…§å®¹
- é«”ç¾å€‹æ€§åŒ–çš„è«®è©¢å»ºè­°æ–¹å‘

## äºŒã€åˆ†æèªªæ˜
åŸºæ–¼æ•¸æ“šé€²è¡Œæ·±å…¥åˆ†æï¼ŒåŒ…æ‹¬ï¼š
- ç¸¾æ•ˆè¡¨ç¾è©•ä¼°
- é—œéµæŒ‡æ¨™åˆ†æ
- è¶¨å‹¢è®ŠåŒ–èªªæ˜
- å½±éŸ¿å› ç´ åˆ†æ
- çµåˆå°è«‡ä¸­æåˆ°çš„å…·é«”å•é¡Œå’Œé—œæ³¨é»

## ä¸‰ã€æ”¹å–„å»ºè­°
æä¾›å…·é«”å¯åŸ·è¡Œçš„æ”¹å–„æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ï¼š
- çŸ­æœŸæ”¹å–„æªæ–½ï¼ˆ1-3å€‹æœˆï¼‰
- ä¸­æœŸç­–ç•¥èª¿æ•´ï¼ˆ3-6å€‹æœˆï¼‰
- é•·æœŸç™¼å±•è¦åŠƒï¼ˆ6-12å€‹æœˆï¼‰
- é‡å°å°è«‡ä¸­æåˆ°çš„å…·é«”å•é¡Œæä¾›è§£æ±ºæ–¹æ¡ˆ

## å››ã€è¦åŠƒæ™‚ç¨‹
åˆ¶å®šè©³ç´°çš„åŸ·è¡Œæ™‚ç¨‹è¡¨ï¼š
- ç¬¬ä¸€éšæ®µï¼ˆ1-2å€‹æœˆï¼‰ï¼šç«‹å³è¡Œå‹•é …ç›®
- ç¬¬äºŒéšæ®µï¼ˆ3-4å€‹æœˆï¼‰ï¼šç­–ç•¥èª¿æ•´é …ç›®
- ç¬¬ä¸‰éšæ®µï¼ˆ5-6å€‹æœˆï¼‰ï¼šé•·æœŸè¦åŠƒé …ç›®
- å„éšæ®µé—œéµé‡Œç¨‹ç¢‘å’ŒæˆåŠŸæŒ‡æ¨™

## äº”ã€çµè«–
ç¸½çµå ±å‘Šè¦é»ï¼Œå¼·èª¿é—œéµå»ºè­°å’Œé æœŸæˆæ•ˆï¼Œä¸¦å›æ‡‰å°è«‡ä¸­çš„æ ¸å¿ƒé—œåˆ‡ã€‚

è¦æ±‚ï¼š
1. ä½¿ç”¨å°ˆæ¥­ä½†æ˜“æ‡‚çš„èªè¨€
2. æä¾›å…·é«”å¯åŸ·è¡Œçš„å»ºè­°
3. åŒ…å«é‡åŒ–çš„ç›®æ¨™å’ŒæŒ‡æ¨™
4. è€ƒæ…®å¯¦éš›åŸ·è¡Œå¯è¡Œæ€§
5. å…¨ç¨‹ä½¿ç”¨ç¹é«”ä¸­æ–‡
6. å ±å‘Šç¸½é•·åº¦æ§åˆ¶åœ¨800-1200å­—
7. çµæ§‹æ¸…æ™°ï¼Œé‡é»çªå‡º
8. ä¸»æ—¨å¿…é ˆåŸºæ–¼å°è«‡å…§å®¹å€‹æ€§åŒ–ç”Ÿæˆ
9. å»ºè­°è¦é‡å°å°è«‡ä¸­æåˆ°çš„å…·é«”å•é¡Œ

è«‹ç”Ÿæˆå®Œæ•´çš„å°ˆæ¥­å ±å‘Šæ›¸ï¼š
"""

            # èª¿ç”¨ Gemini API
            response = model.generate_content(system_prompt)
            
            return {
                'success': True,
                'report': response.text,
                'model': 'gemini-pro',
                'report_type': report_type,
                'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'chat_context_used': len(chat_context) if chat_context else 0
            }
            
        except ImportError:
            return self._generate_fallback_report(analysis_context, report_type, chat_context)
        except Exception as e:
            return {
                'success': False,
                'error': f'å°ˆæ¥­å ±å‘Šç”Ÿæˆå¤±æ•—ï¼š{str(e)}'
            }

    def _generate_fallback_report(self, analysis_context=None, report_type="general", chat_context=None):
        """
        å‚™ç”¨å°ˆæ¥­å ±å‘Šç”Ÿæˆï¼ˆç•¶ Gemini API ä¸å¯ç”¨æ™‚ï¼‰
        """
        try:
            # æ§‹å»ºåˆ†æèƒŒæ™¯
            context_parts = []
            if analysis_context:
                context_parts.append(f"åˆ†ææœŸé–“ï¼š{analysis_context.get('period_text', 'N/A')}")
                context_parts.append(f"ç•¶æœŸéŠ·å”®ï¼š{analysis_context.get('current_sales', 0):,.0f} å…ƒ")
                context_parts.append(f"å‰æœŸéŠ·å”®ï¼š{analysis_context.get('last_sales', 0):,.0f} å…ƒ")
                context_parts.append(f"å·®ç•°ï¼š{analysis_context.get('diff', 0):,.0f} å…ƒ")
                context_parts.append(f"ç™¾åˆ†æ¯”å·®ç•°ï¼š{analysis_context.get('percentage_diff', 0):.1f}%")
                context_parts.append(f"åˆ†æç¶­åº¦ï¼š{analysis_context.get('dimension_text', 'N/A')}")
                # æ–°å¢ï¼šå¤šç¶­åº¦åƒè€ƒåˆ†æ
                if analysis_context.get('other_dimension_reference'):
                    context_parts.append(f"å…¶ä»–ç¶­åº¦åƒè€ƒåˆ†æï¼š<br>{analysis_context['other_dimension_reference']}")
            
            # æ§‹å»ºèŠå¤©èƒŒæ™¯
            chat_summary = ""
            if chat_context and len(chat_context) > 0:
                # æå–å°è«‡ä¸­çš„é—œéµå•é¡Œå’Œé—œæ³¨é»
                key_topics = []
                for msg in chat_context[-5:]:  # å–æœ€è¿‘5æ¢å°è©±
                    if msg.get('role') == 'user':
                        content = msg.get('content', '')
                        # ç°¡å–®æå–é—œéµè©
                        if any(word in content for word in ['æ”¹å–„', 'æå‡', 'å•é¡Œ', 'å»ºè­°']):
                            key_topics.append(content[:50] + "...")
                
                if key_topics:
                    chat_summary = f"\n\nç”¨æˆ¶é—œæ³¨é‡é»ï¼š{', '.join(key_topics)}"
            
            # æ ¹æ“šå ±å‘Šé¡å‹ç”Ÿæˆä¸åŒçš„å ±å‘Šæ¨¡æ¿
            if report_type == "performance":
                report = self._generate_performance_report_template(context_parts, chat_summary)
            elif report_type == "strategy":
                report = self._generate_strategy_report_template(context_parts, chat_summary)
            elif report_type == "risk":
                report = self._generate_risk_report_template(context_parts, chat_summary)
            else:
                report = self._generate_general_report_template(context_parts, chat_summary)
            
            return {
                'success': True,
                'report': report,
                'model': 'fallback',
                'report_type': report_type,
                'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'chat_context_used': len(chat_context) if chat_context else 0
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'å‚™ç”¨å ±å‘Šç”Ÿæˆå¤±æ•—ï¼š{str(e)}'
            }

    def _generate_performance_report_template(self, context_parts, chat_summary=""):
        """ç”Ÿæˆç¸¾æ•ˆåˆ†æå ±å‘Šæ¨¡æ¿"""
        # æ ¹æ“šèŠå¤©å…§å®¹èª¿æ•´ä¸»æ—¨
        if chat_summary:
            purpose = f"æœ¬å ±å‘Šæ—¨åœ¨åˆ†æç•¶å‰éŠ·å”®ç¸¾æ•ˆè¡¨ç¾ï¼Œä¸¦é‡å°ç”¨æˆ¶åœ¨å°è«‡ä¸­æåˆ°çš„å…·é«”å•é¡Œ{chat_summary}ï¼Œæä¾›å€‹æ€§åŒ–çš„æ”¹å–„å»ºè­°ã€‚"
        else:
            purpose = "æœ¬å ±å‘Šæ—¨åœ¨åˆ†æç•¶å‰éŠ·å”®ç¸¾æ•ˆè¡¨ç¾ï¼Œè­˜åˆ¥é—œéµæ”¹å–„æ©Ÿæœƒï¼Œä¸¦æä¾›å…·é«”çš„ç¸¾æ•ˆæå‡ç­–ç•¥ï¼Œä»¥å¯¦ç¾å¯æŒçºŒçš„æ¥­å‹™å¢é•·ã€‚"
        
        return f"""
# éŠ·å”®ç¸¾æ•ˆåˆ†æèˆ‡æ”¹å–„å»ºè­°å ±å‘Š

## ä¸€ã€ä¸»æ—¨
{purpose}

## äºŒã€åˆ†æèªªæ˜
åŸºæ–¼åˆ†ææ•¸æ“šé¡¯ç¤ºï¼š
{chr(10).join(context_parts) if context_parts else '- éœ€è¦é€²ä¸€æ­¥çš„æ•¸æ“šåˆ†æä¾†æä¾›å…·é«”è¦‹è§£'}

### ç¸¾æ•ˆè¡¨ç¾è©•ä¼°
- éŠ·å”®è¶¨å‹¢åˆ†æé¡¯ç¤ºæ•´é«”è¡¨ç¾éœ€è¦é—œæ³¨
- é—œéµæŒ‡æ¨™è®ŠåŒ–åæ˜ å¸‚å ´å‹•æ…‹å’Œå…§éƒ¨ç‡Ÿé‹ç‹€æ³
- å„ç¶­åº¦è¡¨ç¾å·®ç•°åŒ–æ˜é¡¯ï¼Œéœ€è¦é‡å°æ€§æ”¹å–„

### å½±éŸ¿å› ç´ åˆ†æ
- å¸‚å ´ç«¶çˆ­ç’°å¢ƒè®ŠåŒ–
- å®¢æˆ¶éœ€æ±‚åå¥½è½‰ç§»
- å…§éƒ¨ç‡Ÿé‹æ•ˆç‡å½±éŸ¿
- ç”¢å“çµ„åˆç­–ç•¥èª¿æ•´

## ä¸‰ã€æ”¹å–„å»ºè­°

### çŸ­æœŸæ”¹å–„æªæ–½ï¼ˆ1-3å€‹æœˆï¼‰
1. **ç«‹å³è¡Œå‹•é …ç›®**
   - åŠ å¼·é«˜ç¸¾æ•ˆç”¢å“æ¨å»£
   - å„ªåŒ–éŠ·å”®æµç¨‹å’Œå®¢æˆ¶æœå‹™
   - å»ºç«‹æ¯æ—¥ç¸¾æ•ˆç›£æ§æ©Ÿåˆ¶

2. **å¿«é€Ÿæ”¹å–„æ–¹æ¡ˆ**
   - é‡å°è¡¨ç¾ä¸‹æ»‘é …ç›®åˆ¶å®šæ”¹å–„è¨ˆåŠƒ
   - åŠ å¼·éŠ·å”®åœ˜éšŠåŸ¹è¨“å’Œæ¿€å‹µ
   - æ”¹å–„å®¢æˆ¶é—œä¿‚ç®¡ç†

### ä¸­æœŸç­–ç•¥èª¿æ•´ï¼ˆ3-6å€‹æœˆï¼‰
1. **ç­–ç•¥å„ªåŒ–**
   - é‡æ–°è©•ä¼°ç”¢å“çµ„åˆç­–ç•¥
   - åˆ¶å®šå·®ç•°åŒ–å®šåƒ¹æ–¹æ¡ˆ
   - åŠ å¼·æ•¸ä½è¡ŒéŠ·å’Œç·šä¸Šæ¨å»£

2. **æµç¨‹æ”¹å–„**
   - å„ªåŒ–åº«å­˜ç®¡ç†ç³»çµ±
   - æ”¹å–„è¨‚å–®è™•ç†æµç¨‹
   - å»ºç«‹å®¢æˆ¶å¿ èª åº¦è¨ˆåŠƒ

### é•·æœŸç™¼å±•è¦åŠƒï¼ˆ6-12å€‹æœˆï¼‰
1. **æˆ°ç•¥è¦åŠƒ**
   - é–‹ç™¼æ–°ç”¢å“ç·šå’Œæœå‹™
   - æ‹“å±•æ–°å¸‚å ´å’Œå®¢æˆ¶ç¾¤
   - å»ºç«‹ç«¶çˆ­å„ªå‹¢

2. **èƒ½åŠ›å»ºè¨­**
   - æå‡åœ˜éšŠå°ˆæ¥­èƒ½åŠ›
   - å»ºç«‹æ•¸æ“šé©…å‹•æ±ºç­–æ–‡åŒ–
   - å„ªåŒ–çµ„ç¹”çµæ§‹

## å››ã€è¦åŠƒæ™‚ç¨‹

### ç¬¬ä¸€éšæ®µï¼ˆ1-2å€‹æœˆï¼‰ï¼šç«‹å³è¡Œå‹•
- **ç¬¬1é€±**ï¼šå»ºç«‹ç¸¾æ•ˆç›£æ§æ©Ÿåˆ¶
- **ç¬¬2-4é€±**ï¼šå¯¦æ–½å¿«é€Ÿæ”¹å–„æªæ–½
- **ç¬¬4-8é€±**ï¼šè©•ä¼°åˆæ­¥æˆæ•ˆä¸¦èª¿æ•´

### ç¬¬äºŒéšæ®µï¼ˆ3-4å€‹æœˆï¼‰ï¼šç­–ç•¥èª¿æ•´
- **ç¬¬3å€‹æœˆ**ï¼šå¯¦æ–½ä¸­æœŸç­–ç•¥èª¿æ•´
- **ç¬¬4å€‹æœˆ**ï¼šå»ºç«‹æ–°çš„ç‡Ÿé‹æµç¨‹
- **é‡Œç¨‹ç¢‘**ï¼šé”æˆéšæ®µæ€§ç¸¾æ•ˆç›®æ¨™

### ç¬¬ä¸‰éšæ®µï¼ˆ5-6å€‹æœˆï¼‰ï¼šé•·æœŸè¦åŠƒ
- **ç¬¬5-6å€‹æœˆ**ï¼šå¯¦æ–½é•·æœŸç™¼å±•è¦åŠƒ
- **é—œéµæŒ‡æ¨™**ï¼šéŠ·å”®å¢é•·ç‡ã€å®¢æˆ¶æ»¿æ„åº¦ã€å¸‚å ´ä»½é¡

## äº”ã€çµè«–
é€šéç³»çµ±æ€§çš„ç¸¾æ•ˆåˆ†æå’Œæ”¹å–„è¨ˆåŠƒï¼Œé æœŸåœ¨6å€‹æœˆå…§å¯¦ç¾é¡¯è‘—çš„æ¥­å‹™æ”¹å–„ã€‚é—œéµæˆåŠŸå› ç´ åŒ…æ‹¬ï¼šé ˜å°å±¤çš„æ‰¿è«¾æ”¯æŒã€åœ˜éšŠçš„ç©æ¥µåƒèˆ‡ã€ä»¥åŠæŒçºŒçš„ç›£æ§å’Œèª¿æ•´æ©Ÿåˆ¶ã€‚å»ºè­°å®šæœŸæª¢è¨é€²åº¦ï¼Œç¢ºä¿æ”¹å–„æªæ–½çš„æœ‰æ•ˆåŸ·è¡Œã€‚
"""

    def _generate_strategy_report_template(self, context_parts, chat_summary=""):
        """ç”Ÿæˆç­–ç•¥è¦åŠƒå ±å‘Šæ¨¡æ¿"""
        # æ ¹æ“šèŠå¤©å…§å®¹èª¿æ•´ä¸»æ—¨
        if chat_summary:
            purpose = f"æœ¬å ±å‘ŠåŸºæ–¼ç•¶å‰æ¥­å‹™è¡¨ç¾åˆ†æï¼Œä¸¦çµåˆç”¨æˆ¶åœ¨å°è«‡ä¸­è¡¨é”çš„å…·é«”éœ€æ±‚{chat_summary}ï¼Œæä¾›å€‹æ€§åŒ–çš„ç¶“ç‡Ÿç­–ç•¥è¦åŠƒå»ºè­°ã€‚"
        else:
            purpose = "æœ¬å ±å‘ŠåŸºæ–¼ç•¶å‰æ¥­å‹™è¡¨ç¾åˆ†æï¼Œæä¾›å…¨é¢çš„ç¶“ç‡Ÿç­–ç•¥è¦åŠƒå»ºè­°ï¼Œæ—¨åœ¨å»ºç«‹å¯æŒçºŒçš„ç«¶çˆ­å„ªå‹¢å’Œæ¥­å‹™å¢é•·æ¨¡å¼ã€‚"
        
        return f"""
# ç¶“ç‡Ÿç­–ç•¥è¦åŠƒèˆ‡å»ºè­°å ±å‘Š

## ä¸€ã€ä¸»æ—¨
{purpose}

## äºŒã€åˆ†æèªªæ˜
{chr(10).join(context_parts) if context_parts else 'åŸºæ–¼ä¸€èˆ¬ç¶“ç‡Ÿåˆ†æéœ€æ±‚'}

### ç­–ç•¥ç’°å¢ƒåˆ†æ
- å¸‚å ´ç«¶çˆ­æ…‹å‹¢è©•ä¼°
- å®¢æˆ¶éœ€æ±‚è®ŠåŒ–è¶¨å‹¢
- å…§éƒ¨è³‡æºèƒ½åŠ›åˆ†æ
- å¤–éƒ¨æ©Ÿæœƒèˆ‡å¨è„…è­˜åˆ¥

### æ ¸å¿ƒç«¶çˆ­åŠ›è©•ä¼°
- ç”¢å“æœå‹™å„ªå‹¢åˆ†æ
- ç‡Ÿé‹æ•ˆç‡è©•ä¼°
- å®¢æˆ¶é—œä¿‚ç®¡ç†èƒ½åŠ›
- å‰µæ–°ç™¼å±•æ½›åŠ›

## ä¸‰ã€æ”¹å–„å»ºè­°

### çŸ­æœŸç­–ç•¥èª¿æ•´ï¼ˆ1-3å€‹æœˆï¼‰
1. **å¸‚å ´å®šä½å„ªåŒ–**
   - é‡æ–°å®šç¾©ç›®æ¨™å®¢æˆ¶ç¾¤
   - èª¿æ•´ç”¢å“æœå‹™å®šä½
   - å„ªåŒ–åƒ¹æ ¼ç­–ç•¥

2. **ç‡Ÿé‹æ•ˆç‡æå‡**
   - æ”¹å–„æµç¨‹å’Œç³»çµ±
   - åŠ å¼·åœ˜éšŠå”ä½œ
   - å»ºç«‹ç¸¾æ•ˆç®¡ç†æ©Ÿåˆ¶

### ä¸­æœŸç­–ç•¥ç™¼å±•ï¼ˆ3-6å€‹æœˆï¼‰
1. **æ¥­å‹™æ¨¡å¼å‰µæ–°**
   - é–‹ç™¼æ–°çš„æ”¶å…¥ä¾†æº
   - å»ºç«‹åˆä½œå¤¥ä¼´é—œä¿‚
   - æ‹“å±•æœå‹™ç¯„åœ

2. **èƒ½åŠ›å»ºè¨­**
   - æå‡åœ˜éšŠå°ˆæ¥­æŠ€èƒ½
   - å»ºç«‹å­¸ç¿’å‹çµ„ç¹”
   - åŠ å¼·æŠ€è¡“å‰µæ–°èƒ½åŠ›

### é•·æœŸæˆ°ç•¥è¦åŠƒï¼ˆ6-12å€‹æœˆï¼‰
1. **å¸‚å ´æ“´å¼µ**
   - é€²å…¥æ–°å¸‚å ´é ˜åŸŸ
   - é–‹ç™¼æ–°ç”¢å“ç·š
   - å»ºç«‹å“ç‰Œå½±éŸ¿åŠ›

2. **å¯æŒçºŒç™¼å±•**
   - å»ºç«‹æ ¸å¿ƒç«¶çˆ­å„ªå‹¢
   - å¯¦ç¾è¦æ¨¡åŒ–ç™¼å±•
   - å»ºç«‹è¡Œæ¥­é ˜å°åœ°ä½

## å››ã€è¦åŠƒæ™‚ç¨‹

### ç¬¬ä¸€éšæ®µï¼ˆ1-2å€‹æœˆï¼‰ï¼šç­–ç•¥èª¿æ•´
- **ç¬¬1é€±**ï¼šç­–ç•¥ç’°å¢ƒåˆ†æ
- **ç¬¬2-4é€±**ï¼šåˆ¶å®šèª¿æ•´æ–¹æ¡ˆ
- **ç¬¬4-8é€±**ï¼šå¯¦æ–½ç­–ç•¥èª¿æ•´

### ç¬¬äºŒéšæ®µï¼ˆ3-4å€‹æœˆï¼‰ï¼šèƒ½åŠ›å»ºè¨­
- **ç¬¬3å€‹æœˆ**ï¼šå»ºç«‹æ–°çš„èƒ½åŠ›é«”ç³»
- **ç¬¬4å€‹æœˆ**ï¼šå„ªåŒ–ç‡Ÿé‹æ¨¡å¼
- **é‡Œç¨‹ç¢‘**ï¼šé”æˆç­–ç•¥èª¿æ•´ç›®æ¨™

### ç¬¬ä¸‰éšæ®µï¼ˆ5-6å€‹æœˆï¼‰ï¼šæˆ°ç•¥ç™¼å±•
- **ç¬¬5-6å€‹æœˆ**ï¼šå¯¦æ–½é•·æœŸæˆ°ç•¥
- **é—œéµæŒ‡æ¨™**ï¼šå¸‚å ´ä»½é¡ã€å®¢æˆ¶æ»¿æ„åº¦ã€ç‡Ÿæ”¶å¢é•·

## äº”ã€çµè«–
é€šéç³»çµ±æ€§çš„ç­–ç•¥è¦åŠƒå’ŒåŸ·è¡Œï¼Œé æœŸå»ºç«‹å¯æŒçºŒçš„ç«¶çˆ­å„ªå‹¢ã€‚æˆåŠŸé—œéµåœ¨æ–¼ï¼šæ¸…æ™°çš„æˆ°ç•¥æ–¹å‘ã€æœ‰æ•ˆçš„åŸ·è¡Œæ©Ÿåˆ¶ã€ä»¥åŠæŒçºŒçš„ç›£æ§å’Œèª¿æ•´ã€‚å»ºè­°å»ºç«‹å®šæœŸç­–ç•¥æª¢è¨æ©Ÿåˆ¶ï¼Œç¢ºä¿ç­–ç•¥çš„æœ‰æ•ˆæ€§å’Œé©æ‡‰æ€§ã€‚
"""

    def _generate_risk_report_template(self, context_parts, chat_summary=""):
        """ç”Ÿæˆé¢¨éšªè©•ä¼°å ±å‘Šæ¨¡æ¿"""
        # æ ¹æ“šèŠå¤©å…§å®¹èª¿æ•´ä¸»æ—¨
        if chat_summary:
            purpose = f"æœ¬å ±å‘Šæ—¨åœ¨è­˜åˆ¥ç•¶å‰æ¥­å‹™é‹ç‡Ÿä¸­çš„æ½›åœ¨é¢¨éšªï¼Œä¸¦é‡å°ç”¨æˆ¶åœ¨å°è«‡ä¸­æåˆ°çš„å…·é«”é—œæ³¨é»{chat_summary}ï¼Œæä¾›ç›¸æ‡‰çš„é¢¨éšªç®¡ç†ç­–ç•¥å’Œå»ºè­°ã€‚"
        else:
            purpose = "æœ¬å ±å‘Šæ—¨åœ¨è­˜åˆ¥ç•¶å‰æ¥­å‹™é‹ç‡Ÿä¸­çš„æ½›åœ¨é¢¨éšªï¼Œè©•ä¼°é¢¨éšªå½±éŸ¿ç¨‹åº¦ï¼Œä¸¦æä¾›ç›¸æ‡‰çš„é¢¨éšªç®¡ç†ç­–ç•¥å’Œå»ºè­°ã€‚"
        
        return f"""
# é¢¨éšªè©•ä¼°èˆ‡ç®¡ç†å»ºè­°å ±å‘Š

## ä¸€ã€ä¸»æ—¨
{purpose}

## äºŒã€åˆ†æèªªæ˜
{chr(10).join(context_parts) if context_parts else 'åŸºæ–¼ä¸€èˆ¬ç¶“ç‡Ÿåˆ†æéœ€æ±‚'}

### é¢¨éšªè­˜åˆ¥èˆ‡è©•ä¼°
- **å¸‚å ´é¢¨éšª**ï¼šç«¶çˆ­åŠ åŠ‡ã€éœ€æ±‚è®ŠåŒ–
- **ç‡Ÿé‹é¢¨éšª**ï¼šæµç¨‹æ•ˆç‡ã€äººå“¡æµå¤±
- **è²¡å‹™é¢¨éšª**ï¼šç¾é‡‘æµã€æˆæœ¬æ§åˆ¶
- **ç­–ç•¥é¢¨éšª**ï¼šæ–¹å‘åå·®ã€åŸ·è¡Œä¸åŠ›

### é¢¨éšªå½±éŸ¿åˆ†æ
- å°æ¥­å‹™é€£çºŒæ€§çš„å½±éŸ¿
- å°è²¡å‹™è¡¨ç¾çš„å½±éŸ¿
- å°å®¢æˆ¶é—œä¿‚çš„å½±éŸ¿
- å°åœ˜éšŠå£«æ°£çš„å½±éŸ¿

## ä¸‰ã€æ”¹å–„å»ºè­°

### çŸ­æœŸé¢¨éšªæ§åˆ¶ï¼ˆ1-3å€‹æœˆï¼‰
1. **ç«‹å³é¢¨éšªç·©è§£**
   - å»ºç«‹é¢¨éšªç›£æ§æ©Ÿåˆ¶
   - åˆ¶å®šæ‡‰æ€¥é æ¡ˆ
   - åŠ å¼·å…§éƒ¨æ§åˆ¶

2. **å¿«é€Ÿæ”¹å–„æªæ–½**
   - å„ªåŒ–é—œéµæµç¨‹
   - åŠ å¼·åœ˜éšŠåŸ¹è¨“
   - æ”¹å–„æºé€šæ©Ÿåˆ¶

### ä¸­æœŸé¢¨éšªç®¡ç†ï¼ˆ3-6å€‹æœˆï¼‰
1. **ç³»çµ±æ€§æ”¹å–„**
   - å»ºç«‹é¢¨éšªç®¡ç†é«”ç³»
   - å„ªåŒ–ç‡Ÿé‹æµç¨‹
   - åŠ å¼·æŠ€è¡“æ”¯æŒ

2. **èƒ½åŠ›å»ºè¨­**
   - æå‡é¢¨éšªè­˜åˆ¥èƒ½åŠ›
   - å»ºç«‹é è­¦æ©Ÿåˆ¶
   - åŠ å¼·åœ˜éšŠæ‡‰è®Šèƒ½åŠ›

### é•·æœŸé¢¨éšªé˜²ç¯„ï¼ˆ6-12å€‹æœˆï¼‰
1. **æˆ°ç•¥æ€§è¦åŠƒ**
   - å»ºç«‹é¢¨éšªæ–‡åŒ–
   - å„ªåŒ–çµ„ç¹”çµæ§‹
   - åŠ å¼·æŠ€è¡“å‰µæ–°

2. **å¯æŒçºŒç™¼å±•**
   - å»ºç«‹é¢¨éšªç®¡ç†é•·æ•ˆæ©Ÿåˆ¶
   - å¯¦ç¾é¢¨éšªèˆ‡æ”¶ç›Šå¹³è¡¡
   - å»ºç«‹è¡Œæ¥­æœ€ä½³å¯¦è¸

## å››ã€è¦åŠƒæ™‚ç¨‹

### ç¬¬ä¸€éšæ®µï¼ˆ1-2å€‹æœˆï¼‰ï¼šé¢¨éšªè­˜åˆ¥èˆ‡æ§åˆ¶
- **ç¬¬1é€±**ï¼šå…¨é¢é¢¨éšªè©•ä¼°
- **ç¬¬2-4é€±**ï¼šåˆ¶å®šæ§åˆ¶æªæ–½
- **ç¬¬4-8é€±**ï¼šå¯¦æ–½é¢¨éšªæ§åˆ¶

### ç¬¬äºŒéšæ®µï¼ˆ3-4å€‹æœˆï¼‰ï¼šé¢¨éšªç®¡ç†é«”ç³»
- **ç¬¬3å€‹æœˆ**ï¼šå»ºç«‹ç®¡ç†é«”ç³»
- **ç¬¬4å€‹æœˆ**ï¼šå„ªåŒ–æ§åˆ¶æµç¨‹
- **é‡Œç¨‹ç¢‘**ï¼šé”æˆé¢¨éšªæ§åˆ¶ç›®æ¨™

### ç¬¬ä¸‰éšæ®µï¼ˆ5-6å€‹æœˆï¼‰ï¼šé¢¨éšªé˜²ç¯„æ©Ÿåˆ¶
- **ç¬¬5-6å€‹æœˆ**ï¼šå»ºç«‹é•·æ•ˆæ©Ÿåˆ¶
- **é—œéµæŒ‡æ¨™**ï¼šé¢¨éšªäº‹ä»¶ç™¼ç”Ÿç‡ã€æå¤±æ§åˆ¶æ•ˆæœ

## äº”ã€çµè«–
é€šéç³»çµ±æ€§çš„é¢¨éšªè©•ä¼°å’Œç®¡ç†ï¼Œé æœŸå»ºç«‹ç©©å¥çš„æ¥­å‹™é‹ç‡Ÿç’°å¢ƒã€‚é—œéµæˆåŠŸå› ç´ åŒ…æ‹¬ï¼šé ˜å°å±¤çš„é‡è¦–ã€å…¨å“¡åƒèˆ‡ã€ä»¥åŠæŒçºŒçš„ç›£æ§å’Œæ”¹é€²ã€‚å»ºè­°å»ºç«‹å®šæœŸé¢¨éšªæª¢è¨æ©Ÿåˆ¶ï¼Œç¢ºä¿é¢¨éšªç®¡ç†çš„æœ‰æ•ˆæ€§å’Œé©æ‡‰æ€§ã€‚
"""

    def _generate_general_report_template(self, context_parts, chat_summary=""):
        """ç”Ÿæˆç¶œåˆåˆ†æå ±å‘Šæ¨¡æ¿"""
        # æ ¹æ“šèŠå¤©å…§å®¹èª¿æ•´ä¸»æ—¨
        if chat_summary:
            purpose = f"æœ¬å ±å‘ŠåŸºæ–¼å…¨é¢çš„ç¶“ç‡Ÿæ•¸æ“šåˆ†æï¼Œä¸¦çµåˆç”¨æˆ¶åœ¨å°è«‡ä¸­è¡¨é”çš„å…·é«”éœ€æ±‚{chat_summary}ï¼Œæä¾›å€‹æ€§åŒ–çš„æ¥­å‹™è©•ä¼°å’Œæ”¹å–„å»ºè­°ã€‚"
        else:
            purpose = "æœ¬å ±å‘ŠåŸºæ–¼å…¨é¢çš„ç¶“ç‡Ÿæ•¸æ“šåˆ†æï¼Œæä¾›ç¶œåˆæ€§çš„æ¥­å‹™è©•ä¼°å’Œæ”¹å–„å»ºè­°ï¼Œæ—¨åœ¨ä¿ƒé€²æ¥­å‹™çš„å¯æŒçºŒç™¼å±•å’Œç«¶çˆ­åŠ›æå‡ã€‚"
        
        return f"""
# ç¶œåˆç¶“ç‡Ÿåˆ†æèˆ‡å»ºè­°å ±å‘Š

## ä¸€ã€ä¸»æ—¨
{purpose}

## äºŒã€åˆ†æèªªæ˜
{chr(10).join(context_parts) if context_parts else 'åŸºæ–¼ä¸€èˆ¬ç¶“ç‡Ÿåˆ†æéœ€æ±‚'}

### æ•´é«”è¡¨ç¾è©•ä¼°
- æ¥­å‹™ç¸¾æ•ˆç¶œåˆåˆ†æ
- é—œéµæŒ‡æ¨™è¶¨å‹¢è©•ä¼°
- ç«¶çˆ­åŠ›åˆ†æ
- ç™¼å±•æ½›åŠ›è©•ä¼°

### æ ¸å¿ƒå•é¡Œè­˜åˆ¥
- ç‡Ÿé‹æ•ˆç‡å•é¡Œ
- å¸‚å ´ç«¶çˆ­æŒ‘æˆ°
- å®¢æˆ¶éœ€æ±‚è®ŠåŒ–
- å…§éƒ¨ç®¡ç†æ”¹å–„ç©ºé–“

## ä¸‰ã€æ”¹å–„å»ºè­°

### çŸ­æœŸæ”¹å–„æªæ–½ï¼ˆ1-3å€‹æœˆï¼‰
1. **ç«‹å³è¡Œå‹•é …ç›®**
   - å„ªåŒ–é—œéµæ¥­å‹™æµç¨‹
   - åŠ å¼·å®¢æˆ¶æœå‹™å“è³ª
   - æ”¹å–„å…§éƒ¨æºé€šæ©Ÿåˆ¶

2. **å¿«é€Ÿæ”¹å–„æ–¹æ¡ˆ**
   - åˆ¶å®šç¸¾æ•ˆæå‡è¨ˆåŠƒ
   - åŠ å¼·åœ˜éšŠåŸ¹è¨“
   - å»ºç«‹ç›£æ§æ©Ÿåˆ¶

### ä¸­æœŸç­–ç•¥èª¿æ•´ï¼ˆ3-6å€‹æœˆï¼‰
1. **æ¥­å‹™å„ªåŒ–**
   - é‡æ–°è©•ä¼°æ¥­å‹™æ¨¡å¼
   - å„ªåŒ–ç”¢å“æœå‹™çµ„åˆ
   - æ”¹å–„å®¢æˆ¶é«”é©—

2. **èƒ½åŠ›å»ºè¨­**
   - æå‡åœ˜éšŠå°ˆæ¥­èƒ½åŠ›
   - åŠ å¼·æŠ€è¡“å‰µæ–°
   - å»ºç«‹å­¸ç¿’å‹çµ„ç¹”

### é•·æœŸç™¼å±•è¦åŠƒï¼ˆ6-12å€‹æœˆï¼‰
1. **æˆ°ç•¥ç™¼å±•**
   - åˆ¶å®šé•·æœŸç™¼å±•æˆ°ç•¥
   - å»ºç«‹ç«¶çˆ­å„ªå‹¢
   - å¯¦ç¾å¯æŒçºŒå¢é•·

2. **çµ„ç¹”ç™¼å±•**
   - å„ªåŒ–çµ„ç¹”çµæ§‹
   - å»ºç«‹ä¼æ¥­æ–‡åŒ–
   - å¯¦ç¾è¦æ¨¡åŒ–ç™¼å±•

## å››ã€è¦åŠƒæ™‚ç¨‹

### ç¬¬ä¸€éšæ®µï¼ˆ1-2å€‹æœˆï¼‰ï¼šåŸºç¤æ”¹å–„
- **ç¬¬1é€±**ï¼šå•é¡Œè­˜åˆ¥èˆ‡åˆ†æ
- **ç¬¬2-4é€±**ï¼šåˆ¶å®šæ”¹å–„æ–¹æ¡ˆ
- **ç¬¬4-8é€±**ï¼šå¯¦æ–½æ”¹å–„æªæ–½

### ç¬¬äºŒéšæ®µï¼ˆ3-4å€‹æœˆï¼‰ï¼šç­–ç•¥èª¿æ•´
- **ç¬¬3å€‹æœˆ**ï¼šå¯¦æ–½ç­–ç•¥èª¿æ•´
- **ç¬¬4å€‹æœˆ**ï¼šå»ºç«‹æ–°çš„ç‡Ÿé‹æ¨¡å¼
- **é‡Œç¨‹ç¢‘**ï¼šé”æˆéšæ®µæ€§ç›®æ¨™

### ç¬¬ä¸‰éšæ®µï¼ˆ5-6å€‹æœˆï¼‰ï¼šé•·æœŸç™¼å±•
- **ç¬¬5-6å€‹æœˆ**ï¼šå¯¦æ–½é•·æœŸè¦åŠƒ
- **é—œéµæŒ‡æ¨™**ï¼šæ•´é«”ç¸¾æ•ˆæ”¹å–„ã€ç«¶çˆ­åŠ›æå‡

## äº”ã€çµè«–
é€šéç³»çµ±æ€§çš„åˆ†æå’Œæ”¹å–„ï¼Œé æœŸå¯¦ç¾æ¥­å‹™çš„å…¨é¢æå‡ã€‚æˆåŠŸé—œéµåœ¨æ–¼ï¼šæ˜ç¢ºçš„ç›®æ¨™å°å‘ã€æœ‰æ•ˆçš„åŸ·è¡Œæ©Ÿåˆ¶ã€ä»¥åŠæŒçºŒçš„ç›£æ§å’Œèª¿æ•´ã€‚å»ºè­°å»ºç«‹å®šæœŸæª¢è¨æ©Ÿåˆ¶ï¼Œç¢ºä¿æ”¹å–„æªæ–½çš„æœ‰æ•ˆåŸ·è¡Œå’ŒæŒçºŒæ”¹é€²ã€‚
"""

    def _generate_unified_monthly_forecast(self, periods, best_model):
        """çµ±ä¸€çš„æœˆåº¦é æ¸¬ç”Ÿæˆå‡½æ•¸ï¼Œæ·»åŠ æ³¢å‹•æ€§è®“é æ¸¬æ›´æ¥è¿‘æ­·å²æ•¸æ“š"""
        import numpy as np
        import random
        
        # ç”ŸæˆåŸºç¤æœˆåº¦é æ¸¬
        forecast = best_model.forecast(steps=periods)
        monthly_values = forecast.values if hasattr(forecast, 'values') else forecast
        
        # è¨ˆç®—æ­·å²æ•¸æ“šçš„æ³¢å‹•æ€§
        historical_data = self._get_historical_sales_data()
        if historical_data:
            # è¨ˆç®—æ­·å²æ•¸æ“šçš„æ¨™æº–å·®ä½œç‚ºæ³¢å‹•åƒè€ƒ
            historical_values = [float(row['sales']) for row in historical_data if float(row['sales']) > 0]
            if len(historical_values) > 1:
                historical_std = np.std(historical_values)
                historical_mean = np.mean(historical_values)
                
                # æ·»åŠ éš¨æ©Ÿæ³¢å‹•ï¼Œè®“é æ¸¬æ›´æ¥è¿‘æ­·å²æ•¸æ“šçš„æ³¢å‹•æ¨¡å¼
                # æ³¢å‹•å¹…åº¦ç‚ºæ­·å²æ¨™æº–å·®çš„ 10-30%
                volatility_factor = random.uniform(0.1, 0.3)
                noise_std = historical_std * volatility_factor
                
                # ç‚ºæ¯å€‹é æ¸¬å€¼æ·»åŠ éš¨æ©Ÿæ³¢å‹•
                for i in range(len(monthly_values)):
                    # ç”Ÿæˆæ­£æ…‹åˆ†ä½ˆçš„éš¨æ©Ÿæ³¢å‹•
                    noise = np.random.normal(0, noise_std)
                    monthly_values[i] += noise
                    
                    # ç¢ºä¿é æ¸¬å€¼ä¸æœƒè®Šæˆè² æ•¸
                    monthly_values[i] = max(0, monthly_values[i])
        
        return monthly_values

    def _add_volatility_to_forecast(self, forecast_values, historical_data):
        """ç‚ºé æ¸¬å€¼æ·»åŠ æ³¢å‹•æ€§ï¼Œè®“é æ¸¬æ›´æ¥è¿‘æ­·å²æ•¸æ“šçš„æ³¢å‹•æ¨¡å¼"""
        import numpy as np
        import random
        
        if not historical_data:
            return forecast_values
            
        # è¨ˆç®—æ­·å²æ•¸æ“šçš„æ³¢å‹•æ€§
        historical_values = [float(row['sales']) for row in historical_data if float(row['sales']) > 0]
        if len(historical_values) < 2:
            return forecast_values
            
        historical_std = np.std(historical_values)
        historical_mean = np.mean(historical_values)
        
        # æ·»åŠ éš¨æ©Ÿæ³¢å‹•ï¼Œè®“é æ¸¬æ›´æ¥è¿‘æ­·å²æ•¸æ“šçš„æ³¢å‹•æ¨¡å¼
        # æ³¢å‹•å¹…åº¦ç‚ºæ­·å²æ¨™æº–å·®çš„ 15-35%ï¼ˆæ¯” ARIMA ç¨é«˜ä¸€äº›ï¼‰
        volatility_factor = random.uniform(0.15, 0.35)
        noise_std = historical_std * volatility_factor
        
        # ç‚ºæ¯å€‹é æ¸¬å€¼æ·»åŠ éš¨æ©Ÿæ³¢å‹•
        for i in range(len(forecast_values)):
            # ç”Ÿæˆæ­£æ…‹åˆ†ä½ˆçš„éš¨æ©Ÿæ³¢å‹•
            noise = np.random.normal(0, noise_std)
            forecast_values[i] += noise
            
            # ç¢ºä¿é æ¸¬å€¼ä¸æœƒè®Šæˆè² æ•¸
            forecast_values[i] = max(0, forecast_values[i])
        
        return forecast_values

    def generate_unified_forecast(self, forecast_type, periods=12, dimension='all', value=None):
        """
        ä½¿ç”¨çµ±ä¸€é æ¸¬ç³»çµ±ç”Ÿæˆæ¥­ç¸¾é æ¸¬ï¼Œå¯æŒ‡å®šç¶­åº¦
        Args:
            forecast_type (str): é æ¸¬é¡å‹ ('month', 'quarter', 'year')
            periods (int): é æ¸¬æœŸæ•¸
            dimension (str): ç¶­åº¦é¡å‹ all/product/customer
            value: ç¶­åº¦å€¼
        Returns:
            dict: é æ¸¬çµæœ
        """
        try:
            # å°å…¥çµ±ä¸€é æ¸¬ç³»çµ±
            from models.unified_forecaster import UnifiedForecaster
            
            # åˆå§‹åŒ–çµ±ä¸€é æ¸¬å™¨
            unified_forecaster = UnifiedForecaster(self.data_manager)
            
            # ä½¿ç”¨çµ±ä¸€é æ¸¬ç³»çµ±é€²è¡Œé æ¸¬
            result = unified_forecaster.generate_unified_forecast(
                forecast_type=forecast_type,
                periods=periods,
                enable_ai_analysis=False  # æš«æ™‚é—œé–‰AIåˆ†æï¼Œå°ˆæ³¨æ–¼é æ¸¬
            )
            
            if not result['success']:
                return result
            
            # å¦‚æœæŒ‡å®šäº†ç¶­åº¦ï¼Œéœ€è¦é€²è¡Œé¡å¤–çš„éæ¿¾è™•ç†
            if dimension != 'all' and value:
                # é€™è£¡å¯ä»¥æ·»åŠ ç¶­åº¦éæ¿¾é‚è¼¯
                # ç›®å‰çµ±ä¸€é æ¸¬ç³»çµ±ä½¿ç”¨æ•´é«”æ•¸æ“šï¼Œç¶­åº¦éæ¿¾åŠŸèƒ½å¯ä»¥å¾ŒçºŒæ“´å±•
                print(f"âš ï¸  æ³¨æ„ï¼šç¶­åº¦éæ¿¾åŠŸèƒ½ ({dimension}={value}) å°‡åœ¨å¾ŒçºŒç‰ˆæœ¬ä¸­æ”¯æ´")
            
            return result

        except Exception as e:
            return {
                'success': False,
                'error': f'çµ±ä¸€é æ¸¬éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}'
            }

    def generate_ets_forecast(self, forecast_type, periods=12, dimension='all', value=None):
        """
        ä½¿ç”¨ ETS (Exponential Smoothing) æ¨¡å‹ç”Ÿæˆæ¥­ç¸¾é æ¸¬ï¼Œå¯æŒ‡å®šç¶­åº¦
        Args:
            forecast_type (str): é æ¸¬é¡å‹ ('month', 'quarter', 'year')
            periods (int): é æ¸¬æœŸæ•¸
            dimension (str): ç¶­åº¦é¡å‹ all/product/customer
            value: ç¶­åº¦å€¼
        Returns:
            dict: é æ¸¬çµæœ
        """
        try:
            import numpy as np
            import pandas as pd
            from statsmodels.tsa.holtwinters import ExponentialSmoothing
            from datetime import datetime, timedelta
            import warnings
            warnings.filterwarnings('ignore')

            # æ ¹æ“šç¶­åº¦éæ¿¾è³‡æ–™
            if dimension == 'product' and value:
                sql = f"""
                    SELECT t.date, SUM(sf.amount) as sales
                    FROM sales_fact sf
                    JOIN dim_time t ON sf.time_id = t.time_id
                    WHERE sf.product_id = ?
                    GROUP BY t.date
                    ORDER BY t.date
                """
                df = self.data_manager.execute_query(sql, (value,))
            elif dimension == 'customer' and value:
                sql = f"""
                    SELECT t.date, SUM(sf.amount) as sales
                    FROM sales_fact sf
                    JOIN dim_time t ON sf.time_id = t.time_id
                    WHERE sf.customer_id = ?
                    GROUP BY t.date
                    ORDER BY t.date
                """
                df = self.data_manager.execute_query(sql, (value,))
            else:
                sql = """
                    SELECT t.date, SUM(sf.amount) as sales
                    FROM sales_fact sf
                    JOIN dim_time t ON sf.time_id = t.time_id
                    GROUP BY t.date
                    ORDER BY t.date
                """
                df = self.data_manager.execute_query(sql)

            if df.empty:
                return {'success': False, 'error': 'ç„¡æ­·å²æ•¸æ“šå¯ç”¨æ–¼é æ¸¬'}

            # å–å‡º sales series
            sales_series = df.set_index('date')['sales'].astype(float)
            # è³‡æ–™æª¢æŸ¥ï¼šæœ‰ NaNã€å…¨ 0ã€æ¥µç«¯ä½å€¼
            if sales_series.isnull().any():
                return {'success': False, 'error': 'æ­·å²æ•¸æ“šåŒ…å«ç©ºå€¼ï¼Œç„¡æ³•é æ¸¬'}
            if (sales_series == 0).all():
                return {'success': False, 'error': 'æ­·å²æ•¸æ“šå…¨ç‚º 0ï¼Œç„¡æ³•é æ¸¬'}
            if sales_series.mean() < 1000:
                return {'success': False, 'error': 'æ­·å²æ•¸æ“šéä½ï¼Œç„¡æ³•é æ¸¬'}

            # æ ¹æ“šé æ¸¬é¡å‹è™•ç†æ•¸æ“š
            if forecast_type == 'month':
                # æœˆåº¦é æ¸¬ï¼šåŸºæ–¼æœˆåº¦æ•¸æ“šé€²è¡Œé æ¸¬ï¼Œè€ƒæ…®å­£ç¯€æ€§è®ŠåŒ–
                processed_data = self._process_monthly_data(df.to_dict('records'))
                period_text = 'æœˆåº¦'
                date_format = '%Y-%m'
                seasonal_periods = 12
            elif forecast_type == 'quarter':
                # å­£åº¦é æ¸¬ï¼šåŸºæ–¼æœˆåº¦é æ¸¬çµæœé€²è¡ŒåŠ ç¸½
                processed_data = self._process_monthly_data(df.to_dict('records'))
                period_text = 'å­£åº¦'
                date_format = '%Y-Q%m'
                seasonal_periods = 12
            elif forecast_type == 'year':
                # å¹´åº¦é æ¸¬ï¼šåŸºæ–¼æœˆåº¦é æ¸¬çµæœé€²è¡ŒåŠ ç¸½
                processed_data = self._process_monthly_data(df.to_dict('records'))
                period_text = 'å¹´åº¦'
                date_format = '%Y'
                seasonal_periods = 12
            else:
                return {
                    'success': False,
                    'error': 'ç„¡æ•ˆçš„é æ¸¬é¡å‹'
                }

            if len(processed_data) < 3:
                return {
                    'success': False,
                    'error': f'{period_text}æ•¸æ“šä¸è¶³ï¼Œç„¡æ³•é€²è¡Œé æ¸¬'
                }

            # å¼·åˆ¶ä½¿ç”¨åŠ æ³•è¶¨å‹¢èˆ‡å­£ç¯€æ€§
            try:
                model = ExponentialSmoothing(
                    sales_series,
                    trend='add',
                    seasonal='add' if seasonal_periods else None,
                    seasonal_periods=seasonal_periods if seasonal_periods else None
                )
                fitted_model = model.fit(optimized=True)
                aic = fitted_model.aic if hasattr(fitted_model, 'aic') else None
            except Exception as e:
                return {'success': False, 'error': f'ETSæ¨¡å‹è¨“ç·´å¤±æ•—: {str(e)}'}

            if forecast_type == 'month':
                # æœˆåº¦é æ¸¬ï¼šç›´æ¥ä½¿ç”¨æœˆåº¦é æ¸¬å€¼
                forecast = fitted_model.forecast(steps=periods)
                forecast_values = forecast.values if hasattr(forecast, 'values') else forecast
                
                # ç‚º ETS é æ¸¬æ·»åŠ æ³¢å‹•æ€§
                forecast_values = self._add_volatility_to_forecast(forecast_values, processed_data)
                
            elif forecast_type == 'quarter':
                # å­£åº¦é æ¸¬ï¼šå…ˆé æ¸¬æœˆåº¦ï¼Œç„¶å¾ŒåŠ ç¸½ç‚ºå­£åº¦
                months_to_predict = periods * 3  # æ¯å€‹å­£åº¦3å€‹æœˆ
                forecast = fitted_model.forecast(steps=months_to_predict)
                monthly_values = forecast.values if hasattr(forecast, 'values') else forecast
                
                # ç‚ºæœˆåº¦é æ¸¬æ·»åŠ æ³¢å‹•æ€§
                monthly_values = self._add_volatility_to_forecast(monthly_values, processed_data)
                
                # å°‡æœˆåº¦é æ¸¬å€¼åŠ ç¸½ç‚ºå­£åº¦é æ¸¬å€¼
                quarterly_forecast_values = []
                for i in range(0, len(monthly_values), 3):
                    quarter_sum = sum(monthly_values[i:i+3])
                    quarterly_forecast_values.append(quarter_sum)
                
                # åªå–éœ€è¦çš„å­£åº¦æ•¸
                quarterly_forecast_values = quarterly_forecast_values[:periods]
                forecast_values = quarterly_forecast_values
            elif forecast_type == 'year':
                # å¹´åº¦é æ¸¬ï¼šå…ˆé æ¸¬æœˆåº¦ï¼Œç„¶å¾ŒåŠ ç¸½ç‚ºå¹´åº¦
                months_to_predict = periods * 12  # æ¯å¹´12å€‹æœˆ
                forecast = fitted_model.forecast(steps=months_to_predict)
                monthly_values = forecast.values if hasattr(forecast, 'values') else forecast
                
                # ç‚ºæœˆåº¦é æ¸¬æ·»åŠ æ³¢å‹•æ€§
                monthly_values = self._add_volatility_to_forecast(monthly_values, processed_data)
                
                # å°‡æœˆåº¦é æ¸¬å€¼åŠ ç¸½ç‚ºå¹´åº¦é æ¸¬å€¼
                yearly_forecast_values = []
                for i in range(0, len(monthly_values), 12):
                    year_sum = sum(monthly_values[i:i+12])
                    yearly_forecast_values.append(year_sum)
                
                # åªå–éœ€è¦çš„å¹´åº¦æ•¸
                yearly_forecast_values = yearly_forecast_values[:periods]
                forecast_values = yearly_forecast_values
            
            forecast_dates = self._generate_forecast_dates(forecast_type, periods)
            forecast_data = []
            for i, (date, value) in enumerate(zip(forecast_dates, forecast_values)):
                forecast_data.append({
                    'period': date,
                    'forecast_sales': round(max(0, value), 2),
                    'period_number': i + 1
                })
            total_forecast = sum(item['forecast_sales'] for item in forecast_data)
            avg_forecast = total_forecast / len(forecast_data) if len(forecast_data) > 0 else 0
            forecast_summary = self._generate_forecast_summary(
                forecast_type, periods, total_forecast, avg_forecast, 
                processed_data, forecast_data
            )
            # é æ¸¬ç•°å¸¸æª¢æŸ¥
            historical_sales = [float(row['sales']) for row in processed_data]
            historical_avg = sum(historical_sales) / len(historical_sales) if len(historical_sales) > 0 else 0
            warning = None
            if historical_avg > 0 and avg_forecast < 0.2 * historical_avg:
                warning = f'âš ï¸ é æ¸¬å€¼é ä½æ–¼æ­·å²å¹³å‡ï¼Œè«‹æª¢æŸ¥è³‡æ–™æˆ–è€ƒæ…®å…¶ä»–æ¨¡å‹ã€‚æ­·å²å¹³å‡: {historical_avg:,.2f}ï¼Œé æ¸¬å¹³å‡: {avg_forecast:,.2f}'
            return {
                'success': True,
                'forecast_type': forecast_type,
                'period_text': period_text,
                'periods': periods,
                'forecast_data': forecast_data,
                'total_forecast': round(total_forecast, 2),
                'avg_forecast': round(avg_forecast, 2),
                'historical_data': processed_data,
                'forecast_summary': forecast_summary,
                'model_info': {
                    'method': 'ETS',
                    'trend': 'add',
                    'seasonal': 'add' if seasonal_periods else None,
                    'seasonal_periods': seasonal_periods,
                    'aic': round(aic, 2) if aic else None
                },
                'warning': warning
            }
        except Exception as e:
            return {
                'success': False,
                'error': f'ETSé æ¸¬éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}'
            }

    def _get_historical_sales_data(self):
        """ç²å–æ­·å²éŠ·å”®æ•¸æ“š"""
        try:
            # ä½¿ç”¨æ•¸æ“šç®¡ç†å™¨ç²å–éŠ·å”®æ•¸æ“š
            sql = """
            SELECT 
                t.date,
                SUM(sf.amount) as sales
            FROM sales_fact sf
            JOIN dim_time t ON sf.time_id = t.time_id
            GROUP BY t.date
            ORDER BY t.date
            """
            
            result = self.data_manager.execute_custom_sql(sql)
            if result['success']:
                return result['data']
            else:
                return None
        except Exception as e:
            print(f"ç²å–æ­·å²æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None
    
    def _process_monthly_data(self, historical_data):
        """è™•ç†æœˆåº¦æ•¸æ“š"""
        try:
            monthly_data = {}
            
            for row in historical_data:
                date_str = row['date']
                sales = float(row['sales'])
                
                # æå–å¹´æœˆ
                year_month = date_str[:7]  # YYYY-MM
                
                if year_month in monthly_data:
                    monthly_data[year_month]['sales'] += sales
                else:
                    monthly_data[year_month] = {
                        'period': year_month,
                        'sales': sales
                    }
            
            # æŒ‰æ—¥æœŸæ’åº
            sorted_data = sorted(monthly_data.values(), key=lambda x: x['period'])
            return sorted_data
            
        except Exception as e:
            print(f"è™•ç†æœˆåº¦æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []
    
    def _process_quarterly_data(self, historical_data):
        """è™•ç†å­£åº¦æ•¸æ“š"""
        try:
            quarterly_data = {}
            
            for row in historical_data:
                date_str = row['date']
                sales = float(row['sales'])
                
                # æå–å¹´æœˆ
                year = int(date_str[:4])
                month = int(date_str[5:7])
                
                # è¨ˆç®—å­£åº¦
                quarter = (month - 1) // 3 + 1
                quarter_key = f"{year}-Q{quarter}"
                
                if quarter_key in quarterly_data:
                    quarterly_data[quarter_key]['sales'] += sales
                else:
                    quarterly_data[quarter_key] = {
                        'period': quarter_key,
                        'sales': sales
                    }
            
            # æŒ‰æ—¥æœŸæ’åº
            sorted_data = sorted(quarterly_data.values(), key=lambda x: x['period'])
            return sorted_data
            
        except Exception as e:
            print(f"è™•ç†å­£åº¦æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []
    
    def _process_yearly_data(self, historical_data):
        """è™•ç†å¹´åº¦æ•¸æ“š"""
        try:
            yearly_data = {}
            
            for row in historical_data:
                date_str = row['date']
                sales = float(row['sales'])
                
                # æå–å¹´ä»½
                year = date_str[:4]
                
                if year in yearly_data:
                    yearly_data[year]['sales'] += sales
                else:
                    yearly_data[year] = {
                        'period': year,
                        'sales': sales
                    }
            
            # æŒ‰æ—¥æœŸæ’åº
            sorted_data = sorted(yearly_data.values(), key=lambda x: x['period'])
            return sorted_data
            
        except Exception as e:
            print(f"è™•ç†å¹´åº¦æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []
    
    def _generate_forecast_dates(self, forecast_type, periods):
        """ç”Ÿæˆé æ¸¬æ—¥æœŸ"""
        try:
            from datetime import datetime, timedelta
            import calendar
            
            # ä½¿ç”¨å›ºå®šæ—¥æœŸä½œç‚ºåŸºæº–ï¼Œç¢ºä¿æ™‚é–“è»¸ä¸€è‡´æ€§
            base_date = datetime(2025, 7, 10)  # èˆ‡å…¶ä»–æ¨¡çµ„ä¿æŒä¸€è‡´
            
            forecast_dates = []
            
            if forecast_type == 'month':
                # å¾2025å¹´8æœˆé–‹å§‹é æ¸¬
                start_year = 2025
                start_month = 8
                
                for i in range(periods):
                    if start_month > 12:
                        start_month = 1
                        start_year += 1
                    
                    forecast_dates.append(f"{start_year}-{start_month:02d}")
                    start_month += 1
                    
            elif forecast_type == 'quarter':
                # å¾2025å¹´Q3é–‹å§‹é æ¸¬
                start_quarter = 3
                start_year = 2025
                
                for i in range(periods):
                    if start_quarter > 4:
                        start_quarter = 1
                        start_year += 1
                    
                    forecast_dates.append(f"{start_year}-Q{start_quarter}")
                    start_quarter += 1
                    
            elif forecast_type == 'year':
                # å¾2026å¹´é–‹å§‹é æ¸¬
                start_year = 2026
                
                for i in range(periods):
                    forecast_dates.append(str(start_year + i))
            
            return forecast_dates
            
        except Exception as e:
            print(f"ç”Ÿæˆé æ¸¬æ—¥æœŸæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []
    
    def _generate_forecast_summary(self, forecast_type, periods, total_forecast, avg_forecast, 
                                  historical_data, forecast_data):
        """ç”Ÿæˆé æ¸¬æ‘˜è¦"""
        try:
            # è¨ˆç®—æ­·å²å¹³å‡
            historical_sales = [float(row['sales']) for row in historical_data]
            historical_avg = sum(historical_sales) / len(historical_sales) if len(historical_sales) > 0 else 0
            
            # è¨ˆç®—å¢é•·ç‡ï¼ˆé¿å…é™¤é›¶éŒ¯èª¤ï¼‰
            if historical_avg > 0:
                growth_rate = ((avg_forecast - historical_avg) / historical_avg * 100)
            else:
                growth_rate = 0
            
            # ç”Ÿæˆæ‘˜è¦æ–‡æœ¬
            period_text = {'month': 'æœˆ', 'quarter': 'å­£', 'year': 'å¹´'}[forecast_type]
            
            summary = f"""
## {period_text}åº¦æ¥­ç¸¾é æ¸¬åˆ†æå ±å‘Š

### é æ¸¬æ¦‚è¦½
- **é æ¸¬æœŸé–“**: æœªä¾† {periods} {period_text}
- **ç¸½é æ¸¬éŠ·å”®é¡**: {total_forecast:,.2f} å…ƒ
- **å¹³å‡{period_text}åº¦éŠ·å”®é¡**: {avg_forecast:,.2f} å…ƒ
- **æ­·å²å¹³å‡{period_text}åº¦éŠ·å”®é¡**: {historical_avg:,.2f} å…ƒ
- **é æ¸¬å¢é•·ç‡**: {growth_rate:+.2f}%

### é æ¸¬è¶¨å‹¢åˆ†æ
"""
            
            if growth_rate > 0:
                summary += f"- é æ¸¬é¡¯ç¤º{period_text}åº¦éŠ·å”®é¡å‘ˆä¸Šå‡è¶¨å‹¢\n"
                summary += f"- å¹³å‡æ¯{period_text}é è¨ˆå¢é•· {growth_rate:.2f}%\n"
            elif growth_rate < 0:
                summary += f"- é æ¸¬é¡¯ç¤º{period_text}åº¦éŠ·å”®é¡å‘ˆä¸‹é™è¶¨å‹¢\n"
                summary += f"- å¹³å‡æ¯{period_text}é è¨ˆä¸‹é™ {abs(growth_rate):.2f}%\n"
            else:
                summary += f"- é æ¸¬é¡¯ç¤º{period_text}åº¦éŠ·å”®é¡ä¿æŒç©©å®š\n"
            
            summary += f"""
### é æ¸¬è©³ç´°æ•¸æ“š
| æœŸé–“ | é æ¸¬éŠ·å”®é¡ |
|------|------------|
"""
            
            for item in forecast_data:
                summary += f"| {item['period']} | {item['forecast_sales']:,.2f} å…ƒ |\n"
            
            summary += f"""
### å»ºè­°èˆ‡æ³¨æ„äº‹é …
1. **æ•¸æ“šé©…å‹•æ±ºç­–**: åŸºæ–¼æ­·å²æ•¸æ“šçš„ ARIMA æ¨¡å‹é æ¸¬
2. **å®šæœŸæ›´æ–°**: å»ºè­°æ¯æœˆæ›´æ–°é æ¸¬æ¨¡å‹
3. **é¢¨éšªè€ƒé‡**: é æ¸¬çµæœåƒ…ä¾›åƒè€ƒï¼Œå¯¦éš›æƒ…æ³å¯èƒ½å—å¤šç¨®å› ç´ å½±éŸ¿
4. **ç­–ç•¥èª¿æ•´**: æ ¹æ“šé æ¸¬çµæœèª¿æ•´æ¥­å‹™ç­–ç•¥å’Œè³‡æºé…ç½®
"""
            
            return summary
            
        except Exception as e:
            print(f"ç”Ÿæˆé æ¸¬æ‘˜è¦æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return "é æ¸¬æ‘˜è¦ç”Ÿæˆå¤±æ•—"

    def generate_line_notification_data(self, query_type="summary", custom_query=None, time_range=None):
        """
        ç”Ÿæˆé©åˆ LINE é€šçŸ¥çš„è³‡æ–™åº«æŸ¥è©¢çµæœ
        Args:
            query_type (str): æŸ¥è©¢é¡å‹ ('summary', 'product', 'staff', 'customer', 'region', 'custom')
            custom_query (str): è‡ªå®šç¾©æŸ¥è©¢å…§å®¹
            time_range (dict): æ™‚é–“ç¯„åœ {'start': '2025-01-01', 'end': '2025-01-31'}
        Returns:
            dict: LINE é€šçŸ¥æ ¼å¼çš„æ•¸æ“š
        """
        try:
            # è¨­å®šé è¨­æ™‚é–“ç¯„åœ
            if not time_range:
                today = datetime(2025, 7, 10)
                current_start = today.replace(day=1)
                last_start = (current_start - timedelta(days=1)).replace(day=1)
                current_end = (current_start + relativedelta(months=1)) - timedelta(days=1)
                last_end = (last_start + relativedelta(months=1)) - timedelta(days=1)
                time_range = {
                    'current_start': current_start.strftime('%Y-%m-%d'),
                    'current_end': current_end.strftime('%Y-%m-%d'),
                    'last_start': last_start.strftime('%Y-%m-%d'),
                    'last_end': last_end.strftime('%Y-%m-%d')
                }

            # æ ¹æ“šæŸ¥è©¢é¡å‹ç”Ÿæˆä¸åŒçš„æ•¸æ“š
            if query_type == "summary":
                return self._generate_summary_line_data(time_range)
            elif query_type == "product":
                return self._generate_product_line_data(time_range)
            elif query_type == "staff":
                return self._generate_staff_line_data(time_range)
            elif query_type == "customer":
                return self._generate_customer_line_data(time_range)
            elif query_type == "region":
                return self._generate_region_line_data(time_range)
            elif query_type == "custom" and custom_query:
                return self._generate_custom_line_data(custom_query, time_range)
            else:
                return {
                    'success': False,
                    'error': 'ç„¡æ•ˆçš„æŸ¥è©¢é¡å‹æˆ–ç¼ºå°‘è‡ªå®šç¾©æŸ¥è©¢'
                }

        except Exception as e:
            return {
                'success': False,
                'error': f'ç”Ÿæˆ LINE é€šçŸ¥æ•¸æ“šå¤±æ•—: {str(e)}'
            }

    def _generate_summary_line_data(self, time_range):
        """ç”Ÿæˆæ‘˜è¦ LINE é€šçŸ¥æ•¸æ“š"""
        try:
            # åŸ·è¡ŒæœŸé–“æ¯”è¼ƒ
            period_comparison = self.data_manager.get_period_comparison(
                time_range['current_start'], time_range['current_end'],
                time_range['last_start'], time_range['last_end']
            )
            
            current_sales = period_comparison['current_period_sales'].iloc[0]
            last_sales = period_comparison['last_period_sales'].iloc[0]
            diff = current_sales - last_sales
            percentage_diff = (diff / last_sales * 100) if last_sales != 0 else 0
            
            # ç²å–å„ç¶­åº¦çš„ä¸»è¦è²¢ç»è€…
            dimensions = ['product', 'staff', 'customer', 'region']
            top_contributors = {}
            
            for dim in dimensions:
                try:
                    driver_analysis = self.data_manager.get_driver_analysis(
                        time_range['current_start'], time_range['current_end'],
                        time_range['last_start'], time_range['last_end'],
                        dim
                    )
                    if not driver_analysis.empty:
                        top_contributors[dim] = driver_analysis.head(3).to_dict('records')
                except:
                    continue

            # ç”Ÿæˆ LINE é€šçŸ¥æ ¼å¼
            message = f"ğŸ“Š éŠ·å”®æ¥­ç¸¾æ‘˜è¦å ±å‘Š\n"
            message += f"ğŸ“… æœŸé–“: {time_range['current_start']} ~ {time_range['current_end']}\n"
            message += f"ğŸ’° ç•¶æœŸéŠ·å”®: {current_sales:,.0f} å…ƒ\n"
            message += f"ğŸ“ˆ å‰æœŸéŠ·å”®: {last_sales:,.0f} å…ƒ\n"
            
            if diff > 0:
                message += f"âœ… æˆé•·: +{diff:,.0f} å…ƒ (+{percentage_diff:.1f}%)\n"
            else:
                message += f"âŒ ä¸‹æ»‘: {diff:,.0f} å…ƒ ({percentage_diff:.1f}%)\n"

            # æ·»åŠ ä¸»è¦è²¢ç»è€…
            if top_contributors:
                message += f"\nğŸ† ä¸»è¦è²¢ç»è€…:\n"
                for dim, contributors in top_contributors.items():
                    dim_name = {'product': 'ç”¢å“', 'staff': 'æ¥­å‹™å“¡', 'customer': 'å®¢æˆ¶', 'region': 'åœ°å€'}[dim]
                    message += f"â€¢ {dim_name}: {contributors[0]['åˆ†æç¶­åº¦']} ({contributors[0]['å·®ç•°']:,.0f}å…ƒ)\n"

            return {
                'success': True,
                'message': message,
                'data': {
                    'current_sales': current_sales,
                    'last_sales': last_sales,
                    'diff': diff,
                    'percentage_diff': percentage_diff,
                    'top_contributors': top_contributors,
                    'time_range': time_range
                }
            }

        except Exception as e:
            return {
                'success': False,
                'error': f'ç”Ÿæˆæ‘˜è¦æ•¸æ“šå¤±æ•—: {str(e)}'
            }

    def _generate_product_line_data(self, time_range):
        """ç”Ÿæˆç”¢å“ç¶­åº¦ LINE é€šçŸ¥æ•¸æ“š"""
        try:
            driver_analysis = self.data_manager.get_driver_analysis(
                time_range['current_start'], time_range['current_end'],
                time_range['last_start'], time_range['last_end'],
                'product'
            )
            
            message = f"ğŸ“¦ ç”¢å“éŠ·å”®åˆ†æ\n"
            message += f"ğŸ“… æœŸé–“: {time_range['current_start']} ~ {time_range['current_end']}\n\n"
            
            for i, row in driver_analysis.head(5).iterrows():
                diff = row['å·®ç•°']
                if diff > 0:
                    message += f"âœ… {row['åˆ†æç¶­åº¦']}: +{diff:,.0f} å…ƒ\n"
                else:
                    message += f"âŒ {row['åˆ†æç¶­åº¦']}: {diff:,.0f} å…ƒ\n"

            return {
                'success': True,
                'message': message,
                'data': driver_analysis.head(5).to_dict('records')
            }

        except Exception as e:
            return {
                'success': False,
                'error': f'ç”Ÿæˆç”¢å“æ•¸æ“šå¤±æ•—: {str(e)}'
            }

    def _generate_staff_line_data(self, time_range):
        """ç”Ÿæˆæ¥­å‹™å“¡ç¶­åº¦ LINE é€šçŸ¥æ•¸æ“š"""
        try:
            driver_analysis = self.data_manager.get_driver_analysis(
                time_range['current_start'], time_range['current_end'],
                time_range['last_start'], time_range['last_end'],
                'staff'
            )
            
            message = f"ğŸ‘¥ æ¥­å‹™å“¡æ¥­ç¸¾åˆ†æ\n"
            message += f"ğŸ“… æœŸé–“: {time_range['current_start']} ~ {time_range['current_end']}\n\n"
            
            for i, row in driver_analysis.head(5).iterrows():
                diff = row['å·®ç•°']
                if diff > 0:
                    message += f"ğŸ† {row['åˆ†æç¶­åº¦']}: +{diff:,.0f} å…ƒ\n"
                else:
                    message += f"âš ï¸ {row['åˆ†æç¶­åº¦']}: {diff:,.0f} å…ƒ\n"

            return {
                'success': True,
                'message': message,
                'data': driver_analysis.head(5).to_dict('records')
            }

        except Exception as e:
            return {
                'success': False,
                'error': f'ç”Ÿæˆæ¥­å‹™å“¡æ•¸æ“šå¤±æ•—: {str(e)}'
            }

    def _generate_customer_line_data(self, time_range):
        """ç”Ÿæˆå®¢æˆ¶ç¶­åº¦ LINE é€šçŸ¥æ•¸æ“š"""
        try:
            driver_analysis = self.data_manager.get_driver_analysis(
                time_range['current_start'], time_range['current_end'],
                time_range['last_start'], time_range['last_end'],
                'customer'
            )
            
            message = f"ğŸ‘¤ å®¢æˆ¶æ¶ˆè²»åˆ†æ\n"
            message += f"ğŸ“… æœŸé–“: {time_range['current_start']} ~ {time_range['current_end']}\n\n"
            
            for i, row in driver_analysis.head(5).iterrows():
                diff = row['å·®ç•°']
                if diff > 0:
                    message += f"ğŸ’ {row['åˆ†æç¶­åº¦']}: +{diff:,.0f} å…ƒ\n"
                else:
                    message += f"ğŸ“‰ {row['åˆ†æç¶­åº¦']}: {diff:,.0f} å…ƒ\n"

            return {
                'success': True,
                'message': message,
                'data': driver_analysis.head(5).to_dict('records')
            }

        except Exception as e:
            return {
                'success': False,
                'error': f'ç”Ÿæˆå®¢æˆ¶æ•¸æ“šå¤±æ•—: {str(e)}'
            }

    def _generate_region_line_data(self, time_range):
        """ç”Ÿæˆåœ°å€ç¶­åº¦ LINE é€šçŸ¥æ•¸æ“š"""
        try:
            driver_analysis = self.data_manager.get_driver_analysis(
                time_range['current_start'], time_range['current_end'],
                time_range['last_start'], time_range['last_end'],
                'region'
            )
            
            message = f"ğŸŒ åœ°å€éŠ·å”®åˆ†æ\n"
            message += f"ğŸ“… æœŸé–“: {time_range['current_start']} ~ {time_range['current_end']}\n\n"
            
            for i, row in driver_analysis.head(5).iterrows():
                diff = row['å·®ç•°']
                if diff > 0:
                    message += f"ğŸš€ {row['åˆ†æç¶­åº¦']}: +{diff:,.0f} å…ƒ\n"
                else:
                    message += f"ğŸ“Š {row['åˆ†æç¶­åº¦']}: {diff:,.0f} å…ƒ\n"

            return {
                'success': True,
                'message': message,
                'data': driver_analysis.head(5).to_dict('records')
            }

        except Exception as e:
            return {
                'success': False,
                'error': f'ç”Ÿæˆåœ°å€æ•¸æ“šå¤±æ•—: {str(e)}'
            }

    def _generate_custom_line_data(self, custom_query, time_range):
        """ç”Ÿæˆè‡ªå®šç¾©æŸ¥è©¢ LINE é€šçŸ¥æ•¸æ“š"""
        try:
            # å°‡è‡ªç„¶èªè¨€æŸ¥è©¢è½‰æ›ç‚º SQL
            sql_query = self.natural_language_to_sql(custom_query)
            
            # åŸ·è¡ŒæŸ¥è©¢
            result = self.data_manager.execute_custom_sql(sql_query)
            
            if not result['success']:
                return {
                    'success': False,
                    'error': f'è‡ªå®šç¾©æŸ¥è©¢åŸ·è¡Œå¤±æ•—: {result["error"]}'
                }

            # ç”Ÿæˆ LINE é€šçŸ¥æ ¼å¼
            message = f"ğŸ” è‡ªå®šç¾©æŸ¥è©¢çµæœ\n"
            message += f"ğŸ“… æœŸé–“: {time_range['current_start']} ~ {time_range['current_end']}\n"
            message += f"â“ æŸ¥è©¢: {custom_query}\n\n"
            
            if result['data']:
                # é¡¯ç¤ºå‰5ç­†çµæœ
                for i, row in enumerate(result['data'][:5], 1):
                    message += f"{i}. {str(row)}\n"
                
                if len(result['data']) > 5:
                    message += f"... é‚„æœ‰ {len(result['data']) - 5} ç­†è³‡æ–™\n"
            else:
                message += "ğŸ“­ æŸ¥ç„¡è³‡æ–™"

            return {
                'success': True,
                'message': message,
                'data': result['data'],
                'sql_query': sql_query
            }

        except Exception as e:
            return {
                'success': False,
                'error': f'ç”Ÿæˆè‡ªå®šç¾©æŸ¥è©¢æ•¸æ“šå¤±æ•—: {str(e)}'
            }

    def _analyze_specific_customer_query(self, query, customer_name):
        """åˆ†æç‰¹å®šå®¢æˆ¶æŸ¥è©¢"""
        try:
            # æª¢æŸ¥å®¢æˆ¶æ˜¯å¦å­˜åœ¨
            customer_exists = self._check_customer_exists(customer_name)
            
            if not customer_exists:
                return {
                    'success': True,
                    'message': f'å®¢æˆ¶ã€Œ{customer_name}ã€åœ¨è³‡æ–™åº«ä¸­æ²’æœ‰æ‰¾åˆ°ç›¸é—œçš„éŠ·å”®è¨˜éŒ„ã€‚',
                    'customer_name': customer_name,
                    'exists': False,
                    'data': []
                }
            
            # ç”ŸæˆSQLæŸ¥è©¢
            sql = self.natural_language_to_sql(query)
            
            # åŸ·è¡ŒæŸ¥è©¢
            result = self.data_manager.execute_query(sql)
            
            if result is None or result.empty:
                return {
                    'success': True,
                    'message': f'å®¢æˆ¶ã€Œ{customer_name}ã€åœ¨è³‡æ–™åº«ä¸­æ²’æœ‰æ‰¾åˆ°ç›¸é—œçš„éŠ·å”®è¨˜éŒ„ã€‚',
                    'customer_name': customer_name,
                    'exists': False,
                    'data': []
                }
            
            # æ ¼å¼åŒ–çµæœ
            formatted_data = []
            for _, row in result.iterrows():
                formatted_data.append({
                    'customer_name': row['customer_name'],
                    'total_sales': float(row['total_sales']),
                    'total_quantity': int(row['total_quantity'])
                })
            
            return {
                'success': True,
                'customer_name': customer_name,
                'exists': True,
                'data': formatted_data,
                'sql_query': sql,
                'message': f'æŸ¥è©¢å®¢æˆ¶ã€Œ{customer_name}ã€çš„éŠ·å”®è¨˜éŒ„æˆåŠŸã€‚'
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'æŸ¥è©¢å®¢æˆ¶ã€Œ{customer_name}ã€æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}'
            }

    def _analyze_specific_staff_query(self, query, staff_name):
        """åˆ†æç‰¹å®šæ¥­å‹™å“¡æŸ¥è©¢"""
        try:
            # ç”ŸæˆSQLæŸ¥è©¢
            sql = self.natural_language_to_sql(query)
            
            # åŸ·è¡ŒæŸ¥è©¢
            result = self.data_manager.execute_query(sql)
            
            if result is None or result.empty:
                return {
                    'success': True,
                    'message': f'æ¥­å‹™å“¡ã€Œ{staff_name}ã€åœ¨è³‡æ–™åº«ä¸­æ²’æœ‰æ‰¾åˆ°ç›¸é—œçš„éŠ·å”®è¨˜éŒ„ã€‚',
                    'staff_name': staff_name,
                    'exists': False,
                    'data': []
                }
            
            # æ ¼å¼åŒ–çµæœ
            formatted_data = []
            for _, row in result.iterrows():
                formatted_data.append({
                    'staff_name': row['staff_name'],
                    'total_sales': float(row['total_sales']),
                    'total_quantity': int(row['total_quantity'])
                })
            
            return {
                'success': True,
                'staff_name': staff_name,
                'exists': True,
                'data': formatted_data,
                'sql_query': sql,
                'message': f'æŸ¥è©¢æ¥­å‹™å“¡ã€Œ{staff_name}ã€çš„éŠ·å”®è¨˜éŒ„æˆåŠŸã€‚'
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'æŸ¥è©¢æ¥­å‹™å“¡ã€Œ{staff_name}ã€æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}'
            }

    def _analyze_specific_product_query(self, query, product_name):
        """åˆ†æç‰¹å®šç”¢å“æŸ¥è©¢"""
        try:
            # ç”ŸæˆSQLæŸ¥è©¢
            sql = self.natural_language_to_sql(query)
            
            # åŸ·è¡ŒæŸ¥è©¢
            result = self.data_manager.execute_query(sql)
            
            if result is None or result.empty:
                return {
                    'success': True,
                    'message': f'ç”¢å“ã€Œ{product_name}ã€åœ¨è³‡æ–™åº«ä¸­æ²’æœ‰æ‰¾åˆ°ç›¸é—œçš„éŠ·å”®è¨˜éŒ„ã€‚',
                    'product_name': product_name,
                    'exists': False,
                    'data': []
                }
            
            # æ ¼å¼åŒ–çµæœ
            formatted_data = []
            for _, row in result.iterrows():
                formatted_data.append({
                    'product_name': row['product_name'],
                    'total_sales': float(row['total_sales']),
                    'total_quantity': int(row['total_quantity'])
                })
            
            return {
                'success': True,
                'product_name': product_name,
                'exists': True,
                'data': formatted_data,
                'sql_query': sql,
                'message': f'æŸ¥è©¢ç”¢å“ã€Œ{product_name}ã€çš„éŠ·å”®è¨˜éŒ„æˆåŠŸã€‚'
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'æŸ¥è©¢ç”¢å“ã€Œ{product_name}ã€æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}'
            }

    def _analyze_specific_region_query(self, query, region_name):
        """åˆ†æç‰¹å®šåœ°å€æŸ¥è©¢"""
        try:
            # ç”ŸæˆSQLæŸ¥è©¢
            sql = self.natural_language_to_sql(query)
            
            # åŸ·è¡ŒæŸ¥è©¢
            result = self.data_manager.execute_query(sql)
            
            if result is None or result.empty:
                return {
                    'success': True,
                    'message': f'åœ°å€ã€Œ{region_name}ã€åœ¨è³‡æ–™åº«ä¸­æ²’æœ‰æ‰¾åˆ°ç›¸é—œçš„éŠ·å”®è¨˜éŒ„ã€‚',
                    'region_name': region_name,
                    'exists': False,
                    'data': []
                }
            
            # æ ¼å¼åŒ–çµæœ
            formatted_data = []
            for _, row in result.iterrows():
                formatted_data.append({
                    'region_name': row['region_name'],
                    'total_sales': float(row['total_sales']),
                    'total_quantity': int(row['total_quantity'])
                })
            
            return {
                'success': True,
                'region_name': region_name,
                'exists': True,
                'data': formatted_data,
                'sql_query': sql,
                'message': f'æŸ¥è©¢åœ°å€ã€Œ{region_name}ã€çš„éŠ·å”®è¨˜éŒ„æˆåŠŸã€‚'
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'æŸ¥è©¢åœ°å€ã€Œ{region_name}ã€æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}'
            }

    def _get_dimension_values(self, dimension):
        """å‹•æ…‹ç²å–æŒ‡å®šç¶­åº¦çš„æ‰€æœ‰å€¼"""
        try:
            dim_map = {
                'customer': {'table': 'dim_customer', 'name': 'customer_name'},
                'staff': {'table': 'dim_staff', 'name': 'staff_name'},
                'product': {'table': 'dim_product', 'name': 'product_name'},
                'region': {'table': 'dim_region', 'name': 'region_name'}
            }
            
            if dimension not in dim_map:
                return []
            
            d = dim_map[dimension]
            sql = f"SELECT {d['name']} FROM {d['table']}"
            result = self.data_manager.execute_query(sql)
            
            if result is not None and len(result) > 0:
                return result[d['name']].tolist()
            else:
                return []
        except Exception as e:
            print(f"ç²å–{dimension}ç¶­åº¦è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []

    def _check_customer_exists(self, customer_name):
        """æª¢æŸ¥å®¢æˆ¶æ˜¯å¦å­˜åœ¨æ–¼è³‡æ–™åº«ä¸­"""
        try:
            # åŸ·è¡ŒæŸ¥è©¢
            sql = f"""
            SELECT COUNT(*)
            FROM dim_customer
            WHERE customer_name = '{customer_name}'
            """
            result = self.data_manager.execute_query(sql)
            if result is not None and len(result) > 0:
                return result.iloc[0, 0] > 0
            else:
                return False
        except Exception as e:
            print(f"æª¢æŸ¥å®¢æˆ¶æ˜¯å¦å­˜åœ¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
    
    # ==================== å‘é‡æœå°‹è¼”åŠ©æ–¹æ³• ====================
    
    def _build_semantic_period_query(self, parsed):
        """æ§‹å»ºèªç¾©æœŸé–“æŸ¥è©¢"""
        try:
            # æ ¹æ“šæ™‚é–“ç¯„åœå’Œç¶­åº¦æ§‹å»ºèªç¾©æŸ¥è©¢
            period_text = parsed['period_text']
            dimension = parsed['dimension']
            
            # æ§‹å»ºèªç¾©æŸ¥è©¢æ–‡å­—
            semantic_query = f"åˆ†æ{period_text}æœŸé–“çš„{dimension}ç¶­åº¦è¡¨ç¾"
            
            # æ·»åŠ æ™‚é–“ç¯„åœä¿¡æ¯ï¼ˆæª¢æŸ¥éµæ˜¯å¦å­˜åœ¨ï¼‰
            try:
                current_start = parsed['current_start'].strftime('%Y-%m-%d') if 'current_start' in parsed else "æœªçŸ¥"
                current_end = parsed['current_end'].strftime('%Y-%m-%d') if 'current_end' in parsed else "æœªçŸ¥"
                last_start = parsed['last_start'].strftime('%Y-%m-%d') if 'last_start' in parsed else "æœªçŸ¥"
                last_end = parsed['last_end'].strftime('%Y-%m-%d') if 'last_end' in parsed else "æœªçŸ¥"
            except Exception as e:
                print(f"æ™‚é–“ç¯„åœè§£æéŒ¯èª¤: {e}")
                current_start = current_end = last_start = last_end = "æœªçŸ¥"
            
            semantic_query += f"ï¼Œç•¶å‰æœŸé–“ï¼š{current_start}åˆ°{current_end}ï¼Œæ¯”è¼ƒæœŸé–“ï¼š{last_start}åˆ°{last_end}"
            
            return semantic_query
            
        except Exception as e:
            # self.logger.error(f"æ§‹å»ºèªç¾©æŸ¥è©¢å¤±æ•—: {e}")
            return "æœŸé–“åˆ†ææŸ¥è©¢"
    
    def _execute_vector_period_analysis(self, semantic_query, parsed):
        """åŸ·è¡Œå‘é‡æœŸé–“åˆ†æ"""
        try:
            # ä½¿ç”¨å‘é‡æœå°‹é€²è¡Œæ™ºèƒ½åˆ†æ
            vector_results = {}
            
            # 1. ç”¢å“ç¶­åº¦å‘é‡åˆ†æ
            if parsed['dimension'] == 'product':
                # æœå°‹ç›¸ä¼¼ç”¢å“æ¨¡å¼
                product_results = self.data_manager.search_similar_products(semantic_query, limit=5)
                if product_results['success']:
                    vector_results['products'] = product_results['results']
            
            # 2. å®¢æˆ¶ç¶­åº¦å‘é‡åˆ†æ
            elif parsed['dimension'] == 'customer':
                # æœå°‹ç›¸ä¼¼å®¢æˆ¶æ¨¡å¼
                customer_results = self.data_manager.search_similar_customers(semantic_query, limit=5)
                if customer_results['success']:
                    vector_results['customers'] = customer_results['results']
            
            # 3. éŠ·å”®äº‹ä»¶å‘é‡åˆ†æ
            # ä½¿ç”¨èªç¾©æŸ¥è©¢æœå°‹ç›¸ä¼¼éŠ·å”®æ¨¡å¼
            sales_results = self.data_manager.search_similar_sales(
                quantity=100,  # é è¨­å€¼
                amount=10000,  # é è¨­å€¼
                limit=5
            )
            if sales_results['success']:
                vector_results['sales_patterns'] = sales_results['results']
            
            # 4. æ™‚é–“åºåˆ—å‘é‡åˆ†æ
            # åˆ†ææ™‚é–“æ¨¡å¼
            time_patterns = self._analyze_time_patterns_vector(parsed)
            if time_patterns:
                vector_results['time_patterns'] = time_patterns
            
            return vector_results
            
        except Exception as e:
            # self.logger.error(f"åŸ·è¡Œå‘é‡æœŸé–“åˆ†æå¤±æ•—: {e}")
            return {}
    
    def _analyze_time_patterns_vector(self, parsed):
        """ä½¿ç”¨å‘é‡åˆ†ææ™‚é–“æ¨¡å¼"""
        try:
            # æ§‹å»ºæ™‚é–“åºåˆ—æŸ¥è©¢
            time_query = f"åˆ†æ{parsed['period_text']}çš„æ™‚é–“æ¨¡å¼"
            
            # é€™è£¡å¯ä»¥æ“´å±•ç‚ºæ›´è¤‡é›œçš„æ™‚é–“åºåˆ—å‘é‡åˆ†æ
            # ä¾‹å¦‚ï¼šå­£ç¯€æ€§æ¨¡å¼ã€è¶¨å‹¢åˆ†æã€ç•°å¸¸æª¢æ¸¬ç­‰
            
            return {
                'query': time_query,
                'patterns': ['å­£ç¯€æ€§è®ŠåŒ–', 'è¶¨å‹¢å¢é•·', 'é€±æœŸæ€§æ³¢å‹•'],
                'confidence': 0.85
            }
            
        except Exception as e:
            # self.logger.error(f"å‘é‡æ™‚é–“æ¨¡å¼åˆ†æå¤±æ•—: {e}")
            return None

    def generate_voice_summary(self, summary_text, voice_type="mandarin_female"):
        """
        ç”ŸæˆèªéŸ³æ’­æ”¾å…§å®¹
        æ’­æ”¾å…§å®¹ç‚ºä¸»è¦è²¢ç»åˆ†æã€å…¶ä»–ç¶­åº¦åƒè€ƒåˆ†æ
        æ’­æ”¾èªéŸ³ç‚ºåœ‹èªæ–°èæ’­æ”¾å¥³ç”Ÿ
        """
        try:
            # æå–ä¸»è¦è²¢ç»åˆ†æ
            main_contribution = self._extract_main_contribution(summary_text)
            
            # æå–å…¶ä»–ç¶­åº¦åƒè€ƒåˆ†æ
            other_dimension = self._extract_other_dimension_reference(summary_text)
            
            # çµ„åˆèªéŸ³æ’­æ”¾å…§å®¹
            voice_content = self._combine_voice_content(main_contribution, other_dimension)
            
            # ç”ŸæˆèªéŸ³æ–‡ä»¶
            audio_file_path = self._synthesize_speech(voice_content, voice_type)
            
            return {
                'success': True,
                'voice_content': voice_content,
                'audio_file_path': audio_file_path,
                'main_contribution': main_contribution,
                'other_dimension': other_dimension
            }
            
        except Exception as e:
            # self.logger.error(f"èªéŸ³ç¸½çµç”Ÿæˆå¤±æ•—: {e}")
            return {
                'success': False,
                'error': f"èªéŸ³ç¸½çµç”Ÿæˆå¤±æ•—: {str(e)}"
            }

    def _extract_main_contribution(self, summary_text):
        """
        å¾åˆ†æç¸½çµä¸­æå–ä¸»è¦è²¢ç»åˆ†æ
        """
        try:
            # å°‹æ‰¾ä¸»è¦è²¢ç»åˆ†æéƒ¨åˆ†
            main_contribution_pattern = r'ğŸ“Š\s*<strong>ä¸»è¦è²¢ç»åˆ†æï¼š</strong>(.*?)(?=<br><br>|$)'
            match = re.search(main_contribution_pattern, summary_text, re.DOTALL)
            
            if match:
                content = match.group(1).strip()
                # ç§»é™¤HTMLæ¨™ç±¤
                content = re.sub(r'<[^>]+>', '', content)
                return content
            else:
                # å¦‚æœæ²’æœ‰æ‰¾åˆ°ä¸»è¦è²¢ç»åˆ†æï¼Œå˜—è©¦å¾å…¶ä»–éƒ¨åˆ†æå–
                if 'ä¸»è¦è²¢ç»' in summary_text:
                    # æå–åŒ…å«"ä¸»è¦è²¢ç»"çš„æ®µè½
                    lines = summary_text.split('<br>')
                    for line in lines:
                        if 'ä¸»è¦è²¢ç»' in line:
                            content = re.sub(r'<[^>]+>', '', line)
                            return content
                
                return "ä¸»è¦è²¢ç»åˆ†æï¼šéŠ·å”®è¡¨ç¾åˆ†æå®Œæˆ"
                
        except Exception as e:
            # self.logger.error(f"æå–ä¸»è¦è²¢ç»åˆ†æå¤±æ•—: {e}")
            return "ä¸»è¦è²¢ç»åˆ†æï¼šéŠ·å”®è¡¨ç¾åˆ†æå®Œæˆ"

    def _extract_other_dimension_reference(self, summary_text):
        """
        å¾åˆ†æç¸½çµä¸­æå–å…¶ä»–ç¶­åº¦åƒè€ƒåˆ†æ
        """
        try:
            # å°‹æ‰¾å…¶ä»–ç¶­åº¦åƒè€ƒåˆ†æéƒ¨åˆ†
            other_dimension_pattern = r'ğŸ”\s*<strong>å…¶ä»–ç¶­åº¦åƒè€ƒåˆ†æï¼š</strong><br>(.*?)(?=<br><br>|$)'
            match = re.search(other_dimension_pattern, summary_text, re.DOTALL)
            
            if match:
                content = match.group(1).strip()
                # ç§»é™¤HTMLæ¨™ç±¤
                content = re.sub(r'<[^>]+>', '', content)
                return content
            else:
                # å¦‚æœæ²’æœ‰æ‰¾åˆ°å…¶ä»–ç¶­åº¦åƒè€ƒåˆ†æï¼Œå˜—è©¦å¾å…¶ä»–éƒ¨åˆ†æå–
                if 'å…¶ä»–ç¶­åº¦' in summary_text:
                    # æå–åŒ…å«"å…¶ä»–ç¶­åº¦"çš„æ®µè½
                    lines = summary_text.split('<br>')
                    for line in lines:
                        if 'å…¶ä»–ç¶­åº¦' in line:
                            content = re.sub(r'<[^>]+>', '', line)
                            return content
                
                return "å…¶ä»–ç¶­åº¦åƒè€ƒåˆ†æï¼šå¤šç¶­åº¦åˆ†æå®Œæˆ"
                
        except Exception as e:
            # self.logger.error(f"æå–å…¶ä»–ç¶­åº¦åƒè€ƒåˆ†æå¤±æ•—: {e}")
            return "å…¶ä»–ç¶­åº¦åƒè€ƒåˆ†æï¼šå¤šç¶­åº¦åˆ†æå®Œæˆ"

    def _combine_voice_content(self, main_contribution, other_dimension):
        """
        çµ„åˆèªéŸ³æ’­æ”¾å…§å®¹
        """
        try:
            voice_content = f"åˆ†æç¸½çµå ±å‘Šã€‚{main_contribution}ã€‚{other_dimension}ã€‚å ±å‘Šæ’­æ”¾å®Œç•¢ã€‚"
            
            # å„ªåŒ–èªéŸ³å…§å®¹ï¼Œä½¿å…¶æ›´é©åˆèªéŸ³æ’­æ”¾
            voice_content = voice_content.replace('ã€‚', 'ï¼Œ')
            voice_content = voice_content.replace('ï¼š', 'ï¼Œ')
            voice_content = voice_content.replace('ï¼ˆ', 'ï¼Œ')
            voice_content = voice_content.replace('ï¼‰', 'ï¼Œ')
            voice_content = voice_content.replace('å…ƒ', 'å…ƒï¼Œ')
            voice_content = voice_content.replace('vs', 'å°æ¯”')
            voice_content = voice_content.replace('vs', 'å°æ¯”')
            
            # ç§»é™¤å¤šé¤˜çš„é€—è™Ÿ
            voice_content = re.sub(r'ï¼Œ+', 'ï¼Œ', voice_content)
            voice_content = voice_content.strip('ï¼Œ')
            
            return voice_content
            
        except Exception as e:
            # self.logger.error(f"çµ„åˆèªéŸ³å…§å®¹å¤±æ•—: {e}")
            return "åˆ†æç¸½çµå ±å‘Šæ’­æ”¾å®Œç•¢"

    def _synthesize_speech(self, text, voice_type="mandarin_female"):
        """
        èªéŸ³åˆæˆ
        ä½¿ç”¨ gTTS (Google Text-to-Speech) ç”Ÿæˆåœ‹èªå¥³è²èªéŸ³
        """
        try:
            # å˜—è©¦ä½¿ç”¨ gTTS
            try:
                from gtts import gTTS
                from gtts.lang import tts_langs
                
                # æª¢æŸ¥æ˜¯å¦æ”¯æ´ç¹é«”ä¸­æ–‡
                supported_langs = tts_langs()
                if 'zh-tw' in supported_langs:
                    lang = 'zh-tw'  # ç¹é«”ä¸­æ–‡
                elif 'zh' in supported_langs:
                    lang = 'zh'      # ç°¡é«”ä¸­æ–‡
                else:
                    lang = 'en'      # è‹±æ–‡ï¼ˆå‚™ç”¨ï¼‰
                
                # å‰µå»ºè‡¨æ™‚ç›®éŒ„
                temp_dir = os.path.join(tempfile.gettempdir(), 'voice_summary')
                os.makedirs(temp_dir, exist_ok=True)
                
                # ç”ŸæˆèªéŸ³æ–‡ä»¶
                tts = gTTS(text=text, lang=lang, slow=False)
                audio_file_path = os.path.join(temp_dir, f'voice_summary_{datetime.now().strftime("%Y%m%d_%H%M%S")}.mp3')
                tts.save(audio_file_path)
                
                # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦æˆåŠŸç”Ÿæˆ
                if os.path.exists(audio_file_path) and os.path.getsize(audio_file_path) > 0:
                    # self.logger.info(f"èªéŸ³æ–‡ä»¶ç”ŸæˆæˆåŠŸ: {audio_file_path}")
                    # self.logger.info(f"æ–‡ä»¶å¤§å°: {os.path.getsize(audio_file_path)} å­—ç¯€")
                    return audio_file_path
                else:
                    # self.logger.error(f"èªéŸ³æ–‡ä»¶ç”Ÿæˆå¤±æ•—æˆ–æ–‡ä»¶ç‚ºç©º: {audio_file_path}")
                    return None
                
            except ImportError:
                # å¦‚æœæ²’æœ‰å®‰è£ gTTSï¼Œä½¿ç”¨å‚™ç”¨æ–¹æ¡ˆ
                # self.logger.info("gTTS æœªå®‰è£ï¼Œä½¿ç”¨å‚™ç”¨èªéŸ³åˆæˆæ–¹æ¡ˆ")
                return self._fallback_speech_synthesis(text)
                
        except Exception as e:
            # self.logger.error(f"èªéŸ³åˆæˆå¤±æ•—: {e}")
            return None

    def _fallback_speech_synthesis(self, text):
        """
        å‚™ç”¨èªéŸ³åˆæˆæ–¹æ¡ˆ
        ä½¿ç”¨ pyttsx3 æˆ–å…¶ä»–æœ¬åœ°èªéŸ³åˆæˆå¼•æ“
        """
        try:
            # å˜—è©¦ä½¿ç”¨ pyttsx3
            try:
                import pyttsx3
                
                # åˆå§‹åŒ–èªéŸ³å¼•æ“
                engine = pyttsx3.init()
                
                # è¨­å®šèªéŸ³å±¬æ€§ï¼ˆå˜—è©¦è¨­å®šç‚ºå¥³è²ï¼‰
                voices = engine.getProperty('voices')
                for voice in voices:
                    if 'female' in voice.name.lower() or 'å¥³' in voice.name.lower():
                        engine.setProperty('voice', voice.id)
                        break
                
                # è¨­å®šèªé€Ÿå’ŒéŸ³é‡
                engine.setProperty('rate', 150)    # èªé€Ÿ
                engine.setProperty('volume', 0.9)  # éŸ³é‡
                
                # å‰µå»ºè‡¨æ™‚ç›®éŒ„
                temp_dir = os.path.join(tempfile.gettempdir(), 'voice_summary')
                os.makedirs(temp_dir, exist_ok=True)
                
                # ç”ŸæˆèªéŸ³æ–‡ä»¶
                audio_file_path = os.path.join(temp_dir, f'voice_summary_{datetime.now().strftime("%Y%m%d_%H%M%S")}.wav')
                engine.save_to_file(text, audio_file_path)
                engine.runAndWait()
                
                # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦æˆåŠŸç”Ÿæˆ
                if os.path.exists(audio_file_path) and os.path.getsize(audio_file_path) > 0:
                    # self.logger.info(f"å‚™ç”¨èªéŸ³æ–‡ä»¶ç”ŸæˆæˆåŠŸ: {audio_file_path}")
                    # self.logger.info(f"æ–‡ä»¶å¤§å°: {os.path.getsize(audio_file_path)} å­—ç¯€")
                    return audio_file_path
                else:
                    # self.logger.error(f"å‚™ç”¨èªéŸ³æ–‡ä»¶ç”Ÿæˆå¤±æ•—æˆ–æ–‡ä»¶ç‚ºç©º: {audio_file_path}")
                    return None
                
            except ImportError:
                # å¦‚æœéƒ½æ²’æœ‰å®‰è£ï¼Œè¿”å› None
                # self.logger.warning("æœªå®‰è£èªéŸ³åˆæˆå¥—ä»¶ï¼Œç„¡æ³•ç”ŸæˆèªéŸ³æ–‡ä»¶")
                return None
                
        except Exception as e:
            # self.logger.error(f"å‚™ç”¨èªéŸ³åˆæˆå¤±æ•—: {e}")
            return None

    def get_voice_summary_status(self):
        """
        ç²å–èªéŸ³ç¸½çµåŠŸèƒ½ç‹€æ…‹
        """
        try:
            # æª¢æŸ¥æ˜¯å¦æ”¯æ´èªéŸ³åˆæˆ
            gtts_available = False
            pyttsx3_available = False
            
            try:
                from gtts import gTTS
                gtts_available = True
            except ImportError:
                pass
            
            try:
                import pyttsx3
                pyttsx3_available = True
            except ImportError:
                pass
            
            return {
                'success': True,
                'voice_synthesis_available': gtts_available or pyttsx3_available,
                'gtts_available': gtts_available,
                'pyttsx3_available': pyttsx3_available,
                'supported_voice_types': ['mandarin_female', 'mandarin_male', 'english_female', 'english_male'] if (gtts_available or pyttsx3_available) else []
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f"ç²å–èªéŸ³ç¸½çµç‹€æ…‹å¤±æ•—: {str(e)}"
            }
