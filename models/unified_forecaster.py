# çµ±ä¸€é æ¸¬ç³»çµ± - çµåˆæ¥­ç¸¾é æ¸¬å’Œåˆ†æçµæœé æ¸¬çš„å„ªé»
# æ•´åˆ matplotlib ç´°è†©åœ–è¡¨ + CrewAI æ·±åº¦åˆ†æ

import numpy as np
import pandas as pd
from statsmodels.tsa.statespace.sarimax import SARIMAX
import matplotlib
matplotlib.use('Agg')  # è¨­ç½® matplotlib ä½¿ç”¨ Agg å¾Œç«¯
import matplotlib.pyplot as plt
from datetime import datetime, timedelta
import os
import warnings
from matplotlib.font_manager import FontProperties
from pandas.tseries.offsets import DateOffset
import requests
import json
from dotenv import load_dotenv
import math
# import logging  # è¨»è§£æ‰ logging æ¨¡çµ„
import hashlib
import pickle
warnings.filterwarnings('ignore')

# è¨­ç½®æ—¥èªŒè¨˜éŒ„ - è¨»è§£æ‰
# logging.basicConfig(
#     level=logging.INFO,
#     format='%(asctime)s - %(levelname)s - %(message)s',
#     handlers=[
#         logging.FileHandler('unified_forecaster.log'),
#         logging.StreamHandler()
#     ]
# )

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()
API_KEY = os.getenv("GOOGLE_API_KEY")

# è¨­å®šä¸­æ–‡å­—å‹
font_paths = [
    '/System/Library/Fonts/PingFang.ttc',
    '/System/Library/Fonts/STHeiti Light.ttc',
    '/System/Library/Fonts/Hiragino Sans GB.ttc',
    '/System/Library/Fonts/Arial Unicode MS.ttf',
    '/System/Library/Fonts/Helvetica.ttc'
]

chinese_font = None
try:
    for font_path in font_paths:
        if os.path.exists(font_path):
            chinese_font = FontProperties(fname=font_path)
            # logging.info(f"æˆåŠŸè¼‰å…¥å­—å‹: {font_path}")  # è¨»è§£æ‰ logging
            break
    
    if chinese_font is None:
        import matplotlib.font_manager as fm
        chinese_fonts = [f.name for f in fm.fontManager.ttflist if 'chinese' in f.name.lower() or 'cjk' in f.name.lower()]
        if chinese_fonts:
            chinese_font = FontProperties(family=chinese_fonts[0])
            # logging.info(f"ä½¿ç”¨å…§å»ºä¸­æ–‡å­—å‹: {chinese_fonts[0]}")  # è¨»è§£æ‰ logging
        else:
            chinese_font = FontProperties()
            # logging.info("ä½¿ç”¨é è¨­å­—å‹")  # è¨»è§£æ‰ logging
except Exception as e:
    # logging.error(f"å­—å‹è¨­å®šéŒ¯èª¤: {e}")  # è¨»è§£æ‰ logging
    chinese_font = FontProperties()

def safe_float(value):
    """å®‰å…¨è½‰æ›ç‚ºæµ®é»æ•¸ï¼Œè™•ç†NaNå’Œç„¡æ•ˆå€¼"""
    try:
        if pd.isna(value) or value is None:
            return 0.0
        float_val = float(value)
        if math.isnan(float_val) or math.isinf(float_val):
            return 0.0
        return float_val
    except (ValueError, TypeError):
        return 0.0

class UnifiedForecaster:
    """
    çµ±ä¸€é æ¸¬å™¨é¡ - çµåˆæ¥­ç¸¾é æ¸¬å’Œåˆ†æçµæœé æ¸¬çš„å„ªé»
    ç¢ºä¿æ•¸æ“šä¸€è‡´æ€§å’Œå®Œæ•´çš„AIåˆ†æåŠŸèƒ½
    """
    
    def __init__(self, db_manager):
        self.db_manager = db_manager
        self.default_periods = 12
        self.default_seasonal_periods = 12
        self.api_key = API_KEY
        
        # å¿«å–æ©Ÿåˆ¶
        self.cache_dir = 'cache'
        if not os.path.exists(self.cache_dir):
            os.makedirs(self.cache_dir)
        
        # çµ±ä¸€çš„é æ¸¬æ¨¡å‹åƒæ•¸ï¼Œç¢ºä¿ä¸€è‡´æ€§
        # åŸºæ–¼æ­·å²æ•¸æ“šåˆ†æå„ªåŒ–çš„åƒæ•¸ï¼Œèƒ½æ›´å¥½åœ°æ•æ‰å­£ç¯€æ€§æ¨¡å¼
        self.model_params = {
            'order': (1, 1, 2),  # å¢åŠ MAé …è¤‡é›œåº¦ï¼Œæ›´å¥½åœ°æ•æ‰çŸ­æœŸæ³¢å‹•
            'seasonal_order': (1, 1, 1, 12),  # ä¿æŒå­£ç¯€æ€§å»ºæ¨¡
            'enforce_stationarity': False,
            'enforce_invertibility': False
        }
        
        # logging.info("çµ±ä¸€é æ¸¬å™¨åˆå§‹åŒ–å®Œæˆ")  # è¨»è§£æ‰ logging
        
    def _get_cache_key(self, forecast_type, periods, enable_ai_analysis):
        """ç”Ÿæˆå¿«å–éµå€¼"""
        cache_data = {
            'forecast_type': forecast_type,
            'periods': periods,
            'enable_ai_analysis': enable_ai_analysis,
            'timestamp': datetime.now().strftime('%Y%m%d')  # æ¯å¤©æ›´æ–°å¿«å–
        }
        cache_str = json.dumps(cache_data, sort_keys=True)
        return hashlib.md5(cache_str.encode()).hexdigest()
    
    def _load_from_cache(self, cache_key):
        """å¾å¿«å–è¼‰å…¥çµæœ"""
        cache_file = os.path.join(self.cache_dir, f"{cache_key}.pkl")
        if os.path.exists(cache_file):
            try:
                with open(cache_file, 'rb') as f:
                    cached_result = pickle.load(f)
                # logging.info(f"å¾å¿«å–è¼‰å…¥çµæœ: {cache_key}")  # è¨»è§£æ‰ logging
                return cached_result
            except Exception as e:
                # logging.warning(f"å¿«å–è¼‰å…¥å¤±æ•—: {e}")  # è¨»è§£æ‰ logging
                pass # è¨»è§£æ‰ logging
        return None
    
    def _save_to_cache(self, cache_key, result):
        """å„²å­˜çµæœåˆ°å¿«å–"""
        cache_file = os.path.join(self.cache_dir, f"{cache_key}.pkl")
        try:
            with open(cache_file, 'wb') as f:
                pickle.dump(result, f)
            # logging.info(f"çµæœå·²å„²å­˜åˆ°å¿«å–: {cache_key}")  # è¨»è§£æ‰ logging
        except Exception as e:
            # logging.warning(f"å¿«å–å„²å­˜å¤±æ•—: {e}")  # è¨»è§£æ‰ logging
            pass # è¨»è§£æ‰ logging
    
    def generate_unified_forecast(self, forecast_type='month', periods=12, enable_ai_analysis=True):
        """
        ç”Ÿæˆçµ±ä¸€é æ¸¬çµæœ
        Args:
            forecast_type: é æ¸¬é¡å‹ ('month', 'quarter', 'year')
            periods: é æ¸¬æœŸæ•¸
            enable_ai_analysis: æ˜¯å¦å•Ÿç”¨ AI åˆ†æ
        Returns:
            dict: åŒ…å«é æ¸¬çµæœã€åœ–è¡¨å’Œ AI åˆ†æçš„å®Œæ•´å­—å…¸
        """
        try:
            # æª¢æŸ¥å¿«å–
            cache_key = self._get_cache_key(forecast_type, periods, enable_ai_analysis)
            cached_result = self._load_from_cache(cache_key)
            if cached_result:
                return cached_result
            
            # logging.info("ğŸš€ é–‹å§‹çµ±ä¸€é æ¸¬æµç¨‹...")  # è¨»è§£æ‰ logging
            
            # 1. åŸ·è¡ŒåŸºç¤é æ¸¬
            # logging.info("ğŸ“Š åŸ·è¡ŒåŸºç¤é æ¸¬...")  # è¨»è§£æ‰ logging
            forecast_result = self._execute_basic_forecast(forecast_type, periods)
            
            if not forecast_result['success']:
                return forecast_result
            
            # 2. ç”Ÿæˆç´°è†©åœ–è¡¨
            # logging.info("ğŸ“ˆ ç”Ÿæˆç´°è†©åœ–è¡¨...")  # è¨»è§£æ‰ logging
            chart_result = self._generate_detailed_chart(forecast_result)
            forecast_result.update(chart_result)
            
            # 3. åŸ·è¡Œ AI åˆ†æï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
            if enable_ai_analysis and self.api_key:
                # logging.info("ğŸ¤– åŸ·è¡Œ AI åˆ†æ...")  # è¨»è§£æ‰ logging
                ai_analysis = self._generate_comprehensive_ai_analysis(forecast_result)
                forecast_result['ai_analysis'] = ai_analysis
            else:
                forecast_result['ai_analysis'] = {
                    'success': False,
                    'message': 'AI åˆ†ææœªå•Ÿç”¨æˆ– API Key æœªè¨­å®š'
                }
            
            # å„²å­˜åˆ°å¿«å–
            self._save_to_cache(cache_key, forecast_result)
            
            # logging.info("âœ… çµ±ä¸€é æ¸¬å®Œæˆ")  # è¨»è§£æ‰ logging
            return forecast_result
            
        except Exception as e:
            # logging.error(f"âŒ çµ±ä¸€é æ¸¬å¤±æ•—: {str(e)}")  # è¨»è§£æ‰ logging
            return {
                'success': False,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def _execute_basic_forecast(self, forecast_type, periods):
        """åŸ·è¡ŒåŸºç¤é æ¸¬ï¼Œä½¿ç”¨çµ±ä¸€çš„æ¨¡å‹åƒæ•¸ç¢ºä¿ä¸€è‡´æ€§"""
        try:
            # å¾è³‡æ–™åº«ç²å–æ­·å²æ•¸æ“š
            historical_data, date_labels = self._get_historical_data()
            
            # è³‡æ–™é è™•ç†
            historical_data = pd.Series(historical_data)
            historical_data = historical_data.astype(float)
            historical_data_for_plot = historical_data.values
            
            # è‡ªå‹•é¸æ“‡æœ€ä½³åƒæ•¸ï¼ˆå¦‚æœæ•¸æ“šé‡è¶³å¤ ï¼‰
            if len(historical_data) >= 24:  # è‡³å°‘éœ€è¦24å€‹æ•¸æ“šé»
                selected_params = self._auto_select_best_parameters(historical_data)
            else:
                selected_params = self.model_params
                # logging.warning("ğŸ“Š æ•¸æ“šé‡ä¸è¶³ï¼Œä½¿ç”¨é è¨­åƒæ•¸")  # è¨»è§£æ‰ logging
            
            # ä½¿ç”¨é¸å®šçš„SARIMAXæ¨¡å‹åƒæ•¸é€²è¡Œé æ¸¬
            model = SARIMAX(historical_data,
                          order=selected_params['order'],
                          seasonal_order=selected_params['seasonal_order'],
                          enforce_stationarity=selected_params['enforce_stationarity'],
                          enforce_invertibility=selected_params['enforce_invertibility'])
            
            results = model.fit(disp=False)
            
            # æ ¹æ“šé æ¸¬é¡å‹èª¿æ•´é æ¸¬æœŸæ•¸
            if forecast_type == 'quarter':
                months_to_forecast = periods * 3
            elif forecast_type == 'year':
                months_to_forecast = periods * 12
            else:
                months_to_forecast = periods
                
            # ç”Ÿæˆé æ¸¬
            forecast = results.forecast(steps=months_to_forecast)
            
            # å¾ç³»çµ±ç•¶å‰æ—¥æœŸçš„ä¸‹å€‹æœˆé–‹å§‹é æ¸¬
            current_date = datetime.now()
            start_date = current_date.replace(day=1)
            if current_date.month == 12:
                start_date = start_date.replace(year=current_date.year + 1, month=1)
            else:
                start_date = start_date.replace(month=current_date.month + 1)
            
            # ç”Ÿæˆé æ¸¬æœŸé–“çš„æ—¥æœŸæ¨™ç±¤
            forecast_dates = []
            for i in range(months_to_forecast):
                next_date = start_date + pd.DateOffset(months=i)
                forecast_dates.append(f"{next_date.year}/{next_date.month:02d}")
            
            # è½‰æ›é æ¸¬çµæœ
            forecast_data = self._process_forecast_results(forecast, forecast_type, periods, forecast_dates)
            
            # è¨ˆç®—ç¸½é æ¸¬éŠ·å”®é¡å’Œå¹³å‡é æ¸¬éŠ·å”®é¡
            total_forecast = sum(item['forecast_sales'] for item in forecast_data)
            avg_forecast = total_forecast / len(forecast_data) if len(forecast_data) > 0 else 0
            
            # è¨ˆç®—é æ¸¬æ™‚é–“ç¯„åœ
            forecast_range = f"{forecast_dates[0]} - {forecast_dates[-1]}"
            
            # ç”Ÿæˆ period_text ä»¥ä¿æŒèˆ‡åŸå§‹ç³»çµ±çš„å…¼å®¹æ€§
            period_text_map = {
                'month': 'æœˆ',
                'quarter': 'å­£', 
                'year': 'å¹´'
            }
            period_text = period_text_map.get(forecast_type, 'æœˆ')
            
            # æº–å‚™æ­·å²çµ±è¨ˆæ•¸æ“š
            historical_stats = {
                'data_points': len(historical_data_for_plot),
                'total_sales': safe_float(sum(historical_data_for_plot)),
                'avg_monthly_sales': safe_float(np.mean(historical_data_for_plot)),
                'sales_std': safe_float(np.std(historical_data_for_plot))
            }
            
            # ç”Ÿæˆ forecast_summary ä»¥ä¿æŒèˆ‡å‰ç«¯ä»£ç¢¼çš„å…¼å®¹æ€§
            forecast_summary = self._generate_forecast_summary(
                forecast_type, periods, total_forecast, avg_forecast, 
                forecast_data, historical_stats
            )
            
            # å®‰å…¨è™•ç†æ¨¡å‹æ‘˜è¦çµ±è¨ˆ
            model_summary = {
                'aic': safe_float(results.aic),
                'bic': safe_float(results.bic),
                'hqic': safe_float(results.hqic)
            }
            
            return {
                'success': True,
                'forecast_data': forecast_data,
                'historical_data': {
                    'data': [safe_float(x) for x in historical_data_for_plot.tolist()],
                    'dates': date_labels,
                    'stats': historical_stats
                },
                'total_forecast': safe_float(total_forecast),
                'avg_forecast': safe_float(avg_forecast),
                'forecast_range': forecast_range,
                'periods': periods,
                'forecast_type': forecast_type,
                'period_text': period_text,  # æ·»åŠ  period_text å­—æ®µ
                'forecast_summary': forecast_summary,  # æ·»åŠ  forecast_summary å­—æ®µ
                'model_info': {
                    'training_period': {
                        'start': date_labels[0] if date_labels else '',
                        'end': date_labels[-1] if date_labels else ''
                    },
                    'model_type': 'SARIMAX',
                    'parameters': selected_params,  # ä½¿ç”¨å¯¦éš›é¸æ“‡çš„åƒæ•¸
                    'model_summary': model_summary,
                    'parameter_selection': 'auto' if len(historical_data) >= 24 else 'default'
                },
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            # logging.error(f"åŸºç¤é æ¸¬å¤±æ•—: {str(e)}")  # è¨»è§£æ‰ logging
            return {
                'success': False,
                'error': f"åŸºç¤é æ¸¬å¤±æ•—: {str(e)}",
                'timestamp': datetime.now().isoformat()
            }
    
    def _auto_select_best_parameters(self, historical_data):
        """
        è‡ªå‹•é¸æ“‡æœ€ä½³çš„SARIMAXåƒæ•¸
        åŸºæ–¼AICå’ŒBICè©•åˆ†é¸æ“‡æœ€ä½³æ¨¡å‹
        """
        try:
            best_aic = float('inf')
            best_params = None
            
            # åƒæ•¸ç¯„åœï¼ˆåŸºæ–¼æ•¸æ“šç‰¹æ€§å„ªåŒ–ï¼‰
            p_values = [0, 1, 2]
            d_values = [1]  # é€šå¸¸1æ¬¡å·®åˆ†å³å¯
            q_values = [0, 1, 2]
            P_values = [0, 1]
            D_values = [1]  # å­£ç¯€æ€§å·®åˆ†
            Q_values = [0, 1]
            
            # logging.info("ğŸ” æ­£åœ¨é€²è¡Œè‡ªå‹•åƒæ•¸é¸æ“‡...")  # è¨»è§£æ‰ logging
            
            for p in p_values:
                for d in d_values:
                    for q in q_values:
                        for P in P_values:
                            for D in D_values:
                                for Q in Q_values:
                                    try:
                                        model = SARIMAX(historical_data,
                                                      order=(p, d, q),
                                                      seasonal_order=(P, D, Q, 12),
                                                      enforce_stationarity=False,
                                                      enforce_invertibility=False)
                                        
                                        results = model.fit(disp=False)
                                        
                                        # è¨ˆç®—ç¶œåˆè©•åˆ†ï¼ˆAIC + BICçš„åŠ æ¬Šå¹³å‡ï¼‰
                                        score = (results.aic + results.bic) / 2
                                        
                                        if score < best_aic:
                                            best_aic = score
                                            best_params = {
                                                'order': (p, d, q),
                                                'seasonal_order': (P, D, Q, 12),
                                                'enforce_stationarity': False,
                                                'enforce_invertibility': False
                                            }
                                            
                                    except Exception as e:
                                        # å¿½ç•¥ç„¡æ³•æ”¶æ–‚çš„æ¨¡å‹
                                        # logging.warning(f"å˜—è©¦åƒæ•¸ (p={p}, d={d}, q={q}, P={P}, D={D}, Q={Q}) å¤±æ•—: {e}")  # è¨»è§£æ‰ logging
                                        continue
            
            if best_params:
                # logging.info(f"âœ… æœ€ä½³åƒæ•¸: SARIMA{best_params['order']}{best_params['seasonal_order']}")  # è¨»è§£æ‰ logging
                # logging.info(f"ğŸ“Š æœ€ä½³è©•åˆ†: {best_aic:.2f}")  # è¨»è§£æ‰ logging
                return best_params
            else:
                # logging.warning("âš ï¸ ç„¡æ³•æ‰¾åˆ°åˆé©çš„åƒæ•¸ï¼Œä½¿ç”¨é è¨­åƒæ•¸")  # è¨»è§£æ‰ logging
                return self.model_params
                
        except Exception as e:
            # logging.error(f"è‡ªå‹•åƒæ•¸é¸æ“‡å¤±æ•—: {e}")  # è¨»è§£æ‰ logging
            return self.model_params
    
    def _generate_detailed_chart(self, forecast_result):
        """ç”Ÿæˆç´°è†©çš„é æ¸¬åœ–è¡¨ï¼Œç¢ºä¿èˆ‡æ•¸æ“šä¸€è‡´"""
        try:
            if not os.path.exists('static'):
                os.makedirs('static')
            
            # ç²å–æ•¸æ“š
            historical_data = np.array(forecast_result['historical_data']['data'])
            forecast_data = [item['forecast_sales'] for item in forecast_result['forecast_data']]
            date_labels = forecast_result['historical_data']['dates']
            forecast_dates = [item['period'] for item in forecast_result['forecast_data']]
            forecast_type = forecast_result['forecast_type']
            
            # å‰µå»ºåœ–è¡¨
            fig, ax = plt.subplots(figsize=(14, 8))
            
            # è¨­å®šæ¨£å¼
            plt.rcParams['axes.unicode_minus'] = False
            plt.style.use('classic')
            plt.rcParams.update({
                'figure.facecolor': 'white',
                'axes.facecolor': 'white',
                'grid.color': '#E0E0E0',
                'grid.linestyle': '--',
                'grid.alpha': 0.7
            })
            
            # ç¹ªè£½æ­·å²æ•¸æ“š
            if len(historical_data) > 0:
                ax.plot(range(len(historical_data)), 
                       historical_data, 
                       label='æ­·å²æ•¸æ“š', 
                       color='#4682B4',
                       linewidth=3,
                       marker='o',
                       markersize=6,
                       markerfacecolor='white',
                       markeredgewidth=2)
            
            # ç¹ªè£½é æ¸¬æ•¸æ“š
            if len(historical_data) > 0:
                # å¾æ­·å²æ•¸æ“šçš„æœ«å°¾é–‹å§‹ç¹ªè£½é æ¸¬æ•¸æ“š
                ax.plot(range(len(historical_data), len(historical_data) + len(forecast_data)),
                       forecast_data,
                       label='é æ¸¬æ•¸æ“š',
                       color='#2E8B57',  # æ”¹ç‚ºç¶ è‰²
                       linestyle='--',
                       linewidth=3,
                       marker='s',
                       markersize=6,
                       markerfacecolor='white',
                       markeredgewidth=2)
            else:
                ax.plot(range(len(forecast_data)),
                       forecast_data,
                       label='é æ¸¬æ•¸æ“š',
                       color='#2E8B57',  # æ”¹ç‚ºç¶ è‰²
                       linestyle='--',
                       linewidth=3,
                       marker='s',
                       markersize=6,
                       markerfacecolor='white',
                       markeredgewidth=2)
            
            # è¨­å®šyè»¸ç¯„åœ - å›ºå®šå¾0é–‹å§‹ï¼Œæœ€é«˜å€¼600è¬
            all_values = np.concatenate([historical_data, forecast_data]) if len(historical_data) > 0 else forecast_data
            min_val = 0  # xè»¸å¾0é–‹å§‹
            max_val = 6_000_000  # æœ€é«˜å€¼è¨­å®šç‚º600è¬
            
            # è¨­å®šå›ºå®šçš„yè»¸ç¯„åœ
            ax.set_ylim(min_val, max_val)
            
            # è¨­å®šxè»¸æ¨™ç±¤ - èª¿æ•´é–“è·è®“æ³¢å‹•çœ‹èµ·ä¾†è¼ƒå°
            all_dates = date_labels + forecast_dates
            total_points = len(all_dates)
            
            # æ ¹æ“šæ•¸æ“šé»æ•¸èª¿æ•´é–“è· - åŠ å¤§é–“éš”
            if total_points <= 24:
                step = max(1, total_points // 6)  # æ›´å°‘çš„æ¨™ç±¤
            elif total_points <= 48:
                step = max(1, total_points // 8)  # æ¸›å°‘æ¨™ç±¤æ•¸é‡
            else:
                step = max(1, total_points // 12)  # è¼ƒå¤šæ•¸æ“šæ™‚é€²ä¸€æ­¥æ¸›å°‘æ¨™ç±¤
                
            x_ticks = list(range(0, total_points, step))
            if total_points - 1 not in x_ticks:
                x_ticks.append(total_points - 1)
                
            ax.set_xticks(x_ticks)
            ax.set_xticklabels([all_dates[i] for i in x_ticks], rotation=45, ha='right')
            
            # è¨­å®šæ¨™é¡Œå’Œæ¨™ç±¤
            try:
                plt.rcParams['font.sans-serif'] = ['PingFang HK', 'STHeiti', 'Arial Unicode MS', 'SimHei', 'DejaVu Sans']
                ax.set_title(f'çµ±ä¸€é æ¸¬ç³»çµ± - éŠ·å”®é æ¸¬è¶¨å‹¢åœ– ({forecast_type.capitalize()})', 
                            fontproperties=chinese_font, fontsize=16, pad=20)
                ax.set_xlabel('æ™‚é–“', fontproperties=chinese_font, fontsize=14)
                ax.set_ylabel('éŠ·å”®é‡‘é¡ (NT$)', fontproperties=chinese_font, fontsize=14)
                legend = ax.legend(prop=chinese_font, loc='upper left', fontsize=12)
                
                for label in ax.get_xticklabels():
                    label.set_fontproperties(chinese_font)
                    
            except Exception as e:
                # logging.error(f"å­—å‹è¨­å®šå¤±æ•—ï¼Œä½¿ç”¨é è¨­å­—å‹: {e}")  # è¨»è§£æ‰ logging
                ax.set_title(f'Unified Forecast System - Sales Forecast ({forecast_type.capitalize()})', fontsize=16, pad=20)
                ax.set_xlabel('Time', fontsize=14)
                ax.set_ylabel('Sales Amount (NT$)', fontsize=14)
                legend = ax.legend(loc='upper left', fontsize=12)
            
            # æ·»åŠ ç¶²æ ¼ - å„ªåŒ–è¦–è¦ºæ•ˆæœ
            ax.grid(True, linestyle='--', alpha=0.5, color='#E8E8E8')
            
            # æ·»åŠ èƒŒæ™¯è‰²ä»¥æ¸›å°‘è¦–è¦ºæ³¢å‹•
            ax.set_facecolor('#FAFAFA')
            
            # è¨­å®šyè»¸åˆ»åº¦ - å¾0åˆ°600è¬ï¼Œæ¯100è¬ä¸€å€‹åˆ»åº¦
            y_ticks = np.arange(0, max_val + 1, 1_000_000)
            ax.set_yticks(y_ticks)
            
            # æ ¼å¼åŒ–yè»¸
            def format_amount(x, p):
                if x >= 1_000_000:
                    return f'{int(x/10000):,}è¬'
                elif x >= 10000:
                    return f'{int(x/10000)}è¬'
                else:
                    return f'{int(x):,}'
            
            ax.yaxis.set_major_formatter(plt.FuncFormatter(format_amount))
            
            # è¨­å®šyè»¸é–“éš” - å›ºå®šç‚º100è¬
            interval = 1_000_000
            ax.yaxis.set_major_locator(plt.MultipleLocator(interval))
            
            # èª¿æ•´ä½ˆå±€
            plt.tight_layout()
            
            # å„²å­˜åœ–è¡¨
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            plot_path = f'static/unified_forecast_{timestamp}.png'
            plt.savefig(plot_path, bbox_inches='tight', dpi=300)
            plt.close()
            
            return {
                'chart_path': plot_path,
                'chart_filename': os.path.basename(plot_path)
            }
            
        except Exception as e:
            # logging.error(f"ç”Ÿæˆåœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")  # è¨»è§£æ‰ logging
            return {
                'chart_path': None,
                'chart_filename': None,
                'chart_error': str(e)
            }
    
    def _generate_comprehensive_ai_analysis(self, forecast_result):
        """ç”Ÿæˆå…¨é¢çš„ AI åˆ†æï¼ŒåŒ…å«è©³ç´°çš„é æ¸¬è§£é‡‹"""
        try:
            if not self.api_key:
                return {
                    'success': False,
                    'error': 'API Key æœªè¨­å®š'
                }
            
            # æº–å‚™åˆ†ææ•¸æ“š
            forecast_data = forecast_result['forecast_data']
            total_forecast = forecast_result['total_forecast']
            avg_forecast = forecast_result['avg_forecast']
            historical_stats = forecast_result['historical_data']['stats']
            
            # åˆ†æè¶¨å‹¢
            sales_values = [item['forecast_sales'] for item in forecast_data]
            first_quarter_avg = sum(sales_values[:3]) / 3 if len(sales_values) >= 3 else avg_forecast
            last_quarter_avg = sum(sales_values[-3:]) / 3 if len(sales_values) >= 3 else avg_forecast
            trend_direction = "ä¸Šå‡" if last_quarter_avg > first_quarter_avg else "ä¸‹é™"
            
            # è¨ˆç®—è®Šç•°ä¿‚æ•¸
            cv = np.std(sales_values) / np.mean(sales_values) if np.mean(sales_values) > 0 else 0
            
            # ç”Ÿæˆè©³ç´°åˆ†ææç¤º
            analysis_prompt = f"""
            ä½œç‚ºè³‡æ·±ç¶“ç‡Ÿåˆ†æå°ˆå®¶ï¼Œè«‹å°ä»¥ä¸‹çµ±ä¸€é æ¸¬ç³»çµ±çš„éŠ·å”®é æ¸¬çµæœé€²è¡Œæ·±å…¥åˆ†æï¼š

            ã€é æ¸¬æ•¸æ“šæ‘˜è¦ã€‘
            - ç¸½é æ¸¬éŠ·å”®é¡ï¼š{total_forecast:,.0f} å…ƒ
            - å¹³å‡æœˆéŠ·å”®é¡ï¼š{avg_forecast:,.0f} å…ƒ
            - é æ¸¬æœŸæ•¸ï¼š{len(forecast_data)} å€‹æœˆ
            - æ•´é«”è¶¨å‹¢ï¼š{trend_direction}
            - è®Šç•°ä¿‚æ•¸ï¼š{cv:.2f}ï¼ˆè¡¡é‡é æ¸¬ç©©å®šæ€§ï¼‰

            ã€æ­·å²æ•¸æ“šçµ±è¨ˆã€‘
            - æ­·å²æ•¸æ“šé»æ•¸ï¼š{historical_stats['data_points']} å€‹æœˆ
            - ç¸½æ­·å²éŠ·å”®é¡ï¼š{historical_stats['total_sales']:,.0f} å…ƒ
            - å¹³å‡æœˆéŠ·å”®é¡ï¼š{historical_stats['avg_monthly_sales']:,.0f} å…ƒ
            - æ­·å²éŠ·å”®æ¨™æº–å·®ï¼š{historical_stats['sales_std']:,.0f} å…ƒ

            ã€è©³ç´°é æ¸¬æ•¸æ“šã€‘
            {chr(10).join([f"  â€¢ {item['period']}: {item['forecast_sales']:,.0f} å…ƒ" for item in forecast_data])}

            ã€æ¨¡å‹è³‡è¨Šã€‘
            - æ¨¡å‹é¡å‹ï¼šSARIMAX
            - æ¨¡å‹åƒæ•¸ï¼šARIMA({forecast_result['model_info']['parameters']['order'][0]},{forecast_result['model_info']['parameters']['order'][1]},{forecast_result['model_info']['parameters']['order'][2]}) Ã— SARIMA({forecast_result['model_info']['parameters']['seasonal_order'][0]},{forecast_result['model_info']['parameters']['seasonal_order'][1]},{forecast_result['model_info']['parameters']['seasonal_order'][2]},{forecast_result['model_info']['parameters']['seasonal_order'][3]})
            - AICï¼š{forecast_result['model_info']['model_summary']['aic']:.2f}
            - BICï¼š{forecast_result['model_info']['model_summary']['bic']:.2f}

            è«‹æä¾›ä»¥ä¸‹åˆ†æï¼š

            1. ã€é æ¸¬çµæœè§£é‡‹ã€‘ï¼ˆ300å­—ä»¥å…§ï¼‰ï¼š
               - é æ¸¬çµæœçš„æ ¸å¿ƒè¦é»å’Œé—œéµç™¼ç¾
               - èˆ‡æ­·å²æ•¸æ“šçš„æ¯”è¼ƒåˆ†æ
               - é æ¸¬å¯ä¿¡åº¦è©•ä¼°

            2. ã€è¶¨å‹¢åˆ†æã€‘ï¼ˆ400å­—ä»¥å…§ï¼‰ï¼š
               - éŠ·å”®è¶¨å‹¢çš„å­£ç¯€æ€§æ¨¡å¼è­˜åˆ¥
               - é€±æœŸæ€§è®ŠåŒ–çš„åˆ†æ
               - ç•°å¸¸å€¼æˆ–ç‰¹æ®Šæ¨¡å¼çš„è§£é‡‹

            3. ã€æ¥­å‹™ç­–ç•¥å»ºè­°ã€‘ï¼ˆ500å­—ä»¥å…§ï¼‰ï¼š
               - åŸºæ–¼é æ¸¬çµæœçš„å…·é«”æ¥­å‹™ç­–ç•¥
               - è³‡æºé…ç½®å’Œé ç®—è¦åŠƒå»ºè­°
               - é¢¨éšªç®¡ç†å’Œæ‡‰å°æªæ–½

            4. ã€ç¸¾æ•ˆç›£æ§æŒ‡æ¨™ã€‘ï¼ˆ200å­—ä»¥å…§ï¼‰ï¼š
               - é—œéµç¸¾æ•ˆæŒ‡æ¨™ï¼ˆKPIï¼‰å»ºè­°
               - é æ¸¬æº–ç¢ºåº¦ç›£æ§æ–¹æ³•
               - é è­¦æ©Ÿåˆ¶è¨­å®š

            5. ã€è³‡æ·±ç¶“ç‡Ÿåˆ†æå°ˆå®¶å ±å‘Šã€‘ï¼ˆ600å­—ä»¥å…§ï¼‰ï¼š
               - ç¶œåˆæ¥­å‹™è©•ä¼°
               - ç«¶çˆ­å„ªå‹¢åˆ†æ
               - æœªä¾†ç™¼å±•æ–¹å‘å»ºè­°
               - å…·é«”å¯åŸ·è¡Œçš„è¡Œå‹•æ–¹æ¡ˆ

            è«‹ä»¥å°ˆæ¥­ã€å®¢è§€çš„èªæ°£æ’°å¯«ï¼Œä¸¦æä¾›å…·é«”å¯åŸ·è¡Œçš„å»ºè­°ã€‚é‡é»è§£é‡‹é æ¸¬çµæœçš„åˆç†æ€§ï¼Œä»¥åŠå¦‚ä½•åŸºæ–¼é€™äº›é æ¸¬åˆ¶å®šæœ‰æ•ˆçš„æ¥­å‹™ç­–ç•¥ã€‚
            """
            
            # èª¿ç”¨ Gemini API
            headers = {
                'Content-Type': 'application/json',
            }
            
            data = {
                'contents': [{
                    'parts': [{
                        'text': analysis_prompt
                    }]
                }]
            }
            
            response = requests.post(
                f'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro:generateContent?key={self.api_key}',
                headers=headers,
                json=data
            )
            
            if response.status_code == 200:
                result = response.json()
                if 'candidates' in result and len(result['candidates']) > 0:
                    analysis_text = result['candidates'][0]['content']['parts'][0]['text']
                    return {
                        'success': True,
                        'analysis': analysis_text,
                        'timestamp': datetime.now().isoformat(),
                        'analysis_metadata': {
                            'total_forecast': safe_float(total_forecast),
                            'avg_forecast': safe_float(avg_forecast),
                            'trend_direction': trend_direction,
                            'variation_coefficient': safe_float(cv),
                            'forecast_periods': len(forecast_data)
                        }
                    }
                else:
                    return {
                        'success': False,
                        'error': 'AI å›æ‡‰æ ¼å¼éŒ¯èª¤'
                    }
            else:
                return {
                    'success': False,
                    'error': f'API è«‹æ±‚å¤±æ•—: {response.status_code}'
                }
                
        except Exception as e:
            # logging.error(f"AI åˆ†æå¤±æ•—: {str(e)}")  # è¨»è§£æ‰ logging
            return {
                'success': False,
                'error': f'AI åˆ†æå¤±æ•—: {str(e)}'
            }
    
    def _get_historical_data(self):
        """ç²å–æ­·å²æ•¸æ“šï¼Œä½¿ç”¨èˆ‡åŸå§‹é æ¸¬ç³»çµ±ç›¸åŒçš„æŸ¥è©¢æ–¹å¼"""
        try:
            # ä½¿ç”¨èˆ‡åŸå§‹é æ¸¬ç³»çµ±ç›¸åŒçš„æŸ¥è©¢
            query = """
                SELECT 
                    t.year,
                    t.month,
                    COALESCE(SUM(f.amount), 0) as monthly_sales
                FROM sales_fact f
                JOIN dim_time t ON f.time_id = t.time_id
                GROUP BY t.year, t.month
                ORDER BY t.year, t.month
            """
            
            result = self.db_manager.execute_query(query)
            
            if result.empty:
                raise Exception("è³‡æ–™åº«æŸ¥è©¢è¿”å›ç©ºçµæœ")
            
            data = result.values.tolist()
            
            if not data:
                # logging.warning("âš ï¸ æ²’æœ‰æ‰¾åˆ°æ­·å²éŠ·å”®æ•¸æ“šï¼Œä½¿ç”¨ç¤ºä¾‹æ•¸æ“š")  # è¨»è§£æ‰ logging
                # è¿”å›ç¤ºä¾‹æ•¸æ“š
                return [1000000, 1200000, 1100000, 1300000, 1250000, 1400000], ['2022/01', '2022/02', '2022/03', '2022/04', '2022/05', '2022/06']
            
            # è½‰æ›ç‚ºæ™‚é–“åºåˆ—æ ¼å¼
            sales_data = []
            date_labels = []
            
            for row in data:
                year = int(row[0])
                month = int(row[1])
                sales = safe_float(row[2])
                date_label = f"{year}/{month:02d}"
                
                sales_data.append(sales)
                date_labels.append(date_label)
            
            # logging.info(f"ğŸ“Š æˆåŠŸç²å–æ­·å²æ•¸æ“šï¼š{len(sales_data)} å€‹æ•¸æ“šé»")  # è¨»è§£æ‰ logging
            # logging.info(f"ğŸ“… è¨“ç·´æœŸé–“ï¼š{date_labels[0]} åˆ° {date_labels[-1]}")  # è¨»è§£æ‰ logging
            
            return sales_data, date_labels
            
        except Exception as e:
            # logging.error(f"ç²å–æ­·å²æ•¸æ“šå¤±æ•—: {str(e)}")  # è¨»è§£æ‰ logging
            # è¿”å›ç¤ºä¾‹æ•¸æ“š
            return [1000000, 1200000, 1100000, 1300000, 1250000, 1400000], ['2022/01', '2022/02', '2022/03', '2022/04', '2022/05', '2022/06']
    
    def _process_forecast_results(self, forecast, forecast_type, periods, forecast_dates):
        """è™•ç†é æ¸¬çµæœ"""
        forecast_data = []
        
        for i, (date, value) in enumerate(zip(forecast_dates, forecast)):
            forecast_data.append({
                'period': date,
                'forecast_sales': safe_float(value)
            })
        
        return forecast_data
    
    def _generate_forecast_summary(self, forecast_type, periods, total_forecast, avg_forecast, forecast_data, historical_stats):
        """ç”Ÿæˆé æ¸¬æ‘˜è¦"""
        try:
            # æ ¹æ“šé æ¸¬é¡å‹ç”Ÿæˆæ‘˜è¦
            period_text_map = {
                'month': 'æœˆ',
                'quarter': 'å­£', 
                'year': 'å¹´'
            }
            period_text = period_text_map.get(forecast_type, 'æœˆ')
            
            # è¨ˆç®—å¢é•·ç‡
            historical_avg = historical_stats.get('avg_monthly_sales', 0)
            if historical_avg > 0:
                growth_rate = ((avg_forecast - historical_avg) / historical_avg) * 100
            else:
                growth_rate = 0
            
            # ç”Ÿæˆæ‘˜è¦å…§å®¹
            summary_parts = []
            summary_parts.append(f"## {period_text}åº¦æ¥­ç¸¾é æ¸¬åˆ†æå ±å‘Š")
            summary_parts.append("")
            summary_parts.append(f"### é æ¸¬æ¦‚æ³")
            summary_parts.append(f"- **é æ¸¬æœŸé–“**: æœªä¾† {periods} {period_text}")
            summary_parts.append(f"- **ç¸½é æ¸¬éŠ·å”®é¡**: {total_forecast:,.2f} å…ƒ")
            summary_parts.append(f"- **å¹³å‡{period_text}åº¦éŠ·å”®é¡**: {avg_forecast:,.2f} å…ƒ")
            summary_parts.append(f"- **æ­·å²å¹³å‡{period_text}åº¦éŠ·å”®é¡**: {historical_avg:,.2f} å…ƒ")
            summary_parts.append("")
            
            # è¶¨å‹¢åˆ†æ
            summary_parts.append(f"### è¶¨å‹¢åˆ†æ")
            if growth_rate > 5:
                summary_parts.append(f"- é æ¸¬é¡¯ç¤º{period_text}åº¦éŠ·å”®é¡å‘ˆä¸Šå‡è¶¨å‹¢")
                summary_parts.append(f"- å¹³å‡æ¯{period_text}é è¨ˆå¢é•· {growth_rate:.2f}%")
            elif growth_rate < -5:
                summary_parts.append(f"- é æ¸¬é¡¯ç¤º{period_text}åº¦éŠ·å”®é¡å‘ˆä¸‹é™è¶¨å‹¢")
                summary_parts.append(f"- å¹³å‡æ¯{period_text}é è¨ˆä¸‹é™ {abs(growth_rate):.2f}%")
            else:
                summary_parts.append(f"- é æ¸¬é¡¯ç¤º{period_text}åº¦éŠ·å”®é¡ä¿æŒç©©å®š")
            
            summary_parts.append("")
            summary_parts.append(f"### é æ¸¬æ•¸æ“š")
            for i, item in enumerate(forecast_data[:6]):  # åªé¡¯ç¤ºå‰6å€‹
                summary_parts.append(f"- {item['period']}: {item['forecast_sales']:,.2f} å…ƒ")
            if len(forecast_data) > 6:
                summary_parts.append(f"- ... å…± {len(forecast_data)} å€‹é æ¸¬æœŸé–“")
            
            return "\n".join(summary_parts)
            
        except Exception as e:
            # logging.error(f"ç”Ÿæˆé æ¸¬æ‘˜è¦å¤±æ•—: {e}")  # è¨»è§£æ‰ logging
            return f"é æ¸¬æ‘˜è¦ç”Ÿæˆå¤±æ•—: {str(e)}" 